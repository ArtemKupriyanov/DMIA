{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np # calculations with arrays\n",
    "import pandas as pd # user-friendly DataFrames for data representation\n",
    "import sklearn # machine learning algorithms\n",
    "from sklearn import ensemble, linear_model\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "import matplotlib.pyplot as plt # import plot functions\n",
    "# necessary to plot in jupyter notebook:\n",
    "%matplotlib inline\n",
    "import seaborn as sns # make plots beautiful"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download data from competition's page\n",
    "\n",
    "https://inclass.kaggle.com/c/data-mining-in-action-2016-competitions-01/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('competition_zero/train2.csv')\n",
    "test = pd.read_csv('competition_zero/test2.csv')\n",
    "sample_submission = pd.read_csv('competition_zero/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>day</th>\n",
       "      <th>team1</th>\n",
       "      <th>team2</th>\n",
       "      <th>score1</th>\n",
       "      <th>score2</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2998</td>\n",
       "      <td>19</td>\n",
       "      <td>317</td>\n",
       "      <td>131</td>\n",
       "      <td>336</td>\n",
       "      <td>278</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  day  team1  team2  score1  score2 target\n",
       "0  2998   19    317    131     336     278   True"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print first row\n",
    "train[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>year</th>\n",
       "      <th>team1</th>\n",
       "      <th>team2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3021</td>\n",
       "      <td>363</td>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  year  team1  team2\n",
       "0   0  3021    363    161"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  target\n",
       "0   0     0.5"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Target variable is \"target\" and this means we will be predicting it\n",
    "sample_submission[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick look at the unique values in data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "year [2998 2999 3000 3001 3002]\n",
      "day [19 28 30 31 33]\n",
      "team1 [317  61 110 352 229]\n",
      "team2 [131  29 141 146  91]\n",
      "score1 [336 301 359 309 332]\n",
      "score2 [278 259 267 410 220]\n",
      "target [True False]\n"
     ]
    }
   ],
   "source": [
    "for c in train.columns:\n",
    "    print (c, train[c].unique()[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets split data randomly to train and validatation. We will train our algorithms on selected train set and validate them on validation set. Easy as it can be!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101609, 7)"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train size\n",
    "train.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train is quite big, so for example purposes we'll sample only part of it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import ShuffleSplit, train_test_split\n",
    "\n",
    "for itr, ite in ShuffleSplit(len(train), n_iter=1, train_size=0.75, test_size=0.25, random_state=42):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "information about all functions can be found on the internet, for example\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.ShuffleSplit.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# or you can open it in you Jupyter notebook executing function in this manner\n",
    "?ShuffleSplit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76206, 25403)"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(itr), len(ite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([64794, 42486, 54539, 39466, 36905]),\n",
       " array([73749, 26995, 52944, 55854, 35538]))"
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itr[:5], ite[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we have validation set \"ite\" to check the quality of our solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# features and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  target\n",
       "0   0     0.5\n",
       "1   1     0.5"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we need to change 'target' column in \"sample_submission\" to our predictions.\n",
    "\n",
    "For now we will select only features that are present in both train and test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"year\" is NOT present in test\n",
      "\"day\" is NOT present in test\n",
      "\"team1\" is present in test and train\n",
      "\"team2\" is present in test and train\n",
      "\"score1\" is NOT present in test\n",
      "\"score2\" is NOT present in test\n",
      "\"target\" is NOT present in test\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['team1', 'team2']"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = []\n",
    "for c in train.columns:\n",
    "    if c in test.columns and c!='target' and c!='year':\n",
    "        features += [c]\n",
    "        print ('\"{}\" is present in test and train'.format(c))\n",
    "    else:\n",
    "        print ('\"{}\" is NOT present in test'.format(c))\n",
    "        \n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here we split train on \"train\" and \"validation\" parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xtrain = train.loc[itr, features]    \n",
    "ytrain = train.loc[itr, 'target']\n",
    "\n",
    "xval = train.loc[ite, features]\n",
    "yval = train.loc[ite, 'target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline solution\n",
    "\n",
    "lets make baseline first by predicting the mean value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.50096940231672393"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.target.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.5009694,  0.5009694,  0.5009694, ...,  0.5009694,  0.5009694,\n",
       "        0.5009694])"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "constant_prediction = yval * 0 + train.target.mean()\n",
    "constant_prediction = constant_prediction.values\n",
    "constant_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6931565015839517"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(yval, constant_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission = sample_submission.copy()\n",
    "submission.target = train['target'].mean() # notice here that we can refer to a column 'target' in two ways\n",
    "submission.to_csv('constant_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now this should score like \"Baseline - Constant\" on Leaderboard!\n",
    "You can submit this by going to \n",
    "\n",
    "https://inclass.kaggle.com/c/data-mining-in-action-2016-competitions-01/submissions/attach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning\n",
    "\n",
    "Finally, lets try machine learning!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alg = linear_model.LogisticRegression()\n",
    "alg.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prediction = alg.predict_proba(xval)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.69278158850082583"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(yval, prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Well, not so far from the constant solution... Let's try to understand why.\n",
    "\n",
    "What's a linear model such as LogisticRegression is trying to do is multiply each variable on some coefficient and add add it up, in our case:\n",
    "\n",
    "y_predicted = column1 \\* coef1 + column2 \\* coef2 + column3 \\* coef3 + bias\n",
    "\n",
    "We can print coefficients and bias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.00033022, -0.00029718]]), array([  9.62607300e-08]))"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alg.coef_, alg.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But clearly, \"team1\" and \"team2\" are _categorical_ columns, just like names of the teams. \n",
    "\n",
    "So we need to turn \"team\" columns to something linear algorithm can work with. For example first few rows from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    317\n",
       "1     61\n",
       "2    110\n",
       "Name: team1, dtype: int64"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.loc[:2, 'team1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>61</th>\n",
       "      <th>110</th>\n",
       "      <th>317</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   61   110  317\n",
       "0  0.0  0.0  1.0\n",
       "1  1.0  0.0  0.0\n",
       "2  0.0  1.0  0.0"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.get_dummies(train.loc[:2, 'team1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So each team name now has it's own column. Read about \"pd.get_dummies\" here:\n",
    "\n",
    "http://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### But let's come back to more interesting stuff for now\n",
    "### We are competition's solvers, remember? Lets dive into the space of more complicated models!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alg = ensemble.RandomForestClassifier(15, n_jobs=4)\n",
    "alg.fit(xtrain, ytrain)\n",
    "prediction = alg.predict_proba(xval)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.602708141747019"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(yval, prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Surprisingly, this doesn't work very well. Now, like competition pro, let's make our models bigger!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alg = ensemble.RandomForestClassifier(150, n_jobs=4)\n",
    "alg.fit(xtrain, ytrain)\n",
    "prediction = alg.predict_proba(xval)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0174345124319784"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(yval, prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Almost there! But for now let's skip this model too and go to _real_ competitions stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "str_team1 = [str(i) for i in train['team1'].values]\n",
    "str_team2 = [str(i) for i in train['team2'].values]\n",
    "str_team1_test = [str(i) for i in test['team1'].values]\n",
    "str_team2_test = [str(i) for i in test['team2'].values]\n",
    "df_str_team1 = pd.DataFrame(data=str_team1, columns=['team1'])\n",
    "df_str_team2 = pd.DataFrame(data=str_team2, columns=['team2'])\n",
    "df_str_team1_test = pd.DataFrame(data=str_team1_test, columns=['team1'])\n",
    "df_str_team2_test = pd.DataFrame(data=str_team2_test, columns=['team2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = train[['team1', 'team2', 'target']]\n",
    "X_test = test[['team1', 'team2']]\n",
    "X_train_cat = pd.concat([df_str_team1, df_str_team2], axis=1)\n",
    "X_test_cat = pd.concat([df_str_team1_test, df_str_team2_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer as DV\n",
    "encoder = DV(sparse = False)\n",
    "X_cat_oh = encoder.fit_transform(X_train_cat.T.to_dict().values())\n",
    "X_test_cat_oh = encoder.transform(X_test_cat.T.to_dict().values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101609, 706)"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_cat_oh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = X_train['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20321"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delim = int(0.2 * X_cat_oh.shape[0])\n",
    "delim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xtrain = X_cat_oh[:delim, :]\n",
    "ytrain = y[:delim]\n",
    "xval = X_cat_oh[delim:, :]\n",
    "yval = y[delim:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20321, 706)"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "percentage_of_win = {}\n",
    "for year, day, team1, team2, score1, score2, target in train.values:\n",
    "    if team1 not in percentage_of_win:\n",
    "        percentage_of_win[team1] = [int(target), 0, 1, 0]\n",
    "    else:\n",
    "        percentage_of_win[team1][0] += int(target)\n",
    "        percentage_of_win[team1][2] += 1\n",
    "    if team2 not in percentage_of_win:\n",
    "        percentage_of_win[team1] = [0, 1 - int(target), 0, 1]\n",
    "    else:\n",
    "        percentage_of_win[team1][1] += (1 - int(target))\n",
    "        percentage_of_win[team1][3] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>year</th>\n",
       "      <th>team1</th>\n",
       "      <th>team2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>278</td>\n",
       "      <td>3021</td>\n",
       "      <td>303</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>519</td>\n",
       "      <td>3020</td>\n",
       "      <td>349</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>691</th>\n",
       "      <td>691</td>\n",
       "      <td>3021</td>\n",
       "      <td>154</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>781</th>\n",
       "      <td>781</td>\n",
       "      <td>3020</td>\n",
       "      <td>258</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>907</th>\n",
       "      <td>907</td>\n",
       "      <td>3020</td>\n",
       "      <td>265</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924</th>\n",
       "      <td>924</td>\n",
       "      <td>3020</td>\n",
       "      <td>155</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1173</th>\n",
       "      <td>1173</td>\n",
       "      <td>3020</td>\n",
       "      <td>281</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1418</th>\n",
       "      <td>1418</td>\n",
       "      <td>3020</td>\n",
       "      <td>134</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1641</th>\n",
       "      <td>1641</td>\n",
       "      <td>3021</td>\n",
       "      <td>226</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1781</th>\n",
       "      <td>1781</td>\n",
       "      <td>3020</td>\n",
       "      <td>316</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1987</th>\n",
       "      <td>1987</td>\n",
       "      <td>3020</td>\n",
       "      <td>247</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2228</th>\n",
       "      <td>2228</td>\n",
       "      <td>3021</td>\n",
       "      <td>256</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2229</th>\n",
       "      <td>2229</td>\n",
       "      <td>3021</td>\n",
       "      <td>330</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2254</th>\n",
       "      <td>2254</td>\n",
       "      <td>3020</td>\n",
       "      <td>229</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2405</th>\n",
       "      <td>2405</td>\n",
       "      <td>3020</td>\n",
       "      <td>212</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2412</th>\n",
       "      <td>2412</td>\n",
       "      <td>3021</td>\n",
       "      <td>335</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2652</th>\n",
       "      <td>2652</td>\n",
       "      <td>3021</td>\n",
       "      <td>286</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3022</th>\n",
       "      <td>3022</td>\n",
       "      <td>3020</td>\n",
       "      <td>191</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3333</th>\n",
       "      <td>3333</td>\n",
       "      <td>3021</td>\n",
       "      <td>292</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3481</th>\n",
       "      <td>3481</td>\n",
       "      <td>3021</td>\n",
       "      <td>138</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3749</th>\n",
       "      <td>3749</td>\n",
       "      <td>3020</td>\n",
       "      <td>302</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3809</th>\n",
       "      <td>3809</td>\n",
       "      <td>3020</td>\n",
       "      <td>283</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3817</th>\n",
       "      <td>3817</td>\n",
       "      <td>3020</td>\n",
       "      <td>244</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3895</th>\n",
       "      <td>3895</td>\n",
       "      <td>3020</td>\n",
       "      <td>205</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4433</th>\n",
       "      <td>4433</td>\n",
       "      <td>3021</td>\n",
       "      <td>114</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5176</th>\n",
       "      <td>5176</td>\n",
       "      <td>3021</td>\n",
       "      <td>269</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5233</th>\n",
       "      <td>5233</td>\n",
       "      <td>3021</td>\n",
       "      <td>120</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5324</th>\n",
       "      <td>5324</td>\n",
       "      <td>3020</td>\n",
       "      <td>323</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5452</th>\n",
       "      <td>5452</td>\n",
       "      <td>3020</td>\n",
       "      <td>172</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5539</th>\n",
       "      <td>5539</td>\n",
       "      <td>3020</td>\n",
       "      <td>123</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117729</th>\n",
       "      <td>117729</td>\n",
       "      <td>3020</td>\n",
       "      <td>216</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117798</th>\n",
       "      <td>117798</td>\n",
       "      <td>3020</td>\n",
       "      <td>308</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118301</th>\n",
       "      <td>118301</td>\n",
       "      <td>3020</td>\n",
       "      <td>163</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118342</th>\n",
       "      <td>118342</td>\n",
       "      <td>3021</td>\n",
       "      <td>134</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118349</th>\n",
       "      <td>118349</td>\n",
       "      <td>3020</td>\n",
       "      <td>280</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118703</th>\n",
       "      <td>118703</td>\n",
       "      <td>3021</td>\n",
       "      <td>225</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118999</th>\n",
       "      <td>118999</td>\n",
       "      <td>3020</td>\n",
       "      <td>312</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119246</th>\n",
       "      <td>119246</td>\n",
       "      <td>3021</td>\n",
       "      <td>157</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119251</th>\n",
       "      <td>119251</td>\n",
       "      <td>3021</td>\n",
       "      <td>354</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119488</th>\n",
       "      <td>119488</td>\n",
       "      <td>3021</td>\n",
       "      <td>208</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119572</th>\n",
       "      <td>119572</td>\n",
       "      <td>3020</td>\n",
       "      <td>329</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119598</th>\n",
       "      <td>119598</td>\n",
       "      <td>3020</td>\n",
       "      <td>241</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119751</th>\n",
       "      <td>119751</td>\n",
       "      <td>3021</td>\n",
       "      <td>222</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119793</th>\n",
       "      <td>119793</td>\n",
       "      <td>3021</td>\n",
       "      <td>230</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120216</th>\n",
       "      <td>120216</td>\n",
       "      <td>3020</td>\n",
       "      <td>320</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120541</th>\n",
       "      <td>120541</td>\n",
       "      <td>3020</td>\n",
       "      <td>270</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120695</th>\n",
       "      <td>120695</td>\n",
       "      <td>3020</td>\n",
       "      <td>187</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121066</th>\n",
       "      <td>121066</td>\n",
       "      <td>3021</td>\n",
       "      <td>224</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121332</th>\n",
       "      <td>121332</td>\n",
       "      <td>3021</td>\n",
       "      <td>141</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121554</th>\n",
       "      <td>121554</td>\n",
       "      <td>3020</td>\n",
       "      <td>300</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122068</th>\n",
       "      <td>122068</td>\n",
       "      <td>3021</td>\n",
       "      <td>188</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122164</th>\n",
       "      <td>122164</td>\n",
       "      <td>3020</td>\n",
       "      <td>166</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122478</th>\n",
       "      <td>122478</td>\n",
       "      <td>3021</td>\n",
       "      <td>264</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122628</th>\n",
       "      <td>122628</td>\n",
       "      <td>3020</td>\n",
       "      <td>211</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122978</th>\n",
       "      <td>122978</td>\n",
       "      <td>3020</td>\n",
       "      <td>264</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123273</th>\n",
       "      <td>123273</td>\n",
       "      <td>3020</td>\n",
       "      <td>359</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123527</th>\n",
       "      <td>123527</td>\n",
       "      <td>3021</td>\n",
       "      <td>244</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124072</th>\n",
       "      <td>124072</td>\n",
       "      <td>3020</td>\n",
       "      <td>348</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124292</th>\n",
       "      <td>124292</td>\n",
       "      <td>3021</td>\n",
       "      <td>322</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125140</th>\n",
       "      <td>125140</td>\n",
       "      <td>3020</td>\n",
       "      <td>214</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>495 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Id  year  team1  team2\n",
       "278        278  3021    303    113\n",
       "519        519  3020    349    113\n",
       "691        691  3021    154    113\n",
       "781        781  3020    258    113\n",
       "907        907  3020    265    113\n",
       "924        924  3020    155    113\n",
       "1173      1173  3020    281    113\n",
       "1418      1418  3020    134    113\n",
       "1641      1641  3021    226    113\n",
       "1781      1781  3020    316    113\n",
       "1987      1987  3020    247    113\n",
       "2228      2228  3021    256    113\n",
       "2229      2229  3021    330    113\n",
       "2254      2254  3020    229    113\n",
       "2405      2405  3020    212    113\n",
       "2412      2412  3021    335    113\n",
       "2652      2652  3021    286    113\n",
       "3022      3022  3020    191    113\n",
       "3333      3333  3021    292    113\n",
       "3481      3481  3021    138    113\n",
       "3749      3749  3020    302    113\n",
       "3809      3809  3020    283    113\n",
       "3817      3817  3020    244    113\n",
       "3895      3895  3020    205    113\n",
       "4433      4433  3021    114    113\n",
       "5176      5176  3021    269    113\n",
       "5233      5233  3021    120    113\n",
       "5324      5324  3020    323    113\n",
       "5452      5452  3020    172    113\n",
       "5539      5539  3020    123    113\n",
       "...        ...   ...    ...    ...\n",
       "117729  117729  3020    216    113\n",
       "117798  117798  3020    308    113\n",
       "118301  118301  3020    163    113\n",
       "118342  118342  3021    134    113\n",
       "118349  118349  3020    280    113\n",
       "118703  118703  3021    225    113\n",
       "118999  118999  3020    312    113\n",
       "119246  119246  3021    157    113\n",
       "119251  119251  3021    354    113\n",
       "119488  119488  3021    208    113\n",
       "119572  119572  3020    329    113\n",
       "119598  119598  3020    241    113\n",
       "119751  119751  3021    222    113\n",
       "119793  119793  3021    230    113\n",
       "120216  120216  3020    320    113\n",
       "120541  120541  3020    270    113\n",
       "120695  120695  3020    187    113\n",
       "121066  121066  3021    224    113\n",
       "121332  121332  3021    141    113\n",
       "121554  121554  3020    300    113\n",
       "122068  122068  3021    188    113\n",
       "122164  122164  3020    166    113\n",
       "122478  122478  3021    264    113\n",
       "122628  122628  3020    211    113\n",
       "122978  122978  3020    264    113\n",
       "123273  123273  3020    359    113\n",
       "123527  123527  3021    244    113\n",
       "124072  124072  3020    348    113\n",
       "124292  124292  3021    322    113\n",
       "125140  125140  3020    214    113\n",
       "\n",
       "[495 rows x 4 columns]"
      ]
     },
     "execution_count": 463,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[test['team2']==113]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2998, 19, 317, 131, 336, 278, True, 0.6871165644171779, 0.38484848484848483],\n",
       " [2998, 28, 61, 29, 301, 259, True, 0.5050505050505051, 0.44904458598726116],\n",
       " [2998, 28, 110, 141, 359, 267, True, 0.5253731343283582, 0.5047021943573667],\n",
       " [2998, 28, 352, 146, 309, 410, False, 0.5841584158415841, 0.3088235294117647],\n",
       " [2998, 28, 229, 91, 332, 220, True, 0.6873065015479877, 0.48589341692789967],\n",
       " [2998,\n",
       "  28,\n",
       "  164,\n",
       "  238,\n",
       "  236,\n",
       "  278,\n",
       "  False,\n",
       "  0.38738738738738737,\n",
       "  0.3106508875739645],\n",
       " [2998, 28, 184, 243, 181, 224, False, 0.4358974358974359, 0.3853820598006645],\n",
       " [2998, 28, 245, 23, 216, 185, True, 0.6314363143631436, 0.46394984326018807],\n",
       " [2998, 28, 300, 349, 402, 321, True, 0.6363636363636364, 0.43790849673202614],\n",
       " [2998, 30, 61, 110, 259, 325, False, 0.5050505050505051, 0.4732142857142857],\n",
       " [2998, 30, 229, 245, 294, 185, True, 0.6873065015479877, 0.3675675675675676],\n",
       " [2998, 30, 300, 243, 220, 178, True, 0.6363636363636364, 0.3853820598006645],\n",
       " [2998, 31, 10, 310, 282, 232, True, 0.46417445482866043, 0.7015503875968992],\n",
       " [2998, 31, 39, 69, 317, 259, True, 0.7246376811594203, 0.5759493670886076],\n",
       " [2998, 31, 205, 43, 282, 352, False, 0.5673076923076923, 0.40988372093023256],\n",
       " [2998, 31, 47, 112, 406, 398, True, 0.2971014492753623, 0.7459016393442623],\n",
       " [2998, 31, 180, 51, 282, 328, False, 0.6150627615062761, 0.5],\n",
       " [2998, 31, 53, 22, 417, 297, True, 0.7088607594936709, 0.5109034267912772],\n",
       " [2998, 31, 63, 116, 294, 178, True, 0.7087378640776699, 0.6102719033232629],\n",
       " [2998, 31, 82, 312, 336, 297, True, 0.3938356164383562, 0.3783783783783784],\n",
       " [2998, 31, 265, 101, 263, 305, False, 0.5, 0.5795454545454546],\n",
       " [2998, 31, 70, 125, 390, 448, False, 0.19387755102040816, 0.6033333333333334],\n",
       " [2998, 31, 150, 117, 332, 286, True, 0.4189189189189189, 0.5275862068965518],\n",
       " [2998, 31, 188, 158, 425, 541, False, 0.396875, 0.6805555555555556],\n",
       " [2998, 31, 161, 319, 297, 294, True, 0.5495495495495496, 0.5833333333333334],\n",
       " [2998, 31, 241, 166, 212, 379, False, 0.2682119205298013, 0.3323262839879154],\n",
       " [2998, 31, 273, 169, 228, 363, False, 0.564935064935065, 0.3829787234042553],\n",
       " [2998,\n",
       "  31,\n",
       "  232,\n",
       "  185,\n",
       "  150,\n",
       "  301,\n",
       "  False,\n",
       "  0.5520504731861199,\n",
       "  0.42333333333333334],\n",
       " [2998, 31, 201, 98, 309, 267, True, 0.5435435435435435, 0.5975232198142415],\n",
       " [2998, 31, 207, 126, 433, 379, True, 0.6813880126182965, 0.6360424028268551],\n",
       " [2998, 31, 146, 238, 259, 328, False, 0.6888888888888889, 0.3106508875739645],\n",
       " [2998, 31, 206, 244, 282, 356, False, 0.2783171521035599, 0.4401294498381877],\n",
       " [2998, 31, 234, 249, 305, 340, False, 0.5849673202614379, 0.5540540540540541],\n",
       " [2998, 31, 260, 261, 232, 220, True, 0.45714285714285713, 0.4854368932038835],\n",
       " [2998,\n",
       "  31,\n",
       "  250,\n",
       "  264,\n",
       "  232,\n",
       "  259,\n",
       "  False,\n",
       "  0.5869565217391305,\n",
       "  0.48464163822525597],\n",
       " [2998, 31, 283, 271, 301, 383, False, 0.4076655052264808, 0.439873417721519],\n",
       " [2998, 31, 302, 274, 228, 243, False, 0.378839590443686, 0.5427631578947368],\n",
       " [2998,\n",
       "  31,\n",
       "  291,\n",
       "  278,\n",
       "  290,\n",
       "  352,\n",
       "  False,\n",
       "  0.36363636363636365,\n",
       "  0.5859872611464968],\n",
       " [2998, 31, 272, 281, 239, 305, False, 0.5324232081911263, 0.6423611111111112],\n",
       " [2998, 31, 351, 288, 274, 286, False, 0.5765765765765766, 0.1875],\n",
       " [2998, 31, 159, 290, 216, 379, False, 0.39039039039039036, 0.3125],\n",
       " [2998, 31, 295, 268, 348, 224, True, 0.47384615384615386, 0.6101083032490975],\n",
       " [2998, 31, 308, 259, 290, 185, True, 0.4625, 0.49828178694158076],\n",
       " [2998, 31, 48, 350, 239, 402, False, 0.4798657718120805, 0.5575757575757576],\n",
       " [2998, 31, 59, 363, 236, 247, False, 0.43217665615141954, 0.5714285714285714],\n",
       " [2998, 33, 4, 72, 294, 228, True, 0.6397694524495677, 0.348993288590604],\n",
       " [2998, 33, 14, 8, 317, 286, True, 0.49498327759197325, 0.6466666666666666],\n",
       " [2998, 33, 65, 19, 201, 216, False, 0.6567164179104478, 0.7454545454545455],\n",
       " [2998, 33, 310, 22, 263, 348, False, 0.29961089494163423, 0.5109034267912772],\n",
       " [2998, 33, 287, 33, 205, 243, False, 0.5512048192771084, 0.4938650306748466],\n",
       " [2998, 33, 38, 45, 212, 297, False, 0.40131578947368424, 0.5562913907284768],\n",
       " [2998, 33, 188, 48, 274, 336, False, 0.396875, 0.5217391304347826],\n",
       " [2998, 33, 78, 52, 313, 317, False, 0.49019607843137253, 0.7738853503184714],\n",
       " [2998, 33, 53, 10, 278, 267, True, 0.7088607594936709, 0.5372670807453416],\n",
       " [2998, 33, 50, 58, 208, 263, False, 0.5838150289017341, 0.29213483146067415],\n",
       " [2998, 33, 96, 97, 294, 255, True, 0.7340425531914894, 0.6559485530546624],\n",
       " [2998, 33, 104, 26, 429, 282, True, 0.40522875816993464, 0.6201298701298701],\n",
       " [2998, 33, 198, 120, 239, 328, False, 0.4414715719063545, 0.436950146627566],\n",
       " [2998, 33, 337, 122, 189, 305, False, 0.6346153846153846, 0.5261538461538462],\n",
       " [2998, 33, 134, 171, 390, 185, True, 0.5993975903614458, 0.7133550488599348],\n",
       " [2998,\n",
       "  33,\n",
       "  320,\n",
       "  142,\n",
       "  224,\n",
       "  472,\n",
       "  False,\n",
       "  0.37538461538461537,\n",
       "  0.18711656441717792],\n",
       " [2998, 33, 327, 143, 251, 398, False, 0.4825174825174825, 0.4491017964071856],\n",
       " [2998, 33, 157, 124, 394, 282, True, 0.7033639143730887, 0.7166666666666667],\n",
       " [2998,\n",
       "  33,\n",
       "  163,\n",
       "  219,\n",
       "  309,\n",
       "  286,\n",
       "  True,\n",
       "  0.46710526315789475,\n",
       "  0.49823321554770317],\n",
       " [2998, 33, 168, 191, 321, 205, True, 0.6480938416422287, 0.5422077922077922],\n",
       " [2998, 33, 192, 17, 236, 232, True, 0.4950166112956811, 0.5240384615384616],\n",
       " [2998, 33, 204, 258, 352, 162, True, 0.5657492354740061, 0.5080906148867314],\n",
       " [2998, 33, 82, 207, 328, 352, False, 0.3938356164383562, 0.31761006289308175],\n",
       " [2998,\n",
       "  33,\n",
       "  217,\n",
       "  303,\n",
       "  313,\n",
       "  290,\n",
       "  True,\n",
       "  0.39603960396039606,\n",
       "  0.46325878594249204],\n",
       " [2998, 33, 220, 318, 301, 297, True, 0.5252525252525253, 0.5062111801242236],\n",
       " [2998,\n",
       "  33,\n",
       "  159,\n",
       "  234,\n",
       "  317,\n",
       "  348,\n",
       "  False,\n",
       "  0.39039039039039036,\n",
       "  0.4169381107491857],\n",
       " [2998, 33, 237, 139, 325, 247, True, 0.49127906976744184, 0.5353535353535354],\n",
       " [2998, 33, 248, 218, 394, 278, True, 0.5283018867924528, 0.5290519877675841],\n",
       " [2998, 33, 268, 112, 433, 286, True, 0.391304347826087, 0.7459016393442623],\n",
       " [2998, 33, 285, 210, 282, 247, True, 0.5180722891566265, 0.48466257668711654],\n",
       " [2998, 33, 249, 290, 247, 263, False, 0.4440677966101695, 0.3125],\n",
       " [2998, 33, 47, 295, 278, 286, False, 0.2971014492753623, 0.5245398773006135],\n",
       " [2998,\n",
       "  33,\n",
       "  126,\n",
       "  312,\n",
       "  309,\n",
       "  383,\n",
       "  False,\n",
       "  0.36524822695035464,\n",
       "  0.3783783783783784],\n",
       " [2998,\n",
       "  33,\n",
       "  326,\n",
       "  328,\n",
       "  220,\n",
       "  224,\n",
       "  False,\n",
       "  0.46689895470383275,\n",
       "  0.37888198757763975],\n",
       " [2998, 33, 331, 311, 321, 216, True, 0.569078947368421, 0.5352564102564102],\n",
       " [2998, 33, 129, 333, 255, 356, False, 0.5185185185185185, 0.3644578313253012],\n",
       " [2998, 33, 334, 2, 282, 263, True, 0.5924764890282131, 0.6185567010309279],\n",
       " [2998, 33, 92, 344, 236, 301, False, 0.4146341463414634, 0.4420289855072464],\n",
       " [2998, 33, 347, 251, 251, 239, True, 0.515625, 0.43962848297213625],\n",
       " [2998, 33, 322, 348, 228, 336, False, 0.4326923076923077, 0.3925233644859813],\n",
       " [2998, 33, 158, 350, 325, 367, False, 0.3205574912891986, 0.5575757575757576],\n",
       " [2998, 33, 353, 269, 317, 208, True, 0.5623003194888179, 0.6333333333333333],\n",
       " [2998,\n",
       "  33,\n",
       "  160,\n",
       "  358,\n",
       "  259,\n",
       "  344,\n",
       "  False,\n",
       "  0.41823899371069184,\n",
       "  0.34049079754601225],\n",
       " [2998, 33, 361, 156, 371, 301, True, 0.5342465753424658, 0.5143769968051118],\n",
       " [2998, 35, 135, 171, 441, 228, True, 0.5606060606060606, 0.7133550488599348],\n",
       " [2998, 35, 336, 184, 251, 278, False, 0.6139817629179332, 0.5654952076677316],\n",
       " [2998, 35, 54, 214, 224, 375, False, 0.2909090909090909, 0.22285714285714286],\n",
       " [2998, 35, 250, 261, 301, 263, True, 0.5869565217391305, 0.4854368932038835],\n",
       " [2998, 35, 69, 256, 259, 282, False, 0.4253968253968254, 0.42042042042042044],\n",
       " [2998, 37, 16, 178, 356, 321, True, 0.6470588235294118, 0.40460526315789475],\n",
       " [2998, 37, 327, 24, 282, 305, False, 0.4825174825174825, 0.5517241379310345],\n",
       " [2998, 37, 43, 188, 375, 193, True, 0.5918367346938775, 0.6043613707165109],\n",
       " [2998, 37, 50, 153, 278, 189, True, 0.5838150289017341, 0.4868421052631579],\n",
       " [2998, 37, 51, 354, 328, 309, True, 0.498371335504886, 0.5579937304075235],\n",
       " [2998, 37, 53, 92, 290, 224, True, 0.7088607594936709, 0.5866261398176292],\n",
       " [2998, 37, 32, 56, 208, 243, False, 0.4983922829581994, 0.5584415584415584],\n",
       " [2998, 37, 254, 57, 185, 193, False, 0.49498327759197325, 0.5857142857142857],\n",
       " [2998, 37, 60, 306, 359, 321, True, 0.5352112676056338, 0.6063492063492063],\n",
       " [2998, 37, 68, 262, 359, 325, True, 0.5287356321839081, 0.5451713395638629],\n",
       " [2998, 37, 73, 22, 390, 363, True, 0.5706051873198847, 0.5109034267912772],\n",
       " [2998, 37, 191, 75, 301, 313, False, 0.4592833876221498, 0.603225806451613],\n",
       " [2998, 37, 87, 81, 290, 398, False, 0.40273037542662116, 0.125],\n",
       " [2998, 37, 132, 83, 193, 228, False, 0.470404984423676, 0.6006944444444444],\n",
       " [2998, 37, 90, 297, 336, 270, True, 0.4968553459119497, 0.33727810650887574],\n",
       " [2998, 37, 91, 69, 286, 170, True, 0.5125786163522013, 0.5759493670886076],\n",
       " [2998, 37, 70, 101, 278, 356, False, 0.19387755102040816, 0.5795454545454546],\n",
       " [2998, 37, 11, 104, 309, 313, False, 0.4983277591973244, 0.5928338762214984],\n",
       " [2998,\n",
       "  37,\n",
       "  202,\n",
       "  127,\n",
       "  259,\n",
       "  297,\n",
       "  False,\n",
       "  0.3291139240506329,\n",
       "  0.49523809523809526],\n",
       " [2998, 37, 80, 150, 317, 379, False, 0.6426332288401254, 0.5824915824915825],\n",
       " [2998,\n",
       "  37,\n",
       "  159,\n",
       "  158,\n",
       "  336,\n",
       "  390,\n",
       "  False,\n",
       "  0.39039039039039036,\n",
       "  0.6805555555555556],\n",
       " [2998, 37, 268, 170, 336, 352, False, 0.391304347826087, 0.5507246376811594],\n",
       " [2998, 37, 177, 149, 313, 263, True, 0.7072463768115942, 0.5741935483870968],\n",
       " [2998, 37, 179, 138, 267, 212, True, 0.6071428571428571, 0.5462962962962963],\n",
       " [2998, 37, 45, 181, 162, 278, False, 0.44518272425249167, 0.3415384615384615],\n",
       " [2998, 37, 325, 204, 325, 359, False, 0.540453074433657, 0.4329268292682927],\n",
       " [2998, 37, 208, 311, 390, 301, True, 0.6059602649006622, 0.5352564102564102],\n",
       " [2998, 37, 229, 298, 344, 224, True, 0.6873065015479877, 0.627831715210356],\n",
       " [2998, 37, 128, 236, 232, 251, False, 0.6490683229813664, 0.5428571428571428],\n",
       " [2998, 37, 249, 13, 297, 274, True, 0.4440677966101695, 0.44324324324324327],\n",
       " [2998,\n",
       "  37,\n",
       "  274,\n",
       "  260,\n",
       "  263,\n",
       "  290,\n",
       "  False,\n",
       "  0.45874587458745875,\n",
       "  0.5450236966824644],\n",
       " [2998, 37, 291, 26, 410, 328, True, 0.36363636363636365, 0.6201298701298701],\n",
       " [2998, 37, 241, 301, 216, 321, False, 0.2682119205298013, 0.5290519877675841],\n",
       " [2998, 37, 303, 196, 317, 263, True, 0.5352564102564102, 0.6182965299684543],\n",
       " [2998,\n",
       "  37,\n",
       "  211,\n",
       "  308,\n",
       "  247,\n",
       "  278,\n",
       "  False,\n",
       "  0.32967032967032966,\n",
       "  0.5358255451713395],\n",
       " [2998, 37, 323, 322, 255, 263, False, 0.5540983606557377, 0.5686900958466453],\n",
       " [2998, 37, 299, 335, 344, 371, False, 0.4883720930232558, 0.3665158371040724],\n",
       " [2998, 37, 336, 148, 267, 197, True, 0.6139817629179332, 0.6167247386759582],\n",
       " [2998,\n",
       "  37,\n",
       "  356,\n",
       "  338,\n",
       "  166,\n",
       "  301,\n",
       "  False,\n",
       "  0.3821656050955414,\n",
       "  0.44837758112094395],\n",
       " [2998, 37, 344, 160, 270, 228, True, 0.5563636363636364, 0.5830721003134797],\n",
       " [2998, 37, 54, 348, 220, 375, False, 0.2909090909090909, 0.3925233644859813],\n",
       " [2998, 37, 355, 251, 301, 150, True, 0.5220125786163522, 0.43962848297213625],\n",
       " [2998,\n",
       "  37,\n",
       "  269,\n",
       "  358,\n",
       "  274,\n",
       "  317,\n",
       "  False,\n",
       "  0.36789297658862874,\n",
       "  0.34049079754601225],\n",
       " [2998, 37, 29, 361, 232, 301, False, 0.5509554140127388, 0.4681818181818182],\n",
       " [2998, 38, 259, 6, 251, 290, False, 0.5, 0.5190311418685121],\n",
       " [2998, 38, 13, 149, 286, 247, True, 0.5543478260869565, 0.5741935483870968],\n",
       " [2998, 38, 258, 24, 232, 383, False, 0.4935064935064935, 0.5517241379310345],\n",
       " [2998, 38, 35, 30, 259, 383, False, 0.4101694915254237, 0.3952802359882006],\n",
       " [2998, 38, 31, 117, 328, 325, True, 0.5589225589225589, 0.5275862068965518],\n",
       " [2998, 38, 33, 52, 305, 247, True, 0.5076923076923077, 0.7738853503184714],\n",
       " [2998,\n",
       "  38,\n",
       "  320,\n",
       "  37,\n",
       "  321,\n",
       "  375,\n",
       "  False,\n",
       "  0.37538461538461537,\n",
       "  0.43934426229508194],\n",
       " [2998, 38, 39, 223, 259, 232, True, 0.7246376811594203, 0.27631578947368424],\n",
       " [2998, 38, 329, 40, 255, 317, False, 0.6993464052287581, 0.31746031746031744],\n",
       " [2998, 38, 48, 154, 414, 398, True, 0.4798657718120805, 0.5701219512195121],\n",
       " [2998, 38, 64, 357, 294, 263, True, 0.4984025559105431, 0.5178571428571429],\n",
       " [2998, 38, 334, 78, 251, 317, False, 0.5924764890282131, 0.50814332247557],\n",
       " [2998, 38, 133, 82, 313, 348, False, 0.56, 0.6040955631399317],\n",
       " [2998, 38, 124, 96, 232, 286, False, 0.2833333333333333, 0.2631578947368421],\n",
       " [2998, 38, 139, 99, 352, 387, False, 0.46283783783783783, 0.4477124183006536],\n",
       " [2998,\n",
       "  38,\n",
       "  173,\n",
       "  108,\n",
       "  247,\n",
       "  325,\n",
       "  False,\n",
       "  0.3717105263157895,\n",
       "  0.46105919003115264],\n",
       " [2998, 38, 300, 110, 414, 464, False, 0.6363636363636364, 0.4732142857142857],\n",
       " [2998, 38, 134, 342, 367, 224, True, 0.5993975903614458, 0.6360424028268551],\n",
       " [2998, 38, 135, 66, 356, 290, True, 0.5606060606060606, 0.3575757575757576],\n",
       " [2998, 38, 142, 14, 352, 309, True, 0.8128834355828221, 0.5033333333333333],\n",
       " [2998, 38, 164, 62, 363, 313, True, 0.38738738738738737, 0.5504587155963303],\n",
       " [2998, 38, 168, 171, 445, 232, True, 0.6480938416422287, 0.7133550488599348],\n",
       " [2998,\n",
       "  38,\n",
       "  249,\n",
       "  177,\n",
       "  259,\n",
       "  290,\n",
       "  False,\n",
       "  0.4440677966101695,\n",
       "  0.29190751445086704],\n",
       " [2998, 38, 178, 244, 344, 317, True, 0.594059405940594, 0.4401294498381877],\n",
       " [2998,\n",
       "  38,\n",
       "  17,\n",
       "  183,\n",
       "  267,\n",
       "  270,\n",
       "  False,\n",
       "  0.47342995169082125,\n",
       "  0.45896656534954405],\n",
       " [2998, 38, 184, 106, 208, 197, True, 0.4358974358974359, 0.42765273311897106],\n",
       " [2998, 38, 185, 263, 278, 197, True, 0.5752508361204013, 0.6877076411960132],\n",
       " [2998, 38, 210, 283, 305, 228, True, 0.5169230769230769, 0.5902777777777778],\n",
       " [2998, 38, 226, 175, 363, 236, True, 0.6363636363636364, 0.4166666666666667],\n",
       " [2998, 38, 228, 276, 236, 232, True, 0.6580645161290323, 0.5046728971962616],\n",
       " [2998, 38, 238, 229, 243, 286, False, 0.6893491124260355, 0.3117283950617284],\n",
       " [2998, 38, 209, 233, 224, 305, False, 0.5464684014869888, 0.6134185303514377],\n",
       " [2998, 38, 205, 234, 239, 301, False, 0.5673076923076923, 0.4169381107491857],\n",
       " [2998, 38, 239, 86, 398, 344, True, 0.3854748603351955, 0.6528662420382165],\n",
       " [2998, 38, 100, 248, 216, 239, False, 0.3356643356643357, 0.4702194357366771],\n",
       " [2998, 38, 278, 8, 402, 325, True, 0.41214057507987223, 0.6466666666666666],\n",
       " [2998, 38, 293, 65, 301, 274, True, 0.7692307692307693, 0.3382352941176471],\n",
       " [2998, 38, 295, 309, 363, 313, True, 0.47384615384615386, 0.3880597014925373],\n",
       " [2998, 38, 247, 333, 321, 375, False, 0.4529616724738676, 0.3644578313253012],\n",
       " [2998, 38, 321, 341, 328, 387, False, 0.4189189189189189, 0.5953177257525084],\n",
       " [2998, 38, 347, 282, 232, 228, True, 0.515625, 0.5204081632653061],\n",
       " [2998, 38, 351, 111, 305, 297, True, 0.5765765765765766, 0.20699708454810495],\n",
       " [2998, 38, 353, 305, 282, 174, True, 0.5623003194888179, 0.5207100591715976],\n",
       " [2998, 38, 206, 363, 286, 294, False, 0.2783171521035599, 0.5714285714285714],\n",
       " [2998, 40, 299, 4, 328, 406, False, 0.4883720930232558, 0.35919540229885055],\n",
       " [2998, 40, 74, 291, 398, 328, True, 0.5391566265060241, 0.6341463414634146],\n",
       " [2998, 40, 150, 120, 336, 375, False, 0.4189189189189189, 0.436950146627566],\n",
       " [2998, 40, 129, 127, 278, 247, True, 0.5185185185185185, 0.49523809523809526],\n",
       " [2998, 40, 161, 192, 371, 251, True, 0.5495495495495496, 0.5033112582781457],\n",
       " [2998, 40, 16, 177, 274, 332, False, 0.6470588235294118, 0.29190751445086704],\n",
       " [2998, 40, 178, 13, 267, 143, True, 0.594059405940594, 0.44324324324324327],\n",
       " [2998, 40, 187, 322, 336, 259, True, 0.41114982578397213, 0.5686900958466453],\n",
       " [2998, 40, 208, 281, 336, 309, True, 0.6059602649006622, 0.6423611111111112],\n",
       " [2998,\n",
       "  40,\n",
       "  122,\n",
       "  214,\n",
       "  251,\n",
       "  263,\n",
       "  False,\n",
       "  0.4722222222222222,\n",
       "  0.22285714285714286],\n",
       " [2998,\n",
       "  40,\n",
       "  70,\n",
       "  219,\n",
       "  309,\n",
       "  332,\n",
       "  False,\n",
       "  0.19387755102040816,\n",
       "  0.49823321554770317],\n",
       " [2998, 40, 110, 229, 274, 301, False, 0.5253731343283582, 0.3117283950617284],\n",
       " [2998, 40, 236, 38, 344, 239, True, 0.45714285714285713, 0.6],\n",
       " [2998, 40, 238, 300, 352, 336, True, 0.6893491124260355, 0.3626062322946176],\n",
       " [2998, 40, 244, 149, 336, 294, True, 0.5584415584415584, 0.5741935483870968],\n",
       " [2998, 40, 256, 343, 282, 247, True, 0.5783132530120482, 0.38055555555555554],\n",
       " [2998, 40, 275, 279, 290, 313, False, 0.6435643564356436, 0.4967105263157895],\n",
       " [2998, 40, 303, 207, 224, 216, True, 0.5352564102564102, 0.31761006289308175],\n",
       " [2998, 40, 241, 308, 208, 464, False, 0.2682119205298013, 0.5358255451713395],\n",
       " [2998, 40, 312, 190, 359, 239, True, 0.6195652173913043, 0.5777777777777777],\n",
       " [2998, 42, 196, 166, 274, 294, False, 0.3829113924050633, 0.3323262839879154],\n",
       " [2998, 44, 73, 12, 263, 325, False, 0.5706051873198847, 0.25903614457831325],\n",
       " [2998, 44, 54, 19, 228, 205, True, 0.2909090909090909, 0.7454545454545455],\n",
       " [2998, 44, 56, 269, 340, 309, True, 0.44299674267100975, 0.6333333333333333],\n",
       " [2998, 44, 63, 363, 305, 212, True, 0.7087378640776699, 0.5714285714285714],\n",
       " [2998, 44, 74, 283, 309, 259, True, 0.5391566265060241, 0.5902777777777778],\n",
       " [2998, 44, 172, 77, 344, 356, False, 0.6938775510204082, 0.5540983606557377],\n",
       " [2998, 44, 288, 80, 247, 270, False, 0.8105263157894737, 0.3573667711598746],\n",
       " [2998, 44, 85, 57, 294, 224, True, 0.3924914675767918, 0.5857142857142857],\n",
       " [2998, 44, 26, 97, 305, 363, False, 0.3811074918566775, 0.6559485530546624],\n",
       " [2998, 44, 273, 100, 267, 348, False, 0.564935064935065, 0.6643356643356644],\n",
       " [2998, 44, 101, 218, 325, 270, True, 0.42528735632183906, 0.5290519877675841],\n",
       " [2998, 44, 111, 24, 297, 290, True, 0.7923976608187134, 0.5517241379310345],\n",
       " [2998, 44, 118, 186, 274, 212, True, 0.5290697674418605, 0.5787545787545788],\n",
       " [2998, 44, 43, 147, 294, 383, False, 0.5918367346938775, 0.47783251231527096],\n",
       " [2998, 44, 265, 169, 247, 328, False, 0.5, 0.3829787234042553],\n",
       " [2998, 44, 174, 163, 239, 220, True, 0.5789473684210527, 0.5344262295081967],\n",
       " [2998,\n",
       "  44,\n",
       "  241,\n",
       "  180,\n",
       "  201,\n",
       "  375,\n",
       "  False,\n",
       "  0.2682119205298013,\n",
       "  0.38333333333333336],\n",
       " [2998, 44, 182, 211, 340, 224, True, 0.39100346020761245, 0.6678832116788321],\n",
       " [2998, 44, 268, 185, 181, 344, False, 0.391304347826087, 0.42333333333333334],\n",
       " [2998, 44, 205, 158, 464, 448, True, 0.5673076923076923, 0.6805555555555556],\n",
       " [2998, 44, 209, 125, 282, 216, True, 0.5464684014869888, 0.6033333333333334],\n",
       " [2998, 44, 69, 219, 274, 286, False, 0.4253968253968254, 0.49823321554770317],\n",
       " [2998, 44, 339, 250, 197, 325, False, 0.5, 0.4117647058823529],\n",
       " [2998,\n",
       "  44,\n",
       "  45,\n",
       "  251,\n",
       "  278,\n",
       "  294,\n",
       "  False,\n",
       "  0.44518272425249167,\n",
       "  0.43962848297213625],\n",
       " [2998,\n",
       "  44,\n",
       "  260,\n",
       "  264,\n",
       "  205,\n",
       "  224,\n",
       "  False,\n",
       "  0.45714285714285713,\n",
       "  0.48464163822525597],\n",
       " [2998, 44, 323, 285, 220, 290, False, 0.5540983606557377, 0.4804804804804805],\n",
       " [2998, 44, 295, 135, 205, 201, True, 0.47384615384615386, 0.4380664652567976],\n",
       " [2998, 44, 20, 312, 286, 340, False, 0.42857142857142855, 0.3783783783783784],\n",
       " [2998, 44, 316, 44, 317, 286, True, 0.5514950166112956, 0.6510416666666666],\n",
       " [2998, 44, 179, 318, 336, 371, False, 0.6071428571428571, 0.5062111801242236],\n",
       " [2998,\n",
       "  44,\n",
       "  262,\n",
       "  326,\n",
       "  313,\n",
       "  437,\n",
       "  False,\n",
       "  0.45482866043613707,\n",
       "  0.5347222222222222],\n",
       " [2998, 44, 328, 263, 290, 220, True, 0.6199376947040498, 0.6877076411960132],\n",
       " [2998, 44, 338, 235, 336, 224, True, 0.5502958579881657, 0.39144736842105265],\n",
       " [2998,\n",
       "  44,\n",
       "  340,\n",
       "  351,\n",
       "  251,\n",
       "  321,\n",
       "  False,\n",
       "  0.3333333333333333,\n",
       "  0.41964285714285715],\n",
       " [2998, 46, 190, 3, 251, 309, False, 0.42356687898089174, 0.49498327759197325],\n",
       " [2998, 46, 118, 12, 274, 328, False, 0.5290697674418605, 0.25903614457831325],\n",
       " [2998, 46, 17, 14, 251, 232, True, 0.47342995169082125, 0.5033333333333333],\n",
       " [2998, 46, 19, 340, 228, 205, True, 0.2545454545454545, 0.6666666666666666],\n",
       " [2998, 46, 218, 24, 263, 309, False, 0.4723926380368098, 0.5517241379310345],\n",
       " [2998, 46, 30, 34, 297, 205, True, 0.6035502958579881, 0.9285714285714286],\n",
       " [2998, 46, 51, 33, 251, 255, False, 0.498371335504886, 0.4938650306748466],\n",
       " [2998, 46, 339, 43, 228, 263, False, 0.5, 0.40988372093023256],\n",
       " [2998, 46, 175, 53, 239, 317, False, 0.5833333333333334, 0.2875],\n",
       " [2998, 46, 55, 187, 441, 267, True, 0.5608695652173913, 0.5902777777777778],\n",
       " [2998, 46, 74, 316, 356, 305, True, 0.5391566265060241, 0.4470198675496689],\n",
       " [2998, 46, 32, 78, 274, 286, False, 0.4983922829581994, 0.50814332247557],\n",
       " [2998, 46, 81, 117, 456, 251, True, 0.8737864077669902, 0.5275862068965518],\n",
       " [2998, 46, 83, 202, 325, 290, True, 0.3993055555555556, 0.675],\n",
       " [2998, 46, 174, 84, 236, 255, False, 0.5789473684210527, 0.5365853658536586],\n",
       " [2998, 46, 11, 87, 294, 305, False, 0.4983277591973244, 0.5986394557823129],\n",
       " [2998,\n",
       "  46,\n",
       "  101,\n",
       "  111,\n",
       "  297,\n",
       "  294,\n",
       "  True,\n",
       "  0.42528735632183906,\n",
       "  0.20699708454810495],\n",
       " [2998, 46, 102, 173, 328, 286, True, 0.3678571428571429, 0.6295081967213115],\n",
       " [2998,\n",
       "  46,\n",
       "  184,\n",
       "  103,\n",
       "  197,\n",
       "  255,\n",
       "  False,\n",
       "  0.4358974358974359,\n",
       "  0.44011976047904194],\n",
       " [2998, 46, 104, 299, 398, 332, True, 0.40522875816993464, 0.5132450331125827],\n",
       " [2998, 46, 116, 71, 212, 205, True, 0.39090909090909093, 0.6847457627118644],\n",
       " [2998, 46, 120, 164, 313, 305, True, 0.5630498533724341, 0.6160714285714286],\n",
       " [2998,\n",
       "  46,\n",
       "  217,\n",
       "  122,\n",
       "  336,\n",
       "  344,\n",
       "  False,\n",
       "  0.39603960396039606,\n",
       "  0.5261538461538462],\n",
       " [2998, 46, 57, 125, 297, 321, False, 0.4157706093189964, 0.6033333333333334],\n",
       " [2998, 46, 319, 128, 270, 367, False, 0.4166666666666667, 0.3498452012383901],\n",
       " [2998, 46, 39, 131, 282, 375, False, 0.7246376811594203, 0.38484848484848483],\n",
       " [2998, 46, 139, 154, 375, 317, True, 0.46283783783783783, 0.5701219512195121],\n",
       " [2998, 46, 151, 171, 348, 251, True, 0.42207792207792205, 0.7133550488599348],\n",
       " [2998, 46, 168, 10, 359, 263, True, 0.6480938416422287, 0.5372670807453416],\n",
       " [2998,\n",
       "  46,\n",
       "  233,\n",
       "  169,\n",
       "  251,\n",
       "  286,\n",
       "  False,\n",
       "  0.38461538461538464,\n",
       "  0.3829787234042553],\n",
       " [2998,\n",
       "  46,\n",
       "  124,\n",
       "  178,\n",
       "  208,\n",
       "  367,\n",
       "  False,\n",
       "  0.2833333333333333,\n",
       "  0.40460526315789475],\n",
       " [2998, 46, 179, 241, 390, 193, True, 0.6071428571428571, 0.7326732673267327],\n",
       " [2998, 46, 180, 318, 332, 297, True, 0.6150627615062761, 0.5062111801242236],\n",
       " [2998, 46, 181, 301, 297, 181, True, 0.6574074074074074, 0.5290519877675841],\n",
       " [2998, 46, 182, 56, 282, 259, True, 0.39100346020761245, 0.5584415584415584],\n",
       " [2998, 46, 185, 326, 282, 263, True, 0.5752508361204013, 0.5347222222222222],\n",
       " [2998, 46, 186, 73, 344, 325, True, 0.4227941176470588, 0.43103448275862066],\n",
       " [2998, 46, 201, 341, 390, 305, True, 0.5435435435435435, 0.5953177257525084],\n",
       " [2998, 46, 281, 204, 390, 410, False, 0.3576388888888889, 0.4329268292682927],\n",
       " [2998, 46, 208, 207, 309, 282, True, 0.6059602649006622, 0.31761006289308175],\n",
       " [2998, 46, 209, 85, 294, 232, True, 0.5464684014869888, 0.6054421768707483],\n",
       " [2998,\n",
       "  46,\n",
       "  306,\n",
       "  214,\n",
       "  340,\n",
       "  379,\n",
       "  False,\n",
       "  0.39490445859872614,\n",
       "  0.22285714285714286],\n",
       " [2998, 46, 221, 62, 301, 232, True, 0.4169184290030212, 0.5504587155963303],\n",
       " [2998, 46, 364, 225, 239, 278, False, 0.3310104529616725, 0.4318181818181818],\n",
       " [2998, 46, 226, 52, 448, 170, True, 0.6363636363636364, 0.7738853503184714],\n",
       " [2998, 46, 29, 237, 185, 270, False, 0.5509554140127388, 0.5072463768115942],\n",
       " [2998,\n",
       "  46,\n",
       "  148,\n",
       "  243,\n",
       "  189,\n",
       "  278,\n",
       "  False,\n",
       "  0.38461538461538464,\n",
       "  0.3853820598006645],\n",
       " [2998, 46, 247, 188, 367, 232, True, 0.4529616724738676, 0.6043613707165109],\n",
       " [2998, 46, 248, 133, 313, 294, True, 0.5283018867924528, 0.4375],\n",
       " [2998, 46, 250, 147, 301, 243, True, 0.5869565217391305, 0.47783251231527096],\n",
       " [2998, 46, 347, 253, 270, 352, False, 0.515625, 0.5876288659793815],\n",
       " [2998,\n",
       "  46,\n",
       "  357,\n",
       "  254,\n",
       "  216,\n",
       "  286,\n",
       "  False,\n",
       "  0.48214285714285715,\n",
       "  0.5066666666666667],\n",
       " [2998,\n",
       "  46,\n",
       "  193,\n",
       "  256,\n",
       "  379,\n",
       "  421,\n",
       "  False,\n",
       "  0.6869009584664537,\n",
       "  0.42042042042042044],\n",
       " [2998, 46, 259, 2, 197, 170, True, 0.5, 0.6185567010309279],\n",
       " [2998, 46, 268, 262, 301, 325, False, 0.391304347826087, 0.5451713395638629],\n",
       " [2998, 46, 269, 211, 294, 282, True, 0.36789297658862874, 0.6678832116788321],\n",
       " [2998, 46, 275, 138, 352, 325, True, 0.6435643564356436, 0.5462962962962963],\n",
       " [2998, 46, 286, 276, 259, 313, False, 0.5953079178885631, 0.5046728971962616],\n",
       " [2998, 46, 230, 278, 274, 348, False, 0.6088235294117647, 0.5859872611464968],\n",
       " [2998, 46, 48, 282, 301, 317, False, 0.4798657718120805, 0.5204081632653061],\n",
       " [2998, 46, 44, 283, 294, 301, False, 0.3507853403141361, 0.5902777777777778],\n",
       " [2998, 46, 284, 38, 325, 212, True, 0.34448160535117056, 0.6],\n",
       " [2998, 46, 285, 80, 313, 236, True, 0.5180722891566265, 0.3573667711598746],\n",
       " [2998, 46, 290, 60, 274, 224, True, 0.6875, 0.46261682242990654],\n",
       " [2998, 46, 293, 321, 321, 263, True, 0.7692307692307693, 0.5824915824915825],\n",
       " [2998,\n",
       "  46,\n",
       "  295,\n",
       "  297,\n",
       "  282,\n",
       "  228,\n",
       "  True,\n",
       "  0.47384615384615386,\n",
       "  0.33727810650887574],\n",
       " [2998, 46, 303, 310, 274, 243, True, 0.5352564102564102, 0.7015503875968992],\n",
       " [2998, 46, 314, 261, 305, 247, True, 0.43137254901960786, 0.4854368932038835],\n",
       " [2998, 46, 153, 317, 220, 263, False, 0.5131578947368421, 0.3119266055045872],\n",
       " [2998, 46, 323, 288, 313, 239, True, 0.5540983606557377, 0.1875],\n",
       " [2998, 46, 324, 161, 294, 212, True, 0.6696969696969697, 0.4491017964071856],\n",
       " [2998, 46, 325, 70, 414, 363, True, 0.540453074433657, 0.8067796610169492],\n",
       " [2998,\n",
       "  46,\n",
       "  274,\n",
       "  335,\n",
       "  212,\n",
       "  259,\n",
       "  False,\n",
       "  0.45874587458745875,\n",
       "  0.3665158371040724],\n",
       " [2998, 46, 336, 322, 278, 201, True, 0.6139817629179332, 0.5686900958466453],\n",
       " [2998, 46, 121, 344, 251, 301, False, 0.5247813411078717, 0.4420289855072464],\n",
       " [2998, 46, 348, 93, 352, 239, True, 0.6056338028169014, 0.4911242603550296],\n",
       " [2998, 46, 54, 351, 286, 417, False, 0.2909090909090909, 0.41964285714285715],\n",
       " [2998, 46, 353, 311, 255, 178, True, 0.5623003194888179, 0.5352564102564102],\n",
       " [2998, 46, 355, 75, 301, 263, True, 0.5220125786163522, 0.603225806451613],\n",
       " [2998, 46, 356, 198, 317, 297, True, 0.3821656050955414, 0.56],\n",
       " [2998, 46, 358, 239, 371, 336, True, 0.6595092024539877, 0.6111111111111112],\n",
       " [2998, 46, 361, 258, 328, 270, True, 0.5342465753424658, 0.5080906148867314],\n",
       " [2998, 46, 362, 59, 363, 251, True, 0.7409638554216867, 0.5691823899371069],\n",
       " [2998, 47, 338, 4, 267, 309, False, 0.5502958579881657, 0.35919540229885055],\n",
       " [2998, 47, 35, 244, 274, 267, True, 0.4101694915254237, 0.4401294498381877],\n",
       " [2998, 47, 108, 37, 359, 348, True, 0.5375, 0.43934426229508194],\n",
       " [2998, 47, 135, 163, 270, 243, True, 0.5606060606060606, 0.5344262295081967],\n",
       " [2998, 47, 174, 297, 278, 232, True, 0.5789473684210527, 0.33727810650887574],\n",
       " [2998, 47, 214, 65, 421, 255, True, 0.7771428571428571, 0.3382352941176471],\n",
       " [2998, 47, 233, 85, 336, 278, True, 0.38461538461538464, 0.6054421768707483],\n",
       " [2998, 47, 57, 265, 239, 267, False, 0.4157706093189964, 0.5016077170418006],\n",
       " [2998, 47, 295, 84, 212, 185, True, 0.47384615384615386, 0.5365853658536586],\n",
       " [2998, 49, 217, 8, 379, 394, False, 0.39603960396039606, 0.6466666666666666],\n",
       " [2998, 49, 6, 16, 309, 371, False, 0.4791666666666667, 0.35185185185185186],\n",
       " [2998, 49, 334, 24, 263, 297, False, 0.5924764890282131, 0.5517241379310345],\n",
       " [2998, 49, 30, 206, 476, 301, True, 0.6035502958579881, 0.7225806451612903],\n",
       " [2998, 49, 11, 50, 263, 321, False, 0.4983277591973244, 0.414985590778098],\n",
       " [2998,\n",
       "  49,\n",
       "  314,\n",
       "  60,\n",
       "  270,\n",
       "  282,\n",
       "  False,\n",
       "  0.43137254901960786,\n",
       "  0.46261682242990654],\n",
       " [2998, 49, 348, 63, 290, 325, False, 0.6056338028169014, 0.28846153846153844],\n",
       " [2998, 49, 61, 66, 216, 239, False, 0.5050505050505051, 0.3575757575757576],\n",
       " [2998, 49, 92, 322, 282, 228, True, 0.4146341463414634, 0.5686900958466453],\n",
       " [2998, 49, 96, 139, 309, 297, True, 0.7340425531914894, 0.5353535353535354],\n",
       " [2998, 49, 133, 230, 332, 274, True, 0.56, 0.39296187683284456],\n",
       " [2998, 49, 141, 171, 325, 220, True, 0.4937106918238994, 0.7133550488599348],\n",
       " [2998, 49, 156, 268, 383, 290, True, 0.48562300319488816, 0.6101083032490975],\n",
       " [2998, 49, 129, 160, 224, 274, False, 0.5185185185185185, 0.5830721003134797],\n",
       " [2998, 49, 169, 209, 263, 216, True, 0.6170212765957447, 0.45185185185185184],\n",
       " [2998, 49, 78, 176, 286, 387, False, 0.49019607843137253, 0.4511627906976744],\n",
       " [2998,\n",
       "  49,\n",
       "  364,\n",
       "  178,\n",
       "  228,\n",
       "  379,\n",
       "  False,\n",
       "  0.3310104529616725,\n",
       "  0.40460526315789475],\n",
       " [2998, 49, 58, 199, 212, 274, False, 0.7045454545454546, 0.6019417475728155],\n",
       " [2998, 49, 201, 238, 301, 297, True, 0.5435435435435435, 0.3106508875739645],\n",
       " [2998, 49, 54, 204, 236, 325, False, 0.2909090909090909, 0.4329268292682927],\n",
       " [2998, 49, 211, 2, 290, 286, True, 0.32967032967032966, 0.6185567010309279],\n",
       " [2998, 49, 335, 221, 313, 321, False, 0.6318181818181818, 0.5813253012048193],\n",
       " [2998, 49, 112, 222, 282, 476, False, 0.2551440329218107, 0.5654952076677316],\n",
       " [2998, 49, 10, 236, 251, 297, False, 0.46417445482866043, 0.5428571428571428],\n",
       " [2998, 49, 245, 132, 313, 251, True, 0.6314363143631436, 0.531055900621118],\n",
       " [2998, 49, 249, 241, 371, 232, True, 0.4440677966101695, 0.7326732673267327],\n",
       " [2998, 49, 167, 252, 236, 328, False, 0.5016181229773463, 0.5118343195266272],\n",
       " [2998, 49, 264, 70, 390, 251, True, 0.515358361774744, 0.8067796610169492],\n",
       " [2998, 49, 269, 310, 328, 216, True, 0.36789297658862874, 0.7015503875968992],\n",
       " [2998, 49, 165, 273, 243, 309, False, 0.4391691394658754, 0.4336569579288026],\n",
       " [2998, 49, 102, 276, 189, 267, False, 0.3678571428571429, 0.5046728971962616],\n",
       " [2998, 49, 305, 190, 239, 170, True, 0.47928994082840237, 0.5777777777777777],\n",
       " [2998, 49, 316, 154, 437, 325, True, 0.5514950166112956, 0.5701219512195121],\n",
       " [2998, 49, 287, 325, 232, 294, False, 0.5512048192771084, 0.459546925566343],\n",
       " [2998, 49, 343, 127, 309, 301, True, 0.6183844011142061, 0.49523809523809526],\n",
       " [2998,\n",
       "  49,\n",
       "  247,\n",
       "  352,\n",
       "  189,\n",
       "  321,\n",
       "  False,\n",
       "  0.4529616724738676,\n",
       "  0.41776315789473684],\n",
       " [2998,\n",
       "  49,\n",
       "  342,\n",
       "  354,\n",
       "  325,\n",
       "  379,\n",
       "  False,\n",
       "  0.36524822695035464,\n",
       "  0.5579937304075235],\n",
       " [2998, 49, 72, 356, 267, 270, False, 0.6510067114093959, 0.6190476190476191],\n",
       " [2998, 49, 362, 259, 290, 228, True, 0.7409638554216867, 0.49828178694158076],\n",
       " [2998, 51, 51, 4, 236, 294, False, 0.498371335504886, 0.35919540229885055],\n",
       " [2998, 51, 13, 126, 267, 228, True, 0.5543478260869565, 0.6360424028268551],\n",
       " [2998, 51, 23, 180, 313, 201, True, 0.5360501567398119, 0.38333333333333336],\n",
       " [2998, 51, 188, 34, 255, 309, False, 0.396875, 0.9285714285714286],\n",
       " [2998, 51, 39, 68, 387, 321, True, 0.7246376811594203, 0.4659090909090909],\n",
       " [2998, 51, 53, 56, 352, 216, True, 0.7088607594936709, 0.5584415584415584],\n",
       " [2998, 51, 91, 22, 379, 301, True, 0.5125786163522013, 0.5109034267912772],\n",
       " [2998,\n",
       "  51,\n",
       "  116,\n",
       "  103,\n",
       "  297,\n",
       "  313,\n",
       "  False,\n",
       "  0.39090909090909093,\n",
       "  0.44011976047904194],\n",
       " [2998, 51, 110, 337, 309, 228, True, 0.5253731343283582, 0.36712328767123287],\n",
       " [2998, 51, 122, 17, 278, 208, True, 0.4722222222222222, 0.5240384615384616],\n",
       " [2998,\n",
       "  51,\n",
       "  298,\n",
       "  128,\n",
       "  216,\n",
       "  301,\n",
       "  False,\n",
       "  0.37337662337662336,\n",
       "  0.3498452012383901],\n",
       " [2998, 51, 131, 223, 301, 178, True, 0.6139817629179332, 0.27631578947368424],\n",
       " [2998, 51, 134, 79, 321, 216, True, 0.5993975903614458, 0.6203389830508474],\n",
       " [2998, 51, 145, 3, 212, 205, True, 0.6211180124223602, 0.49498327759197325],\n",
       " [2998, 51, 158, 234, 371, 309, True, 0.3205574912891986, 0.4169381107491857],\n",
       " [2998, 51, 64, 163, 255, 267, False, 0.4984025559105431, 0.5344262295081967],\n",
       " [2998, 51, 164, 159, 305, 290, True, 0.38738738738738737, 0.6107784431137725],\n",
       " [2998, 51, 193, 172, 208, 301, False, 0.6869009584664537, 0.3081395348837209],\n",
       " [2998, 51, 97, 181, 236, 332, False, 0.3440514469453376, 0.3415384615384615],\n",
       " [2998, 51, 19, 184, 143, 247, False, 0.2545454545454545, 0.5654952076677316],\n",
       " [2998, 51, 205, 237, 278, 359, False, 0.5673076923076923, 0.5072463768115942],\n",
       " [2998, 51, 243, 253, 158, 178, False, 0.6133333333333333, 0.5876288659793815],\n",
       " [2998, 51, 262, 43, 309, 282, True, 0.45482866043613707, 0.40988372093023256],\n",
       " [2998, 51, 358, 274, 247, 255, False, 0.6595092024539877, 0.5427631578947368],\n",
       " [2998, 51, 318, 279, 251, 321, False, 0.4953271028037383, 0.4967105263157895],\n",
       " [2998, 51, 286, 80, 363, 305, True, 0.5953079178885631, 0.3573667711598746],\n",
       " [2998, 51, 99, 293, 274, 344, False, 0.5508196721311476, 0.23076923076923078],\n",
       " [2998, 51, 296, 235, 267, 251, True, 0.6867469879518072, 0.39144736842105265],\n",
       " [2998, 51, 306, 150, 383, 375, True, 0.39490445859872614, 0.5824915824915825],\n",
       " [2998,\n",
       "  51,\n",
       "  329,\n",
       "  328,\n",
       "  239,\n",
       "  274,\n",
       "  False,\n",
       "  0.6993464052287581,\n",
       "  0.37888198757763975],\n",
       " [2998, 51, 331, 208, 301, 274, True, 0.569078947368421, 0.3927392739273927],\n",
       " [2998, 51, 360, 32, 317, 294, True, 0.5133928571428571, 0.5032051282051282],\n",
       " [2998,\n",
       "  51,\n",
       "  148,\n",
       "  363,\n",
       "  294,\n",
       "  321,\n",
       "  False,\n",
       "  0.38461538461538464,\n",
       "  0.5714285714285714],\n",
       " [2998, 53, 112, 14, 259, 321, False, 0.2551440329218107, 0.5033333333333333],\n",
       " [2998, 53, 26, 16, 178, 495, False, 0.3811074918566775, 0.35185185185185186],\n",
       " [2998, 53, 301, 20, 321, 332, False, 0.4709480122324159, 0.5652173913043478],\n",
       " [2998, 53, 191, 37, 259, 375, False, 0.4592833876221498, 0.43934426229508194],\n",
       " [2998, 53, 52, 41, 290, 356, False, 0.2268370607028754, 0.6610738255033557],\n",
       " [2998, 53, 202, 77, 297, 387, False, 0.3291139240506329, 0.5540983606557377],\n",
       " [2998, 53, 48, 92, 352, 402, False, 0.4798657718120805, 0.5866261398176292],\n",
       " [2998, 53, 96, 49, 220, 201, True, 0.7340425531914894, 0.6440677966101694],\n",
       " [2998, 53, 120, 100, 247, 317, False, 0.5630498533724341, 0.6643356643356644],\n",
       " [2998, 53, 121, 117, 387, 290, True, 0.5247813411078717, 0.5275862068965518],\n",
       " [2998,\n",
       "  53,\n",
       "  217,\n",
       "  138,\n",
       "  309,\n",
       "  313,\n",
       "  False,\n",
       "  0.39603960396039606,\n",
       "  0.5462962962962963],\n",
       " [2998, 53, 146, 169, 348, 267, True, 0.6888888888888889, 0.3829787234042553],\n",
       " [2998, 53, 69, 153, 259, 294, False, 0.4253968253968254, 0.4868421052631579],\n",
       " [2998, 53, 31, 154, 321, 332, False, 0.5589225589225589, 0.5701219512195121],\n",
       " [2998, 53, 168, 244, 294, 255, True, 0.6480938416422287, 0.4401294498381877],\n",
       " [2998,\n",
       "  53,\n",
       "  204,\n",
       "  177,\n",
       "  301,\n",
       "  390,\n",
       "  False,\n",
       "  0.5657492354740061,\n",
       "  0.29190751445086704],\n",
       " [2998, 53, 182, 310, 356, 309, True, 0.39100346020761245, 0.7015503875968992],\n",
       " [2998, 53, 185, 239, 379, 263, True, 0.5752508361204013, 0.6111111111111112],\n",
       " [2998, 53, 71, 206, 185, 216, False, 0.3129251700680272, 0.7225806451612903],\n",
       " [2998, 53, 271, 214, 208, 321, False, 0.560126582278481, 0.22285714285714286],\n",
       " [2998, 53, 124, 218, 259, 274, False, 0.2833333333333333, 0.5290519877675841],\n",
       " [2998, 53, 225, 226, 239, 301, False, 0.5681818181818182, 0.3625],\n",
       " [2998, 53, 229, 209, 243, 212, True, 0.6873065015479877, 0.45185185185185184],\n",
       " [2998, 53, 238, 284, 325, 263, True, 0.6893491124260355, 0.6555183946488294],\n",
       " [2998, 53, 35, 248, 224, 340, False, 0.4101694915254237, 0.4702194357366771],\n",
       " [2998, 53, 258, 249, 197, 301, False, 0.4935064935064935, 0.5540540540540541],\n",
       " [2998, 53, 272, 260, 270, 181, True, 0.5324232081911263, 0.5450236966824644],\n",
       " [2998, 53, 210, 282, 247, 305, False, 0.5169230769230769, 0.5204081632653061],\n",
       " [2998, 53, 221, 308, 305, 321, False, 0.4169184290030212, 0.5358255451713395],\n",
       " [2998, 53, 312, 241, 425, 189, True, 0.6195652173913043, 0.7326732673267327],\n",
       " [2998, 53, 322, 356, 305, 282, True, 0.4326923076923077, 0.6190476190476191],\n",
       " [2998, 53, 111, 325, 232, 297, False, 0.7923976608187134, 0.459546925566343],\n",
       " [2998, 53, 250, 333, 270, 282, False, 0.5869565217391305, 0.3644578313253012],\n",
       " [2998, 53, 305, 334, 224, 236, False, 0.47928994082840237, 0.409375],\n",
       " [2998, 53, 106, 339, 247, 294, False, 0.5709677419354838, 0.5],\n",
       " [2998, 53, 247, 340, 267, 305, False, 0.4529616724738676, 0.6666666666666666],\n",
       " [2998, 53, 343, 84, 247, 239, True, 0.6183844011142061, 0.5365853658536586],\n",
       " [2998, 53, 362, 196, 297, 286, True, 0.7409638554216867, 0.6182965299684543],\n",
       " [2998, 54, 298, 8, 286, 325, False, 0.37337662337662336, 0.6466666666666666],\n",
       " [2998, 54, 13, 327, 336, 239, True, 0.5543478260869565, 0.519163763066202],\n",
       " [2998, 54, 129, 39, 328, 359, False, 0.5185185185185185, 0.2774566473988439],\n",
       " [2998, 54, 40, 309, 394, 332, True, 0.6812749003984063, 0.3880597014925373],\n",
       " [2998, 54, 54, 58, 232, 243, False, 0.2909090909090909, 0.29213483146067415],\n",
       " [2998, 54, 10, 64, 336, 356, False, 0.46417445482866043, 0.5],\n",
       " [2998, 54, 74, 75, 367, 383, False, 0.5391566265060241, 0.603225806451613],\n",
       " [2998, 54, 78, 98, 336, 267, True, 0.49019607843137253, 0.5975232198142415],\n",
       " [2998, 54, 81, 285, 352, 313, True, 0.8737864077669902, 0.4804804804804805],\n",
       " [2998, 54, 68, 83, 220, 224, False, 0.5287356321839081, 0.6006944444444444],\n",
       " [2998, 54, 223, 157, 313, 325, False, 0.72, 0.29573170731707316],\n",
       " [2998, 54, 179, 170, 356, 270, True, 0.6071428571428571, 0.5507246376811594],\n",
       " [2998, 54, 232, 101, 274, 243, True, 0.5520504731861199, 0.5795454545454546],\n",
       " [2998, 54, 347, 251, 328, 383, False, 0.515625, 0.43962848297213625],\n",
       " [2998, 54, 264, 288, 297, 216, True, 0.515358361774744, 0.1875],\n",
       " [2998, 54, 276, 357, 263, 216, True, 0.4953271028037383, 0.5178571428571429],\n",
       " [2998,\n",
       "  54,\n",
       "  269,\n",
       "  281,\n",
       "  239,\n",
       "  379,\n",
       "  False,\n",
       "  0.36789297658862874,\n",
       "  0.6423611111111112],\n",
       " [2998, 54, 297, 192, 332, 321, True, 0.6607142857142857, 0.5033112582781457],\n",
       " [2998, 54, 141, 324, 282, 309, False, 0.4937106918238994, 0.3303030303030303],\n",
       " [2998, 54, 33, 328, 158, 251, False, 0.5076923076923077, 0.37888198757763975],\n",
       " [2998, 54, 335, 323, 348, 274, True, 0.6318181818181818, 0.4444444444444444],\n",
       " [2998,\n",
       "  54,\n",
       "  107,\n",
       "  338,\n",
       "  255,\n",
       "  294,\n",
       "  False,\n",
       "  0.6615384615384615,\n",
       "  0.44837758112094395],\n",
       " [2998,\n",
       "  54,\n",
       "  233,\n",
       "  344,\n",
       "  294,\n",
       "  336,\n",
       "  False,\n",
       "  0.38461538461538464,\n",
       "  0.4420289855072464],\n",
       " [2998, 54, 350, 125, 313, 189, True, 0.44072948328267475, 0.6033333333333334],\n",
       " [2998,\n",
       "  54,\n",
       "  252,\n",
       "  352,\n",
       "  267,\n",
       "  305,\n",
       "  False,\n",
       "  0.4881656804733728,\n",
       "  0.41776315789473684],\n",
       " [2998,\n",
       "  54,\n",
       "  187,\n",
       "  354,\n",
       "  348,\n",
       "  363,\n",
       "  False,\n",
       "  0.41114982578397213,\n",
       "  0.5579937304075235],\n",
       " [2998, 54, 358, 48, 309, 208, True, 0.6595092024539877, 0.5217391304347826],\n",
       " [2998, 56, 4, 201, 297, 255, True, 0.6397694524495677, 0.4550898203592814],\n",
       " [2998, 56, 6, 222, 348, 328, True, 0.4791666666666667, 0.5654952076677316],\n",
       " [2998, 56, 268, 24, 224, 282, False, 0.391304347826087, 0.5517241379310345],\n",
       " [2998, 56, 70, 29, 232, 336, False, 0.19387755102040816, 0.44904458598726116],\n",
       " [2998, 56, 50, 77, 263, 243, True, 0.5838150289017341, 0.5540983606557377],\n",
       " [2998, 56, 53, 87, 406, 267, True, 0.7088607594936709, 0.5986394557823129],\n",
       " [2998, 56, 60, 173, 301, 236, True, 0.5352112676056338, 0.6295081967213115],\n",
       " [2998, 56, 99, 280, 367, 290, True, 0.5508196721311476, 0.5854545454545454],\n",
       " [2998,\n",
       "  56,\n",
       "  154,\n",
       "  108,\n",
       "  267,\n",
       "  421,\n",
       "  False,\n",
       "  0.4298780487804878,\n",
       "  0.46105919003115264],\n",
       " [2998, 56, 38, 116, 208, 274, False, 0.40131578947368424, 0.6102719033232629],\n",
       " [2998, 56, 122, 314, 282, 197, True, 0.4722222222222222, 0.5631067961165048],\n",
       " [2998, 56, 124, 174, 247, 212, True, 0.2833333333333333, 0.419672131147541],\n",
       " [2998, 56, 118, 128, 247, 267, False, 0.5290697674418605, 0.3498452012383901],\n",
       " [2998, 56, 19, 134, 150, 282, False, 0.2545454545454545, 0.3993993993993994],\n",
       " [2998, 56, 32, 156, 181, 259, False, 0.4983922829581994, 0.5143769968051118],\n",
       " [2998, 56, 159, 191, 379, 363, True, 0.39039039039039036, 0.5422077922077922],\n",
       " [2998, 56, 166, 62, 274, 243, True, 0.6666666666666666, 0.5504587155963303],\n",
       " [2998, 56, 188, 183, 197, 375, False, 0.396875, 0.45896656534954405],\n",
       " [2998, 56, 184, 193, 263, 259, True, 0.4358974358974359, 0.31309904153354634],\n",
       " [2998, 56, 235, 198, 313, 282, True, 0.6085526315789473, 0.56],\n",
       " [2998, 56, 236, 283, 236, 197, True, 0.45714285714285713, 0.5902777777777778],\n",
       " [2998, 56, 243, 120, 208, 162, True, 0.6133333333333333, 0.436950146627566],\n",
       " [2998, 56, 245, 241, 398, 220, True, 0.6314363143631436, 0.7326732673267327],\n",
       " [2998, 56, 47, 260, 356, 417, False, 0.2971014492753623, 0.5450236966824644],\n",
       " [2998, 56, 311, 261, 232, 305, False, 0.4662379421221865, 0.4854368932038835],\n",
       " [2998, 56, 262, 165, 375, 267, True, 0.45482866043613707, 0.5621301775147929],\n",
       " [2998, 56, 272, 126, 294, 278, True, 0.5324232081911263, 0.6360424028268551],\n",
       " [2998, 56, 361, 278, 263, 328, False, 0.5342465753424658, 0.5859872611464968],\n",
       " [2998, 56, 286, 360, 336, 297, True, 0.5953079178885631, 0.48444444444444446],\n",
       " [2998, 56, 289, 86, 305, 286, True, 0.3501577287066246, 0.6528662420382165],\n",
       " [2998, 56, 291, 321, 352, 340, True, 0.36363636363636365, 0.5824915824915825],\n",
       " [2998,\n",
       "  56,\n",
       "  84,\n",
       "  293,\n",
       "  301,\n",
       "  325,\n",
       "  False,\n",
       "  0.46568627450980393,\n",
       "  0.23076923076923078],\n",
       " [2998,\n",
       "  56,\n",
       "  217,\n",
       "  300,\n",
       "  414,\n",
       "  479,\n",
       "  False,\n",
       "  0.39603960396039606,\n",
       "  0.3626062322946176],\n",
       " [2998, 56, 138, 312, 239, 321, False, 0.4537037037037037, 0.3783783783783784],\n",
       " [2998, 56, 320, 306, 356, 321, True, 0.37538461538461537, 0.6063492063492063],\n",
       " [2998, 56, 325, 145, 286, 239, True, 0.540453074433657, 0.37770897832817335],\n",
       " [2998, 56, 341, 112, 433, 336, True, 0.40468227424749165, 0.7459016393442623],\n",
       " [2998,\n",
       "  56,\n",
       "  254,\n",
       "  349,\n",
       "  181,\n",
       "  236,\n",
       "  False,\n",
       "  0.49498327759197325,\n",
       "  0.43790849673202614],\n",
       " [2998, 56, 353, 41, 212, 174, True, 0.5623003194888179, 0.6610738255033557],\n",
       " [2998, 56, 150, 363, 205, 286, False, 0.4189189189189189, 0.5714285714285714],\n",
       " [2998, 58, 3, 149, 251, 239, True, 0.5033557046979866, 0.5741935483870968],\n",
       " [2998, 58, 202, 8, 267, 379, False, 0.3291139240506329, 0.6466666666666666],\n",
       " [2998, 58, 11, 17, 328, 286, True, 0.4983277591973244, 0.5240384615384616],\n",
       " [2998, 58, 12, 161, 336, 259, True, 0.7409638554216867, 0.4491017964071856],\n",
       " [2998, 58, 13, 207, 274, 267, True, 0.5543478260869565, 0.31761006289308175],\n",
       " [2998, 58, 139, 14, 278, 290, False, 0.46283783783783783, 0.5033333333333333],\n",
       " [2998, 58, 23, 341, 332, 228, True, 0.5360501567398119, 0.5953177257525084],\n",
       " [2998, 58, 272, 29, 212, 243, False, 0.5324232081911263, 0.44904458598726116],\n",
       " [2998, 58, 30, 117, 379, 228, True, 0.6035502958579881, 0.5275862068965518],\n",
       " [2998, 58, 19, 32, 170, 228, False, 0.2545454545454545, 0.5032051282051282],\n",
       " [2998, 58, 35, 121, 305, 294, True, 0.4101694915254237, 0.4738372093023256],\n",
       " [2998, 58, 40, 141, 255, 243, True, 0.6812749003984063, 0.5047021943573667],\n",
       " [2998, 58, 41, 241, 445, 212, True, 0.3389261744966443, 0.7326732673267327],\n",
       " [2998, 58, 188, 47, 352, 479, False, 0.396875, 0.7050359712230215],\n",
       " [2998, 58, 4, 50, 286, 305, False, 0.6397694524495677, 0.414985590778098],\n",
       " [2998, 58, 52, 305, 336, 332, True, 0.2268370607028754, 0.5207100591715976],\n",
       " [2998, 58, 49, 55, 259, 336, False, 0.35714285714285715, 0.43722943722943725],\n",
       " [2998, 58, 108, 60, 224, 267, False, 0.5375, 0.46261682242990654],\n",
       " [2998, 58, 63, 163, 328, 274, True, 0.7087378640776699, 0.5344262295081967],\n",
       " [2998, 58, 45, 81, 232, 371, False, 0.44518272425249167, 0.125],\n",
       " [2998, 58, 360, 84, 243, 297, False, 0.5133928571428571, 0.5365853658536586],\n",
       " [2998, 58, 165, 86, 317, 328, False, 0.4391691394658754, 0.6528662420382165],\n",
       " [2998, 58, 90, 279, 336, 294, True, 0.4968553459119497, 0.4967105263157895],\n",
       " [2998, 58, 91, 259, 286, 193, True, 0.5125786163522013, 0.49828178694158076],\n",
       " [2998, 58, 96, 355, 236, 193, True, 0.7340425531914894, 0.47648902821316613],\n",
       " [2998, 58, 239, 101, 305, 332, False, 0.3854748603351955, 0.5795454545454546],\n",
       " [2998,\n",
       "  58,\n",
       "  10,\n",
       "  103,\n",
       "  278,\n",
       "  309,\n",
       "  False,\n",
       "  0.46417445482866043,\n",
       "  0.44011976047904194],\n",
       " [2998,\n",
       "  58,\n",
       "  218,\n",
       "  106,\n",
       "  278,\n",
       "  297,\n",
       "  False,\n",
       "  0.4723926380368098,\n",
       "  0.42765273311897106],\n",
       " [2998, 58, 110, 51, 375, 325, True, 0.5253731343283582, 0.5],\n",
       " [2998, 58, 118, 254, 282, 259, True, 0.5290697674418605, 0.5066666666666667],\n",
       " [2998, 58, 122, 145, 309, 216, True, 0.4722222222222222, 0.37770897832817335],\n",
       " [2998, 58, 126, 70, 328, 309, True, 0.36524822695035464, 0.8067796610169492],\n",
       " [2998, 58, 128, 349, 294, 212, True, 0.6490683229813664, 0.43790849673202614],\n",
       " [2998,\n",
       "  58,\n",
       "  156,\n",
       "  134,\n",
       "  251,\n",
       "  325,\n",
       "  False,\n",
       "  0.48562300319488816,\n",
       "  0.3993993993993994],\n",
       " [2998, 58, 135, 220, 325, 255, True, 0.5606060606060606, 0.47315436241610737],\n",
       " [2998,\n",
       "  58,\n",
       "  222,\n",
       "  138,\n",
       "  352,\n",
       "  359,\n",
       "  False,\n",
       "  0.43450479233226835,\n",
       "  0.5462962962962963],\n",
       " [2998, 58, 142, 153, 255, 232, True, 0.8128834355828221, 0.4868421052631579],\n",
       " [2998, 58, 143, 75, 445, 208, True, 0.5495495495495496, 0.603225806451613],\n",
       " [2998, 58, 146, 131, 294, 286, True, 0.6888888888888889, 0.38484848484848483],\n",
       " [2998, 58, 150, 38, 278, 197, True, 0.4189189189189189, 0.6],\n",
       " [2998, 58, 151, 340, 247, 212, True, 0.42207792207792205, 0.6666666666666666],\n",
       " [2998, 58, 159, 320, 352, 317, True, 0.39039039039039036, 0.6257668711656442],\n",
       " [2998, 58, 167, 361, 352, 332, True, 0.5016181229773463, 0.4681818181818182],\n",
       " [2998, 58, 168, 352, 390, 352, True, 0.6480938416422287, 0.41776315789473684],\n",
       " [2998, 58, 169, 362, 352, 278, True, 0.6170212765957447, 0.25903614457831325],\n",
       " [2998, 58, 154, 173, 274, 398, False, 0.4298780487804878, 0.6295081967213115],\n",
       " [2998, 58, 175, 132, 297, 236, True, 0.5833333333333334, 0.531055900621118],\n",
       " [2998, 58, 56, 176, 236, 309, False, 0.44299674267100975, 0.4511627906976744],\n",
       " [2998, 58, 73, 177, 286, 321, False, 0.5706051873198847, 0.29190751445086704],\n",
       " [2998, 58, 180, 335, 286, 274, True, 0.6150627615062761, 0.3665158371040724],\n",
       " [2998, 58, 16, 181, 294, 336, False, 0.6470588235294118, 0.3415384615384615],\n",
       " [2998,\n",
       "  58,\n",
       "  260,\n",
       "  183,\n",
       "  243,\n",
       "  270,\n",
       "  False,\n",
       "  0.45714285714285713,\n",
       "  0.45896656534954405],\n",
       " [2998, 58, 184, 291, 336, 255, True, 0.4358974358974359, 0.6341463414634146],\n",
       " [2998, 58, 69, 185, 185, 259, False, 0.4253968253968254, 0.42333333333333334],\n",
       " [2998,\n",
       "  58,\n",
       "  269,\n",
       "  186,\n",
       "  259,\n",
       "  270,\n",
       "  False,\n",
       "  0.36789297658862874,\n",
       "  0.5787545787545788],\n",
       " [2998, 58, 191, 306, 352, 297, True, 0.4592833876221498, 0.6063492063492063],\n",
       " [2998,\n",
       "  58,\n",
       "  190,\n",
       "  192,\n",
       "  259,\n",
       "  336,\n",
       "  False,\n",
       "  0.42356687898089174,\n",
       "  0.5033112582781457],\n",
       " [2998,\n",
       "  58,\n",
       "  321,\n",
       "  193,\n",
       "  313,\n",
       "  406,\n",
       "  False,\n",
       "  0.4189189189189189,\n",
       "  0.31309904153354634],\n",
       " [2998, 58, 201, 77, 375, 321, True, 0.5435435435435435, 0.5540983606557377],\n",
       " [2998, 58, 66, 204, 328, 348, False, 0.6424242424242425, 0.4329268292682927],\n",
       " [2998, 58, 265, 205, 263, 278, False, 0.5, 0.43450479233226835],\n",
       " [2998, 58, 331, 208, 236, 243, False, 0.569078947368421, 0.3927392739273927],\n",
       " [2998, 58, 210, 65, 274, 270, True, 0.5169230769230769, 0.3382352941176471],\n",
       " [2998, 58, 214, 316, 390, 278, True, 0.7771428571428571, 0.4470198675496689],\n",
       " [2998, 58, 226, 233, 325, 224, True, 0.6363636363636364, 0.6134185303514377],\n",
       " [2998, 58, 64, 228, 270, 375, False, 0.4984025559105431, 0.3408360128617363],\n",
       " [2998, 58, 43, 229, 239, 294, False, 0.5918367346938775, 0.3117283950617284],\n",
       " [2998, 58, 166, 236, 216, 232, False, 0.6666666666666666, 0.5428571428571428],\n",
       " [2998, 58, 243, 24, 236, 208, True, 0.6133333333333333, 0.5517241379310345],\n",
       " [2998, 58, 244, 248, 297, 286, True, 0.5584415584415584, 0.4702194357366771],\n",
       " [2998, 58, 249, 302, 359, 243, True, 0.4440677966101695, 0.6224489795918368],\n",
       " [2998, 58, 250, 93, 286, 255, True, 0.5869565217391305, 0.4911242603550296],\n",
       " [2998, 58, 251, 148, 305, 290, True, 0.5603715170278638, 0.6167247386759582],\n",
       " [2998, 58, 252, 364, 290, 247, True, 0.4881656804733728, 0.6701388888888888],\n",
       " [2998, 58, 253, 324, 352, 328, True, 0.40625, 0.3303030303030303],\n",
       " [2998,\n",
       "  58,\n",
       "  22,\n",
       "  256,\n",
       "  282,\n",
       "  313,\n",
       "  False,\n",
       "  0.48909657320872274,\n",
       "  0.42042042042042044],\n",
       " [2998, 58, 289, 262, 290, 332, False, 0.3501577287066246, 0.5451713395638629],\n",
       " [2998, 58, 264, 158, 228, 224, True, 0.515358361774744, 0.6805555555555556],\n",
       " [2998, 58, 268, 120, 270, 220, True, 0.391304347826087, 0.436950146627566],\n",
       " [2998, 58, 271, 133, 340, 278, True, 0.560126582278481, 0.4375],\n",
       " [2998, 58, 273, 147, 263, 251, True, 0.564935064935065, 0.47783251231527096],\n",
       " [2998, 58, 281, 129, 325, 313, True, 0.3576388888888889, 0.4792626728110599],\n",
       " [2998, 58, 283, 62, 239, 228, True, 0.4076655052264808, 0.5504587155963303],\n",
       " [2998, 58, 37, 284, 309, 313, False, 0.5606557377049181, 0.6555183946488294],\n",
       " [2998, 58, 287, 275, 286, 278, True, 0.5512048192771084, 0.35294117647058826],\n",
       " [2998, 58, 219, 288, 193, 220, False, 0.5017667844522968, 0.1875],\n",
       " [2998, 58, 293, 286, 278, 270, True, 0.7692307692307693, 0.4064327485380117],\n",
       " [2998, 58, 296, 82, 363, 301, True, 0.6867469879518072, 0.6040955631399317],\n",
       " [2998, 58, 261, 300, 224, 328, False, 0.5145631067961165, 0.3626062322946176],\n",
       " [2998, 58, 301, 258, 278, 259, True, 0.4709480122324159, 0.5080906148867314],\n",
       " [2998, 58, 303, 61, 239, 216, True, 0.5352564102564102, 0.4966442953020134],\n",
       " [2998, 58, 308, 274, 251, 216, True, 0.4625, 0.5427631578947368],\n",
       " [2998,\n",
       "  58,\n",
       "  217,\n",
       "  311,\n",
       "  294,\n",
       "  313,\n",
       "  False,\n",
       "  0.39603960396039606,\n",
       "  0.5352564102564102],\n",
       " [2998, 58, 312, 6, 321, 236, True, 0.6195652173913043, 0.5190311418685121],\n",
       " [2998,\n",
       "  58,\n",
       "  237,\n",
       "  317,\n",
       "  224,\n",
       "  379,\n",
       "  False,\n",
       "  0.49127906976744184,\n",
       "  0.3119266055045872],\n",
       " [2998, 58, 323, 199, 356, 340, True, 0.5540983606557377, 0.6019417475728155],\n",
       " [2998, 58, 314, 325, 274, 309, False, 0.43137254901960786, 0.459546925566343],\n",
       " [2998, 58, 109, 326, 328, 425, False, 0.4772727272727273, 0.5347222222222222],\n",
       " [2998, 58, 351, 329, 301, 356, False, 0.5765765765765766, 0.2987012987012987],\n",
       " [2998, 58, 230, 333, 321, 379, False, 0.6088235294117647, 0.3644578313253012],\n",
       " [2998, 58, 98, 334, 267, 286, False, 0.4024767801857585, 0.409375],\n",
       " [2998, 58, 344, 127, 325, 228, True, 0.5563636363636364, 0.49523809523809526],\n",
       " [2998, 58, 348, 92, 255, 166, True, 0.6056338028169014, 0.5866261398176292],\n",
       " [2998, 58, 350, 263, 313, 220, True, 0.44072948328267475, 0.6877076411960132],\n",
       " [2998,\n",
       "  58,\n",
       "  245,\n",
       "  353,\n",
       "  205,\n",
       "  267,\n",
       "  False,\n",
       "  0.6314363143631436,\n",
       "  0.43630573248407645],\n",
       " [2998, 58, 48, 354, 297, 371, False, 0.4798657718120805, 0.5579937304075235],\n",
       " [2998, 58, 339, 356, 232, 255, False, 0.5, 0.6190476190476191],\n",
       " [2998, 58, 358, 57, 352, 220, True, 0.6595092024539877, 0.5857142857142857],\n",
       " [2998,\n",
       "  58,\n",
       "  116,\n",
       "  363,\n",
       "  147,\n",
       "  216,\n",
       "  False,\n",
       "  0.39090909090909093,\n",
       "  0.5714285714285714],\n",
       " [2998, 60, 31, 85, 270, 247, True, 0.5589225589225589, 0.6054421768707483],\n",
       " [2998, 60, 78, 109, 387, 332, True, 0.49019607843137253, 0.5227272727272727],\n",
       " [2998, 60, 198, 164, 290, 305, False, 0.4414715719063545, 0.6160714285714286],\n",
       " [2998, 61, 8, 14, 332, 290, True, 0.35333333333333333, 0.5033333333333333],\n",
       " [2998, 61, 120, 30, 201, 251, False, 0.5630498533724341, 0.3952802359882006],\n",
       " [2998, 61, 39, 173, 371, 282, True, 0.7246376811594203, 0.6295081967213115],\n",
       " [2998, 61, 357, 54, 220, 317, False, 0.48214285714285715, 0.7065217391304348],\n",
       " [2998, 61, 100, 73, 317, 356, False, 0.3356643356643357, 0.43103448275862066],\n",
       " [2998, 61, 75, 107, 294, 359, False, 0.3967741935483871, 0.3384615384615385],\n",
       " [2998,\n",
       "  61,\n",
       "  263,\n",
       "  111,\n",
       "  216,\n",
       "  236,\n",
       "  False,\n",
       "  0.3122923588039867,\n",
       "  0.20699708454810495],\n",
       " [2998, 61, 147, 337, 305, 290, True, 0.5198019801980198, 0.36712328767123287],\n",
       " [2998, 61, 52, 176, 239, 433, False, 0.2268370607028754, 0.4511627906976744],\n",
       " [2998,\n",
       "  61,\n",
       "  334,\n",
       "  223,\n",
       "  255,\n",
       "  274,\n",
       "  False,\n",
       "  0.5924764890282131,\n",
       "  0.27631578947368424],\n",
       " [2998, 61, 333, 247, 274, 278, False, 0.6355421686746988, 0.5486111111111112],\n",
       " [2998,\n",
       "  61,\n",
       "  275,\n",
       "  256,\n",
       "  325,\n",
       "  359,\n",
       "  False,\n",
       "  0.6435643564356436,\n",
       "  0.42042042042042044],\n",
       " [2998, 61, 91, 281, 359, 379, False, 0.5125786163522013, 0.6423611111111112],\n",
       " [2998, 61, 286, 235, 317, 313, True, 0.5953079178885631, 0.39144736842105265],\n",
       " [2998, 61, 322, 316, 255, 243, True, 0.4326923076923077, 0.4470198675496689],\n",
       " [2998,\n",
       "  61,\n",
       "  311,\n",
       "  353,\n",
       "  162,\n",
       "  220,\n",
       "  False,\n",
       "  0.4662379421221865,\n",
       "  0.43630573248407645],\n",
       " [2998,\n",
       "  61,\n",
       "  163,\n",
       "  354,\n",
       "  282,\n",
       "  336,\n",
       "  False,\n",
       "  0.46710526315789475,\n",
       "  0.5579937304075235],\n",
       " [2998, 63, 143, 16, 228, 270, False, 0.5495495495495496, 0.35185185185185186],\n",
       " [2998,\n",
       "  63,\n",
       "  262,\n",
       "  29,\n",
       "  251,\n",
       "  274,\n",
       "  False,\n",
       "  0.45482866043613707,\n",
       "  0.44904458598726116],\n",
       " [2998, 63, 44, 322, 205, 197, True, 0.3507853403141361, 0.5686900958466453],\n",
       " [2998, 63, 49, 254, 247, 232, True, 0.35714285714285715, 0.5066666666666667],\n",
       " [2998, 63, 184, 74, 243, 282, False, 0.4358974358974359, 0.4624624624624625],\n",
       " [2998, 63, 252, 82, 317, 359, False, 0.4881656804733728, 0.6040955631399317],\n",
       " [2998, 63, 93, 92, 359, 305, True, 0.5088757396449705, 0.5866261398176292],\n",
       " [2998, 63, 70, 125, 340, 352, False, 0.19387755102040816, 0.6033333333333334],\n",
       " [2998,\n",
       "  63,\n",
       "  335,\n",
       "  131,\n",
       "  197,\n",
       "  340,\n",
       "  False,\n",
       "  0.6318181818181818,\n",
       "  0.38484848484848483],\n",
       " [2998, 63, 134, 220, 387, 328, True, 0.5993975903614458, 0.47315436241610737],\n",
       " [2998,\n",
       "  63,\n",
       "  326,\n",
       "  135,\n",
       "  317,\n",
       "  371,\n",
       "  False,\n",
       "  0.46689895470383275,\n",
       "  0.4380664652567976],\n",
       " [2998, 63, 146, 302, 317, 139, True, 0.6888888888888889, 0.6224489795918368],\n",
       " [2998, 63, 33, 149, 158, 274, False, 0.5076923076923077, 0.5741935483870968],\n",
       " [2998,\n",
       "  63,\n",
       "  168,\n",
       "  157,\n",
       "  305,\n",
       "  371,\n",
       "  False,\n",
       "  0.6480938416422287,\n",
       "  0.29573170731707316],\n",
       " [2998, 63, 206, 169, 243, 325, False, 0.2783171521035599, 0.3829787234042553],\n",
       " [2998, 63, 180, 79, 305, 193, True, 0.6150627615062761, 0.6203389830508474],\n",
       " [2998, 63, 207, 301, 363, 278, True, 0.6813880126182965, 0.5290519877675841],\n",
       " [2998, 63, 300, 228, 352, 410, False, 0.6363636363636364, 0.3408360128617363],\n",
       " [2998,\n",
       "  63,\n",
       "  156,\n",
       "  229,\n",
       "  274,\n",
       "  297,\n",
       "  False,\n",
       "  0.48562300319488816,\n",
       "  0.3117283950617284],\n",
       " [2998, 63, 121, 244, 282, 309, False, 0.5247813411078717, 0.4401294498381877],\n",
       " [2998, 63, 19, 250, 139, 228, False, 0.2545454545454545, 0.4117647058823529],\n",
       " [2998, 63, 282, 45, 294, 270, True, 0.4742268041237113, 0.5562913907284768],\n",
       " [2998, 63, 128, 296, 216, 356, False, 0.6490683229813664, 0.3123123123123123],\n",
       " [2998, 63, 329, 328, 286, 278, True, 0.6993464052287581, 0.37888198757763975],\n",
       " [2998, 63, 103, 339, 274, 282, False, 0.5598802395209581, 0.5],\n",
       " [2998, 63, 344, 273, 243, 228, True, 0.5563636363636364, 0.4336569579288026],\n",
       " [2998, 63, 350, 86, 309, 228, True, 0.44072948328267475, 0.6528662420382165],\n",
       " [2998, 65, 223, 30, 208, 301, False, 0.72, 0.3952802359882006],\n",
       " [2998, 65, 343, 32, 286, 313, False, 0.6183844011142061, 0.5032051282051282],\n",
       " [2998, 65, 39, 334, 321, 309, True, 0.7246376811594203, 0.409375],\n",
       " [2998, 65, 64, 320, 325, 286, True, 0.4984025559105431, 0.6257668711656442],\n",
       " [2998, 65, 77, 10, 410, 309, True, 0.4459016393442623, 0.5372670807453416],\n",
       " [2998,\n",
       "  65,\n",
       "  101,\n",
       "  205,\n",
       "  363,\n",
       "  301,\n",
       "  True,\n",
       "  0.42528735632183906,\n",
       "  0.43450479233226835],\n",
       " [2998, 65, 120, 133, 166, 220, False, 0.5630498533724341, 0.4375],\n",
       " [2998, 65, 153, 310, 274, 232, True, 0.5131578947368421, 0.7015503875968992],\n",
       " [2998, 65, 289, 154, 301, 305, False, 0.3501577287066246, 0.5701219512195121],\n",
       " [2998, 65, 178, 3, 332, 228, True, 0.594059405940594, 0.49498327759197325],\n",
       " [2998,\n",
       "  65,\n",
       "  182,\n",
       "  183,\n",
       "  247,\n",
       "  297,\n",
       "  False,\n",
       "  0.39100346020761245,\n",
       "  0.45896656534954405],\n",
       " [2998, 65, 358, 204, 259, 332, False, 0.6595092024539877, 0.4329268292682927],\n",
       " [2998, 65, 253, 271, 278, 297, False, 0.40625, 0.439873417721519],\n",
       " [2998, 65, 295, 234, 255, 236, True, 0.47384615384615386, 0.4169381107491857],\n",
       " [2998, 65, 106, 333, 317, 348, False, 0.5709677419354838, 0.3644578313253012],\n",
       " [2998, 65, 347, 34, 348, 274, True, 0.515625, 0.9285714285714286],\n",
       " [2998, 65, 352, 38, 352, 178, True, 0.5841584158415841, 0.6],\n",
       " [2998, 65, 361, 60, 232, 224, True, 0.5342465753424658, 0.46261682242990654],\n",
       " [2998,\n",
       "  65,\n",
       "  145,\n",
       "  362,\n",
       "  251,\n",
       "  282,\n",
       "  False,\n",
       "  0.6211180124223602,\n",
       "  0.25903614457831325],\n",
       " [2998, 67, 111, 126, 305, 270, True, 0.7923976608187134, 0.6360424028268551],\n",
       " [2998, 67, 146, 187, 390, 325, True, 0.6888888888888889, 0.5902777777777778],\n",
       " [2998, 67, 121, 169, 282, 328, False, 0.5247813411078717, 0.3829787234042553],\n",
       " [2998, 67, 175, 73, 228, 181, True, 0.5833333333333334, 0.43103448275862066],\n",
       " [2998, 67, 176, 85, 352, 297, True, 0.5467289719626168, 0.6054421768707483],\n",
       " [2998, 67, 202, 360, 321, 317, True, 0.3291139240506329, 0.48444444444444446],\n",
       " [2998, 67, 252, 225, 259, 301, False, 0.4881656804733728, 0.4318181818181818],\n",
       " [2998, 67, 68, 237, 267, 305, False, 0.5287356321839081, 0.5072463768115942],\n",
       " [2998, 67, 273, 116, 294, 224, True, 0.564935064935065, 0.6102719033232629],\n",
       " [2998, 67, 186, 354, 290, 297, False, 0.4227941176470588, 0.5579937304075235],\n",
       " [2998, 69, 17, 211, 321, 220, True, 0.47342995169082125, 0.6678832116788321],\n",
       " [2998, 69, 29, 69, 255, 174, True, 0.5509554140127388, 0.5759493670886076],\n",
       " [2998, 69, 329, 40, 297, 359, False, 0.6993464052287581, 0.31746031746031744],\n",
       " [2998, 69, 347, 44, 228, 239, False, 0.515625, 0.6510416666666666],\n",
       " [2998, 69, 48, 71, 224, 301, False, 0.4798657718120805, 0.6847457627118644],\n",
       " [2998,\n",
       "  69,\n",
       "  288,\n",
       "  118,\n",
       "  239,\n",
       "  301,\n",
       "  False,\n",
       "  0.8105263157894737,\n",
       "  0.47246376811594204],\n",
       " [2998, 69, 31, 131, 181, 340, False, 0.5589225589225589, 0.38484848484848483],\n",
       " [2998, 69, 170, 310, 263, 205, True, 0.4492753623188406, 0.7015503875968992],\n",
       " [2998,\n",
       "  69,\n",
       "  280,\n",
       "  254,\n",
       "  286,\n",
       "  305,\n",
       "  False,\n",
       "  0.41454545454545455,\n",
       "  0.5066666666666667],\n",
       " [2998, 69, 319, 232, 236, 228, True, 0.4166666666666667, 0.449685534591195],\n",
       " [2998, 69, 45, 342, 290, 294, False, 0.44518272425249167, 0.6360424028268551],\n",
       " [2998, 69, 210, 344, 263, 332, False, 0.5169230769230769, 0.4420289855072464],\n",
       " [2998, 69, 358, 258, 379, 290, True, 0.6595092024539877, 0.5080906148867314],\n",
       " [2998, 69, 38, 364, 278, 294, False, 0.40131578947368424, 0.6701388888888888],\n",
       " [2998, 70, 4, 230, 406, 259, True, 0.6397694524495677, 0.39296187683284456],\n",
       " [2998, 70, 17, 254, 263, 216, True, 0.47342995169082125, 0.5066666666666667],\n",
       " [2998, 70, 20, 279, 359, 301, True, 0.42857142857142855, 0.4967105263157895],\n",
       " [2998, 70, 302, 24, 212, 259, False, 0.378839590443686, 0.5517241379310345],\n",
       " [2998, 70, 132, 39, 251, 309, False, 0.470404984423676, 0.2774566473988439],\n",
       " [2998, 70, 243, 40, 228, 251, False, 0.6133333333333333, 0.31746031746031744],\n",
       " [2998, 70, 45, 38, 297, 243, True, 0.44518272425249167, 0.6],\n",
       " [2998,\n",
       "  70,\n",
       "  298,\n",
       "  55,\n",
       "  232,\n",
       "  328,\n",
       "  False,\n",
       "  0.37337662337662336,\n",
       "  0.43722943722943725],\n",
       " [2998, 70, 56, 85, 286, 232, True, 0.44299674267100975, 0.6054421768707483],\n",
       " [2998, 70, 299, 58, 228, 290, False, 0.4883720930232558, 0.29213483146067415],\n",
       " [2998, 70, 300, 63, 297, 363, False, 0.6363636363636364, 0.28846153846153844],\n",
       " [2998, 70, 68, 239, 379, 363, True, 0.5287356321839081, 0.6111111111111112],\n",
       " [2998, 70, 71, 44, 348, 286, True, 0.3129251700680272, 0.6510416666666666],\n",
       " [2998, 70, 73, 191, 414, 313, True, 0.5706051873198847, 0.5422077922077922],\n",
       " [2998, 70, 79, 149, 267, 259, True, 0.37755102040816324, 0.5741935483870968],\n",
       " [2998, 70, 81, 176, 340, 328, True, 0.8737864077669902, 0.4511627906976744],\n",
       " [2998, 70, 61, 84, 255, 309, False, 0.5050505050505051, 0.5365853658536586],\n",
       " [2998, 70, 90, 319, 332, 297, True, 0.4968553459119497, 0.5833333333333334],\n",
       " [2998, 70, 91, 256, 383, 379, True, 0.5125786163522013, 0.42042042042042044],\n",
       " [2998, 70, 163, 92, 197, 247, False, 0.46710526315789475, 0.5866261398176292],\n",
       " [2998,\n",
       "  70,\n",
       "  104,\n",
       "  102,\n",
       "  297,\n",
       "  309,\n",
       "  False,\n",
       "  0.40522875816993464,\n",
       "  0.6334519572953736],\n",
       " [2998, 70, 103, 169, 297, 251, True, 0.5598802395209581, 0.3829787234042553],\n",
       " [2998, 70, 109, 110, 278, 348, False, 0.4772727272727273, 0.4732142857142857],\n",
       " [2998, 70, 118, 170, 328, 251, True, 0.5290697674418605, 0.5507246376811594],\n",
       " [2998, 70, 122, 127, 290, 255, True, 0.4722222222222222, 0.49523809523809526],\n",
       " [2998, 70, 125, 8, 336, 290, True, 0.39666666666666667, 0.6466666666666666],\n",
       " [2998, 70, 129, 126, 367, 243, True, 0.5185185185185185, 0.6360424028268551],\n",
       " [2998, 70, 131, 41, 383, 201, True, 0.6139817629179332, 0.6610738255033557],\n",
       " [2998, 70, 100, 133, 282, 286, False, 0.3356643356643357, 0.4375],\n",
       " [2998, 70, 135, 134, 379, 325, True, 0.5606060606060606, 0.3993993993993994],\n",
       " [2998, 70, 275, 141, 328, 417, False, 0.6435643564356436, 0.5047021943573667],\n",
       " [2998, 70, 142, 77, 402, 290, True, 0.8128834355828221, 0.5540983606557377],\n",
       " [2998, 70, 6, 143, 313, 383, False, 0.4791666666666667, 0.4491017964071856],\n",
       " [2998, 70, 145, 334, 294, 174, True, 0.6211180124223602, 0.409375],\n",
       " [2998, 70, 13, 146, 263, 363, False, 0.5543478260869565, 0.3088235294117647],\n",
       " [2998, 70, 151, 171, 344, 247, True, 0.42207792207792205, 0.7133550488599348],\n",
       " [2998, 70, 272, 153, 239, 270, False, 0.5324232081911263, 0.4868421052631579],\n",
       " [2998, 70, 47, 156, 344, 429, False, 0.2971014492753623, 0.5143769968051118],\n",
       " [2998, 70, 157, 106, 328, 255, True, 0.7033639143730887, 0.42765273311897106],\n",
       " [2998, 70, 159, 320, 301, 294, True, 0.39039039039039036, 0.6257668711656442],\n",
       " [2998, 70, 188, 160, 212, 406, False, 0.396875, 0.5830721003134797],\n",
       " [2998, 70, 173, 51, 282, 267, True, 0.3717105263157895, 0.5],\n",
       " [2998, 70, 175, 362, 282, 224, True, 0.5833333333333334, 0.25903614457831325],\n",
       " [2998, 70, 177, 78, 352, 290, True, 0.7072463768115942, 0.50814332247557],\n",
       " [2998,\n",
       "  70,\n",
       "  139,\n",
       "  180,\n",
       "  286,\n",
       "  297,\n",
       "  False,\n",
       "  0.46283783783783783,\n",
       "  0.38333333333333336],\n",
       " [2998, 70, 324, 181, 301, 348, False, 0.6696969696969697, 0.3415384615384615],\n",
       " [2998,\n",
       "  70,\n",
       "  190,\n",
       "  182,\n",
       "  263,\n",
       "  325,\n",
       "  False,\n",
       "  0.42356687898089174,\n",
       "  0.6103448275862069],\n",
       " [2998, 70, 184, 206, 274, 208, True, 0.4358974358974359, 0.7225806451612903],\n",
       " [2998, 70, 185, 237, 344, 340, True, 0.5752508361204013, 0.5072463768115942],\n",
       " [2998, 70, 186, 287, 336, 301, True, 0.4227941176470588, 0.45045045045045046],\n",
       " [2998, 70, 193, 192, 379, 286, True, 0.6869009584664537, 0.5033112582781457],\n",
       " [2998,\n",
       "  70,\n",
       "  280,\n",
       "  211,\n",
       "  286,\n",
       "  332,\n",
       "  False,\n",
       "  0.41454545454545455,\n",
       "  0.6678832116788321],\n",
       " [2998, 70, 220, 318, 294, 274, True, 0.5252525252525253, 0.5062111801242236],\n",
       " [2998, 70, 218, 221, 255, 359, False, 0.4723926380368098, 0.5813253012048193],\n",
       " [2998, 70, 167, 225, 247, 290, False, 0.5016181229773463, 0.4318181818181818],\n",
       " [2998, 70, 124, 226, 205, 441, False, 0.2833333333333333, 0.3625],\n",
       " [2998, 70, 355, 229, 208, 317, False, 0.5220125786163522, 0.3117283950617284],\n",
       " [2998,\n",
       "  70,\n",
       "  233,\n",
       "  183,\n",
       "  278,\n",
       "  243,\n",
       "  True,\n",
       "  0.38461538461538464,\n",
       "  0.45896656534954405],\n",
       " [2998, 70, 236, 32, 197, 185, True, 0.45714285714285713, 0.5032051282051282],\n",
       " [2998, 70, 260, 263, 239, 208, True, 0.45714285714285713, 0.6877076411960132],\n",
       " [2998, 70, 234, 262, 263, 317, False, 0.5849673202614379, 0.5451713395638629],\n",
       " [2998, 70, 271, 289, 255, 170, True, 0.560126582278481, 0.6477987421383647],\n",
       " [2998, 70, 351, 281, 344, 394, False, 0.5765765765765766, 0.6423611111111112],\n",
       " [2998, 70, 34, 283, 267, 282, False, 0.07142857142857142, 0.5902777777777778],\n",
       " [2998, 70, 285, 164, 332, 193, True, 0.5180722891566265, 0.6160714285714286],\n",
       " [2998, 70, 288, 310, 259, 239, True, 0.8105263157894737, 0.7015503875968992],\n",
       " [2998, 70, 265, 290, 228, 290, False, 0.5, 0.3125],\n",
       " [2998,\n",
       "  70,\n",
       "  295,\n",
       "  293,\n",
       "  278,\n",
       "  344,\n",
       "  False,\n",
       "  0.47384615384615386,\n",
       "  0.23076923076923078],\n",
       " [2998, 70, 297, 172, 251, 247, True, 0.6607142857142857, 0.3081395348837209],\n",
       " [2998, 70, 49, 309, 178, 352, False, 0.35714285714285715, 0.3880597014925373],\n",
       " [2998, 70, 312, 178, 332, 309, True, 0.6195652173913043, 0.40460526315789475],\n",
       " [2998, 70, 317, 261, 325, 247, True, 0.6871165644171779, 0.4854368932038835],\n",
       " [2998, 70, 328, 69, 290, 224, True, 0.6199376947040498, 0.5759493670886076],\n",
       " [2998, 70, 337, 10, 301, 247, True, 0.6346153846153846, 0.5372670807453416],\n",
       " [2998, 70, 342, 364, 251, 228, True, 0.36524822695035464, 0.6701388888888888],\n",
       " [2998,\n",
       "  70,\n",
       "  22,\n",
       "  343,\n",
       "  259,\n",
       "  332,\n",
       "  False,\n",
       "  0.48909657320872274,\n",
       "  0.38055555555555554],\n",
       " [2998, 70, 347, 48, 286, 212, True, 0.515625, 0.5217391304347826],\n",
       " [2998, 70, 352, 238, 332, 328, True, 0.5841584158415841, 0.3106508875739645],\n",
       " [2998, 72, 207, 12, 208, 255, False, 0.6813880126182965, 0.25903614457831325],\n",
       " [2998, 72, 30, 121, 363, 325, True, 0.6035502958579881, 0.4738372093023256],\n",
       " [2998, 72, 86, 111, 259, 286, False, 0.3471337579617834, 0.20699708454810495],\n",
       " [2998, 72, 166, 70, 305, 135, True, 0.6666666666666666, 0.8067796610169492],\n",
       " [2998, 72, 90, 232, 321, 379, False, 0.4968553459119497, 0.449685534591195],\n",
       " [2998, 72, 108, 245, 239, 251, False, 0.5375, 0.3675675675675676],\n",
       " [2998, 72, 278, 96, 282, 274, True, 0.41214057507987223, 0.2631578947368421],\n",
       " [2998, 74, 154, 34, 286, 390, False, 0.4298780487804878, 0.9285714285714286],\n",
       " [2998, 74, 50, 199, 348, 228, True, 0.5838150289017341, 0.6019417475728155],\n",
       " [2998, 74, 322, 51, 239, 247, False, 0.4326923076923077, 0.5],\n",
       " [2998, 74, 53, 182, 251, 236, True, 0.7088607594936709, 0.6103448275862069],\n",
       " [2998, 74, 102, 55, 321, 336, False, 0.3678571428571429, 0.43722943722943725],\n",
       " [2998, 74, 64, 364, 294, 228, True, 0.4984025559105431, 0.6701388888888888],\n",
       " [2998, 74, 66, 33, 212, 205, True, 0.6424242424242425, 0.4938650306748466],\n",
       " [2998, 74, 218, 83, 255, 270, False, 0.4723926380368098, 0.6006944444444444],\n",
       " [2998, 74, 99, 214, 332, 286, True, 0.5508196721311476, 0.22285714285714286],\n",
       " [2998, 74, 112, 47, 425, 414, True, 0.2551440329218107, 0.7050359712230215],\n",
       " [2998, 74, 158, 314, 367, 325, True, 0.3205574912891986, 0.5631067961165048],\n",
       " [2998, 74, 318, 172, 375, 406, False, 0.4953271028037383, 0.3081395348837209],\n",
       " [2998, 74, 41, 176, 270, 332, False, 0.3389261744966443, 0.4511627906976744],\n",
       " [2998,\n",
       "  74,\n",
       "  84,\n",
       "  180,\n",
       "  263,\n",
       "  336,\n",
       "  False,\n",
       "  0.46568627450980393,\n",
       "  0.38333333333333336],\n",
       " [2998, 74, 221, 126, 325, 232, True, 0.4169184290030212, 0.6360424028268551],\n",
       " [2998, 74, 281, 185, 286, 251, True, 0.3576388888888889, 0.42333333333333334],\n",
       " [2998, 74, 124, 305, 239, 309, False, 0.2833333333333333, 0.5207100591715976],\n",
       " [2998, 74, 98, 316, 328, 394, False, 0.4024767801857585, 0.4470198675496689],\n",
       " [2998, 74, 8, 350, 313, 460, False, 0.35333333333333333, 0.5575757575757576],\n",
       " [2998, 76, 179, 17, 239, 247, False, 0.6071428571428571, 0.5240384615384616],\n",
       " [2998, 76, 23, 132, 236, 228, True, 0.5360501567398119, 0.531055900621118],\n",
       " [2998, 76, 71, 117, 216, 205, True, 0.3129251700680272, 0.5275862068965518],\n",
       " [2998, 76, 268, 161, 247, 390, False, 0.391304347826087, 0.4491017964071856],\n",
       " [2998,\n",
       "  76,\n",
       "  190,\n",
       "  166,\n",
       "  239,\n",
       "  336,\n",
       "  False,\n",
       "  0.42356687898089174,\n",
       "  0.3323262839879154],\n",
       " [2998, 76, 177, 127, 290, 197, True, 0.7072463768115942, 0.49523809523809526],\n",
       " [2998,\n",
       "  76,\n",
       "  78,\n",
       "  178,\n",
       "  255,\n",
       "  263,\n",
       "  False,\n",
       "  0.49019607843137253,\n",
       "  0.40460526315789475],\n",
       " [2998,\n",
       "  76,\n",
       "  139,\n",
       "  214,\n",
       "  336,\n",
       "  379,\n",
       "  False,\n",
       "  0.46283783783783783,\n",
       "  0.22285714285714286],\n",
       " [2998, 76, 225, 61, 270, 208, True, 0.5681818181818182, 0.4966442953020134],\n",
       " [2998, 76, 245, 291, 390, 290, True, 0.6314363143631436, 0.6341463414634146],\n",
       " [2998, 76, 256, 287, 352, 255, True, 0.5783132530120482, 0.45045045045045046],\n",
       " [2998, 76, 274, 356, 255, 212, True, 0.45874587458745875, 0.6190476190476191],\n",
       " [2998, 76, 275, 217, 406, 379, True, 0.6435643564356436, 0.6052631578947368],\n",
       " [2998, 76, 279, 299, 367, 309, True, 0.5032894736842105, 0.5132450331125827],\n",
       " [2998, 76, 280, 97, 340, 278, True, 0.41454545454545455, 0.6559485530546624],\n",
       " [2998, 76, 309, 312, 290, 348, False, 0.6119402985074627, 0.3783783783783784],\n",
       " [2998, 76, 324, 20, 328, 317, True, 0.6696969696969697, 0.5652173913043478],\n",
       " [2998, 77, 54, 4, 259, 414, False, 0.2909090909090909, 0.35919540229885055],\n",
       " [2998, 77, 219, 12, 313, 491, False, 0.5017667844522968, 0.25903614457831325],\n",
       " [2998, 77, 29, 288, 208, 193, True, 0.5509554140127388, 0.1875],\n",
       " [2998, 77, 56, 66, 294, 263, True, 0.44299674267100975, 0.3575757575757576],\n",
       " [2998, 77, 196, 77, 297, 348, False, 0.3829113924050633, 0.5540983606557377],\n",
       " [2998, 77, 108, 110, 255, 251, True, 0.5375, 0.4732142857142857],\n",
       " [2998, 77, 191, 141, 263, 456, False, 0.4592833876221498, 0.5047021943573667],\n",
       " [2998, 77, 149, 316, 367, 344, True, 0.4258064516129032, 0.4470198675496689],\n",
       " [2998, 77, 182, 138, 332, 286, True, 0.39100346020761245, 0.5462962962962963],\n",
       " [2998,\n",
       "  77,\n",
       "  338,\n",
       "  209,\n",
       "  201,\n",
       "  208,\n",
       "  False,\n",
       "  0.5502958579881657,\n",
       "  0.45185185185185184],\n",
       " [2998, 77, 264, 226, 290, 317, False, 0.515358361774744, 0.3625],\n",
       " [2998, 77, 80, 236, 251, 309, False, 0.6426332288401254, 0.5428571428571428],\n",
       " [2998, 77, 243, 201, 193, 181, True, 0.6133333333333333, 0.4550898203592814],\n",
       " [2998,\n",
       "  77,\n",
       "  154,\n",
       "  251,\n",
       "  232,\n",
       "  305,\n",
       "  False,\n",
       "  0.4298780487804878,\n",
       "  0.43962848297213625],\n",
       " [2998,\n",
       "  77,\n",
       "  87,\n",
       "  297,\n",
       "  224,\n",
       "  359,\n",
       "  False,\n",
       "  0.40273037542662116,\n",
       "  0.33727810650887574],\n",
       " [2998, 77, 11, 323, 278, 290, False, 0.4983277591973244, 0.4444444444444444],\n",
       " [2998, 77, 339, 151, 359, 247, True, 0.5, 0.5760517799352751],\n",
       " [2998, 77, 340, 348, 166, 286, False, 0.3333333333333333, 0.3925233644859813],\n",
       " [2998, 79, 170, 40, 247, 402, False, 0.4492753623188406, 0.31746031746031744],\n",
       " [2998, 79, 57, 91, 220, 309, False, 0.4157706093189964, 0.48589341692789967],\n",
       " [2998, 79, 109, 173, 305, 301, True, 0.4772727272727273, 0.6295081967213115],\n",
       " [2998, 79, 26, 139, 359, 425, False, 0.3811074918566775, 0.5353535353535354],\n",
       " [2998, 79, 157, 187, 348, 294, True, 0.7033639143730887, 0.5902777777777778],\n",
       " [2998, 79, 160, 314, 325, 197, True, 0.41823899371069184, 0.5631067961165048],\n",
       " [2998, 79, 59, 164, 178, 274, False, 0.43217665615141954, 0.6160714285714286],\n",
       " [2998, 79, 172, 178, 251, 239, True, 0.6938775510204082, 0.40460526315789475],\n",
       " [2998, 79, 8, 179, 259, 429, False, 0.35333333333333333, 0.3893805309734513],\n",
       " [2998,\n",
       "  79,\n",
       "  222,\n",
       "  205,\n",
       "  340,\n",
       "  452,\n",
       "  False,\n",
       "  0.43450479233226835,\n",
       "  0.43450479233226835],\n",
       " [2998, 79, 208, 303, 294, 263, True, 0.6059602649006622, 0.46325878594249204],\n",
       " [2998, 79, 167, 238, 251, 344, False, 0.5016181229773463, 0.3106508875739645],\n",
       " [2998, 79, 249, 112, 390, 236, True, 0.4440677966101695, 0.7459016393442623],\n",
       " [2998,\n",
       "  79,\n",
       "  310,\n",
       "  269,\n",
       "  263,\n",
       "  270,\n",
       "  False,\n",
       "  0.29961089494163423,\n",
       "  0.6333333333333333],\n",
       " [2998,\n",
       "  79,\n",
       "  211,\n",
       "  318,\n",
       "  201,\n",
       "  205,\n",
       "  False,\n",
       "  0.32967032967032966,\n",
       "  0.5062111801242236],\n",
       " [2998, 79, 343, 193, 359, 344, True, 0.6183844011142061, 0.31309904153354634],\n",
       " [2998, 81, 3, 78, 208, 212, False, 0.5033557046979866, 0.50814332247557],\n",
       " [2998, 81, 86, 75, 394, 263, True, 0.3471337579617834, 0.603225806451613],\n",
       " [2998, 81, 104, 237, 305, 282, True, 0.40522875816993464, 0.5072463768115942],\n",
       " [2998, 81, 118, 126, 340, 294, True, 0.5290697674418605, 0.6360424028268551],\n",
       " [2998, 81, 185, 349, 232, 212, True, 0.5752508361204013, 0.43790849673202614],\n",
       " [2998, 81, 301, 204, 263, 352, False, 0.4709480122324159, 0.4329268292682927],\n",
       " [2998, 81, 261, 97, 363, 348, True, 0.5145631067961165, 0.6559485530546624],\n",
       " [2998, 81, 6, 272, 251, 259, False, 0.4791666666666667, 0.46938775510204084],\n",
       " [2998, 81, 274, 174, 267, 232, True, 0.45874587458745875, 0.419672131147541],\n",
       " [2998, 81, 275, 192, 294, 274, True, 0.6435643564356436, 0.5033112582781457],\n",
       " [2998, 81, 276, 103, 267, 224, True, 0.4953271028037383, 0.44011976047904194],\n",
       " [2998, 81, 278, 99, 356, 340, True, 0.41214057507987223, 0.4477124183006536],\n",
       " [2998, 81, 312, 302, 255, 189, True, 0.6195652173913043, 0.6224489795918368],\n",
       " [2998, 81, 317, 158, 410, 309, True, 0.6871165644171779, 0.6805555555555556],\n",
       " [2998, 81, 322, 70, 278, 243, True, 0.4326923076923077, 0.8067796610169492],\n",
       " [2998,\n",
       "  81,\n",
       "  117,\n",
       "  336,\n",
       "  243,\n",
       "  286,\n",
       "  False,\n",
       "  0.4724137931034483,\n",
       "  0.38484848484848483],\n",
       " [2998, 83, 2, 145, 278, 247, True, 0.38144329896907214, 0.37770897832817335],\n",
       " [2998, 83, 4, 279, 336, 247, True, 0.6397694524495677, 0.4967105263157895],\n",
       " [2998, 83, 13, 11, 340, 220, True, 0.5543478260869565, 0.5016722408026756],\n",
       " [2998, 83, 12, 16, 228, 251, False, 0.7409638554216867, 0.35185185185185186],\n",
       " [2998, 83, 14, 17, 305, 317, False, 0.49498327759197325, 0.5240384615384616],\n",
       " [2998, 83, 90, 22, 328, 344, False, 0.4968553459119497, 0.5109034267912772],\n",
       " [2998, 83, 334, 23, 178, 259, False, 0.5924764890282131, 0.46394984326018807],\n",
       " [2998, 83, 38, 165, 274, 259, True, 0.40131578947368424, 0.5621301775147929],\n",
       " [2998, 83, 40, 351, 313, 263, True, 0.6812749003984063, 0.41964285714285715],\n",
       " [2998,\n",
       "  83,\n",
       "  341,\n",
       "  58,\n",
       "  270,\n",
       "  305,\n",
       "  False,\n",
       "  0.40468227424749165,\n",
       "  0.29213483146067415],\n",
       " [2998, 83, 59, 34, 259, 251, True, 0.43217665615141954, 0.9285714285714286],\n",
       " [2998, 83, 60, 219, 348, 255, True, 0.5352112676056338, 0.49823321554770317],\n",
       " [2998, 83, 69, 68, 236, 317, False, 0.4253968253968254, 0.4659090909090909],\n",
       " [2998, 83, 24, 77, 259, 317, False, 0.4482758620689655, 0.5540983606557377],\n",
       " [2998, 83, 118, 78, 313, 321, False, 0.5290697674418605, 0.50814332247557],\n",
       " [2998, 83, 82, 362, 417, 402, True, 0.3938356164383562, 0.25903614457831325],\n",
       " [2998, 83, 193, 91, 309, 336, False, 0.6869009584664537, 0.48589341692789967],\n",
       " [2998, 83, 98, 96, 170, 267, False, 0.4024767801857585, 0.2631578947368421],\n",
       " [2998, 83, 101, 233, 321, 278, True, 0.42528735632183906, 0.6134185303514377],\n",
       " [2998,\n",
       "  83,\n",
       "  254,\n",
       "  102,\n",
       "  228,\n",
       "  348,\n",
       "  False,\n",
       "  0.49498327759197325,\n",
       "  0.6334519572953736],\n",
       " [2998, 83, 97, 103, 251, 274, False, 0.3440514469453376, 0.44011976047904194],\n",
       " [2998,\n",
       "  83,\n",
       "  171,\n",
       "  107,\n",
       "  143,\n",
       "  305,\n",
       "  False,\n",
       "  0.28664495114006516,\n",
       "  0.3384615384615385],\n",
       " [2998, 83, 108, 236, 270, 208, True, 0.5375, 0.5428571428571428],\n",
       " [2998, 83, 146, 110, 309, 313, False, 0.6888888888888889, 0.4732142857142857],\n",
       " [2998, 83, 120, 283, 274, 205, True, 0.5630498533724341, 0.5902777777777778],\n",
       " [2998, 83, 122, 43, 313, 290, True, 0.4722222222222222, 0.40988372093023256],\n",
       " [2998, 83, 126, 3, 359, 336, True, 0.36524822695035464, 0.49498327759197325],\n",
       " [2998,\n",
       "  83,\n",
       "  320,\n",
       "  128,\n",
       "  274,\n",
       "  325,\n",
       "  False,\n",
       "  0.37538461538461537,\n",
       "  0.3498452012383901],\n",
       " [2998, 83, 183, 129, 197, 236, False, 0.541033434650456, 0.4792626728110599],\n",
       " [2998,\n",
       "  83,\n",
       "  285,\n",
       "  131,\n",
       "  297,\n",
       "  317,\n",
       "  False,\n",
       "  0.5180722891566265,\n",
       "  0.38484848484848483],\n",
       " [2998, 83, 201, 133, 332, 387, False, 0.5435435435435435, 0.4375],\n",
       " [2998, 83, 141, 64, 387, 340, True, 0.4937106918238994, 0.5],\n",
       " [2998, 83, 143, 149, 290, 448, False, 0.5495495495495496, 0.5741935483870968],\n",
       " [2998, 83, 106, 151, 344, 387, False, 0.5709677419354838, 0.5760517799352751],\n",
       " [2998, 83, 156, 268, 356, 267, True, 0.48562300319488816, 0.6101083032490975],\n",
       " [2998,\n",
       "  83,\n",
       "  161,\n",
       "  157,\n",
       "  356,\n",
       "  359,\n",
       "  False,\n",
       "  0.5495495495495496,\n",
       "  0.29573170731707316],\n",
       " [2998, 83, 160, 221, 340, 282, True, 0.41823899371069184, 0.5813253012048193],\n",
       " [2998, 83, 164, 19, 267, 197, True, 0.38738738738738737, 0.7454545454545455],\n",
       " [2998, 83, 166, 26, 344, 205, True, 0.6666666666666666, 0.6201298701298701],\n",
       " [2998, 83, 168, 306, 321, 294, True, 0.6480938416422287, 0.6063492063492063],\n",
       " [2998, 83, 175, 93, 290, 255, True, 0.5833333333333334, 0.4911242603550296],\n",
       " [2998, 83, 176, 249, 336, 270, True, 0.5467289719626168, 0.5540540540540541],\n",
       " [2998, 83, 53, 177, 344, 348, False, 0.7088607594936709, 0.29190751445086704],\n",
       " [2998, 83, 180, 299, 348, 325, True, 0.6150627615062761, 0.5132450331125827],\n",
       " [2998, 83, 181, 138, 383, 294, True, 0.6574074074074074, 0.5462962962962963],\n",
       " [2998, 83, 185, 57, 286, 201, True, 0.5752508361204013, 0.5857142857142857],\n",
       " [2998, 83, 186, 281, 398, 352, True, 0.4227941176470588, 0.6423611111111112],\n",
       " [2998, 83, 287, 199, 313, 328, False, 0.5512048192771084, 0.6019417475728155],\n",
       " [2998, 83, 204, 86, 394, 259, True, 0.5657492354740061, 0.6528662420382165],\n",
       " [2998,\n",
       "  83,\n",
       "  262,\n",
       "  205,\n",
       "  321,\n",
       "  336,\n",
       "  False,\n",
       "  0.45482866043613707,\n",
       "  0.43450479233226835],\n",
       " [2998, 83, 207, 298, 414, 228, True, 0.6813880126182965, 0.627831715210356],\n",
       " [2998, 83, 211, 202, 267, 263, True, 0.32967032967032966, 0.675],\n",
       " [2998, 83, 210, 218, 274, 290, False, 0.5169230769230769, 0.5290519877675841],\n",
       " [2998, 83, 188, 228, 313, 557, False, 0.396875, 0.3408360128617363],\n",
       " [2998, 83, 237, 302, 228, 143, True, 0.49127906976744184, 0.6224489795918368],\n",
       " [2998, 83, 147, 243, 178, 181, False, 0.5198019801980198, 0.3853820598006645],\n",
       " [2998, 83, 244, 336, 286, 259, True, 0.5584415584415584, 0.38484848484848483],\n",
       " [2998, 83, 245, 39, 294, 270, True, 0.6314363143631436, 0.2774566473988439],\n",
       " [2998, 83, 248, 116, 290, 263, True, 0.5283018867924528, 0.6102719033232629],\n",
       " [2998, 83, 253, 154, 332, 278, True, 0.40625, 0.5701219512195121],\n",
       " [2998, 83, 256, 132, 286, 220, True, 0.5783132530120482, 0.531055900621118],\n",
       " [2998, 83, 263, 265, 236, 232, True, 0.3122923588039867, 0.5016077170418006],\n",
       " [2998,\n",
       "  83,\n",
       "  20,\n",
       "  275,\n",
       "  336,\n",
       "  414,\n",
       "  False,\n",
       "  0.42857142857142855,\n",
       "  0.35294117647058826],\n",
       " [2998, 83, 276, 261, 274, 267, True, 0.4953271028037383, 0.4854368932038835],\n",
       " [2998, 83, 284, 80, 321, 282, True, 0.34448160535117056, 0.3573667711598746],\n",
       " [2998, 83, 100, 286, 290, 336, False, 0.3356643356643357, 0.4064327485380117],\n",
       " [2998, 83, 234, 288, 236, 267, False, 0.5849673202614379, 0.1875],\n",
       " [2998, 83, 338, 290, 232, 286, False, 0.5502958579881657, 0.3125],\n",
       " [2998, 83, 293, 148, 336, 224, True, 0.7692307692307693, 0.6167247386759582],\n",
       " [2998,\n",
       "  83,\n",
       "  333,\n",
       "  297,\n",
       "  301,\n",
       "  356,\n",
       "  False,\n",
       "  0.6355421686746988,\n",
       "  0.33727810650887574],\n",
       " [2998, 83, 301, 75, 267, 259, True, 0.4709480122324159, 0.603225806451613],\n",
       " [2998, 83, 173, 308, 216, 317, False, 0.3717105263157895, 0.5358255451713395],\n",
       " [2998,\n",
       "  83,\n",
       "  182,\n",
       "  310,\n",
       "  212,\n",
       "  216,\n",
       "  False,\n",
       "  0.39100346020761245,\n",
       "  0.7015503875968992],\n",
       " [2998, 83, 312, 104, 336, 267, True, 0.6195652173913043, 0.5928338762214984],\n",
       " [2998, 83, 314, 33, 236, 220, True, 0.43137254901960786, 0.4938650306748466],\n",
       " [2998, 83, 109, 316, 363, 367, False, 0.4772727272727273, 0.4470198675496689],\n",
       " [2998,\n",
       "  83,\n",
       "  291,\n",
       "  323,\n",
       "  336,\n",
       "  348,\n",
       "  False,\n",
       "  0.36363636363636365,\n",
       "  0.4444444444444444],\n",
       " [2998, 83, 324, 85, 305, 228, True, 0.6696969696969697, 0.6054421768707483],\n",
       " [2998, 83, 226, 325, 297, 305, False, 0.6363636363636364, 0.459546925566343],\n",
       " [2998, 83, 311, 327, 278, 383, False, 0.4662379421221865, 0.519163763066202],\n",
       " [2998, 83, 328, 355, 224, 139, True, 0.6199376947040498, 0.47648902821316613],\n",
       " [2998, 83, 335, 73, 325, 247, True, 0.6318181818181818, 0.43103448275862066],\n",
       " [2998, 83, 92, 344, 228, 259, False, 0.4146341463414634, 0.4420289855072464],\n",
       " [2998, 83, 347, 282, 325, 321, True, 0.515625, 0.5204081632653061],\n",
       " [2998, 83, 348, 250, 286, 232, True, 0.6056338028169014, 0.4117647058823529],\n",
       " [2998, 83, 339, 352, 251, 255, False, 0.5, 0.41776315789473684],\n",
       " [2998, 83, 353, 52, 278, 205, True, 0.5623003194888179, 0.7738853503184714],\n",
       " [2998,\n",
       "  83,\n",
       "  124,\n",
       "  358,\n",
       "  220,\n",
       "  247,\n",
       "  False,\n",
       "  0.2833333333333333,\n",
       "  0.34049079754601225],\n",
       " [2998, 83, 360, 6, 367, 344, True, 0.5133928571428571, 0.5190311418685121],\n",
       " [2998, 83, 364, 247, 290, 270, True, 0.3310104529616725, 0.5486111111111112],\n",
       " [2998,\n",
       "  84,\n",
       "  125,\n",
       "  111,\n",
       "  239,\n",
       "  309,\n",
       "  False,\n",
       "  0.39666666666666667,\n",
       "  0.20699708454810495],\n",
       " [2998, 84, 121, 289, 336, 321, True, 0.5247813411078717, 0.6477987421383647],\n",
       " [2998, 84, 239, 356, 305, 259, True, 0.3854748603351955, 0.6190476190476191],\n",
       " [2998, 84, 69, 260, 228, 309, False, 0.4253968253968254, 0.5450236966824644],\n",
       " [2998, 84, 66, 273, 232, 274, False, 0.6424242424242425, 0.4336569579288026],\n",
       " [2998, 84, 300, 264, 348, 297, True, 0.6363636363636364, 0.48464163822525597],\n",
       " [2998, 84, 361, 220, 232, 212, True, 0.5342465753424658, 0.47315436241610737],\n",
       " [2998, 86, 174, 13, 220, 239, False, 0.5789473684210527, 0.44324324324324327],\n",
       " [2998, 86, 16, 309, 286, 247, True, 0.6470588235294118, 0.3880597014925373],\n",
       " [2998, 86, 263, 29, 263, 309, False, 0.3122923588039867, 0.44904458598726116],\n",
       " [2998, 86, 39, 23, 301, 278, True, 0.7246376811594203, 0.46394984326018807],\n",
       " [2998, 86, 210, 45, 313, 328, False, 0.5169230769230769, 0.5562913907284768],\n",
       " [2998, 86, 51, 279, 278, 259, True, 0.498371335504886, 0.4967105263157895],\n",
       " [2998, 86, 60, 327, 390, 332, True, 0.5352112676056338, 0.519163763066202],\n",
       " [2998, 86, 93, 63, 228, 344, False, 0.5088757396449705, 0.28846153846153844],\n",
       " [2998, 86, 74, 34, 356, 286, True, 0.5391566265060241, 0.9285714285714286],\n",
       " [2998, 86, 141, 90, 348, 425, False, 0.4937106918238994, 0.5015673981191222],\n",
       " [2998, 86, 252, 99, 232, 294, False, 0.4881656804733728, 0.4477124183006536],\n",
       " [2998, 86, 196, 126, 356, 375, False, 0.3829113924050633, 0.6360424028268551],\n",
       " [2998, 86, 52, 127, 309, 371, False, 0.2268370607028754, 0.49523809523809526],\n",
       " [2998, 86, 146, 225, 282, 243, True, 0.6888888888888889, 0.4318181818181818],\n",
       " [2998, 86, 166, 258, 290, 170, True, 0.6666666666666666, 0.5080906148867314],\n",
       " [2998, 86, 168, 251, 321, 267, True, 0.6480938416422287, 0.43962848297213625],\n",
       " [2998, 86, 138, 172, 282, 336, False, 0.4537037037037037, 0.3081395348837209],\n",
       " [2998, 86, 178, 351, 356, 201, True, 0.594059405940594, 0.41964285714285715],\n",
       " [2998, 86, 128, 181, 170, 236, False, 0.6490683229813664, 0.3415384615384615],\n",
       " [2998, 86, 209, 311, 367, 309, True, 0.5464684014869888, 0.5352564102564102],\n",
       " [2998,\n",
       "  86,\n",
       "  352,\n",
       "  230,\n",
       "  317,\n",
       "  321,\n",
       "  False,\n",
       "  0.5841584158415841,\n",
       "  0.39296187683284456],\n",
       " [2998, 86, 65, 238, 181, 332, False, 0.6567164179104478, 0.3106508875739645],\n",
       " [2998, 86, 71, 244, 208, 313, False, 0.3129251700680272, 0.4401294498381877],\n",
       " [2998, 86, 183, 245, 170, 205, False, 0.541033434650456, 0.3675675675675676],\n",
       " [2998, 86, 262, 101, 352, 317, True, 0.45482866043613707, 0.5795454545454546],\n",
       " [2998, 86, 92, 271, 178, 278, False, 0.4146341463414634, 0.439873417721519],\n",
       " [2998, 86, 322, 288, 189, 274, False, 0.4326923076923077, 0.1875],\n",
       " ...]"
      ]
     },
     "execution_count": 459,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_train = []\n",
    "for row in train.values:\n",
    "    a = list(row) + [percentage_of_win[row[2]][0]/percentage_of_win[row[2]][2], percentage_of_win[row[3]][1]/percentage_of_win[row[3]][3]]\n",
    "    new_train.append(a)\n",
    "new_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 3021, 363, 161, 0.42857142857142855, 0.4491017964071856],\n",
       " [1, 3021, 286, 2, 0.5953079178885631, 0.6185567010309279],\n",
       " [2, 3020, 232, 52, 0.5520504731861199, 0.7738853503184714],\n",
       " [3, 3020, 84, 11, 0.46568627450980393, 0.5016722408026756],\n",
       " [4, 3021, 305, 39, 0.47928994082840237, 0.2774566473988439],\n",
       " [5, 3020, 159, 152, 0.39039039039039036, 0.5705882352941176],\n",
       " [6, 3021, 198, 181, 0.4414715719063545, 0.3415384615384615],\n",
       " [7, 3021, 353, 221, 0.5623003194888179, 0.5813253012048193],\n",
       " [8, 3020, 364, 363, 0.3310104529616725, 0.5714285714285714],\n",
       " [9, 3020, 113, 105, 0, 0.6143790849673203],\n",
       " [10, 3020, 225, 168, 0.5681818181818182, 0.3508771929824561],\n",
       " [11, 3020, 198, 164, 0.4414715719063545, 0.6160714285714286],\n",
       " [12, 3020, 256, 83, 0.5783132530120482, 0.6006944444444444],\n",
       " [13, 3020, 200, 133, 0.27631578947368424, 0.4375],\n",
       " [14, 3021, 270, 217, 0.4492753623188406, 0.6052631578947368],\n",
       " [15, 3021, 152, 2, 0.4294117647058823, 0.6185567010309279],\n",
       " [16, 3020, 184, 148, 0.4358974358974359, 0.6167247386759582],\n",
       " [17, 3021, 335, 121, 0.6318181818181818, 0.4738372093023256],\n",
       " [18, 3021, 285, 55, 0.5180722891566265, 0.43722943722943725],\n",
       " [19, 3020, 179, 167, 0.6071428571428571, 0.5],\n",
       " [20, 3021, 232, 147, 0.5520504731861199, 0.47783251231527096],\n",
       " [21, 3020, 281, 65, 0.3576388888888889, 0.3382352941176471],\n",
       " [22, 3020, 112, 89, 0.2551440329218107, 0.6526315789473685],\n",
       " [23, 3021, 311, 92, 0.4662379421221865, 0.5866261398176292],\n",
       " [24, 3020, 343, 161, 0.6183844011142061, 0.4491017964071856],\n",
       " [25, 3021, 359, 311, 0.35655737704918034, 0.5352564102564102],\n",
       " [26, 3021, 287, 62, 0.5512048192771084, 0.5504587155963303],\n",
       " [27, 3021, 159, 97, 0.39039039039039036, 0.6559485530546624],\n",
       " [28, 3020, 354, 334, 0.44200626959247646, 0.409375],\n",
       " [29, 3020, 289, 167, 0.3501577287066246, 0.5],\n",
       " [30, 3021, 305, 148, 0.47928994082840237, 0.6167247386759582],\n",
       " [31, 3020, 230, 134, 0.6088235294117647, 0.3993993993993994],\n",
       " [32, 3021, 303, 43, 0.5352564102564102, 0.40988372093023256],\n",
       " [33, 3021, 287, 43, 0.5512048192771084, 0.40988372093023256],\n",
       " [34, 3021, 260, 241, 0.45714285714285713, 0.7326732673267327],\n",
       " [35, 3020, 363, 217, 0.42857142857142855, 0.6052631578947368],\n",
       " [36, 3021, 287, 179, 0.5512048192771084, 0.3893805309734513],\n",
       " [37, 3021, 148, 93, 0.38461538461538464, 0.4911242603550296],\n",
       " [38, 3020, 159, 10, 0.39039039039039036, 0.5372670807453416],\n",
       " [39, 3021, 117, 96, 0.4724137931034483, 0.2631578947368421],\n",
       " [40, 3020, 203, 25, 0.17391304347826086, 0.34536082474226804],\n",
       " [41, 3021, 247, 134, 0.4529616724738676, 0.3993993993993994],\n",
       " [42, 3020, 300, 225, 0.6363636363636364, 0.4318181818181818],\n",
       " [43, 3021, 292, 204, 0.40414507772020725, 0.4329268292682927],\n",
       " [44, 3021, 347, 294, 0.515625, 0.5531914893617021],\n",
       " [45, 3021, 158, 94, 0.3205574912891986, 0.6512455516014235],\n",
       " [46, 3020, 280, 168, 0.41454545454545455, 0.3508771929824561],\n",
       " [47, 3020, 187, 12, 0.41114982578397213, 0.25903614457831325],\n",
       " [48, 3021, 347, 232, 0.515625, 0.449685534591195],\n",
       " [49, 3020, 315, 206, 0.3137254901960784, 0.7225806451612903],\n",
       " [50, 3020, 334, 178, 0.5924764890282131, 0.40460526315789475],\n",
       " [51, 3021, 159, 20, 0.39039039039039036, 0.5652173913043478],\n",
       " [52, 3020, 182, 126, 0.39100346020761245, 0.6360424028268551],\n",
       " [53, 3020, 297, 273, 0.6607142857142857, 0.4336569579288026],\n",
       " [54, 3020, 315, 264, 0.3137254901960784, 0.48464163822525597],\n",
       " [55, 3021, 267, 54, 0.35555555555555557, 0.7065217391304348],\n",
       " [56, 3021, 331, 327, 0.569078947368421, 0.519163763066202],\n",
       " [57, 3020, 173, 66, 0.3717105263157895, 0.3575757575757576],\n",
       " [58, 3020, 309, 231, 0.6119402985074627, 0.4084507042253521],\n",
       " [59, 3020, 132, 90, 0.470404984423676, 0.5015673981191222],\n",
       " [60, 3021, 343, 320, 0.6183844011142061, 0.6257668711656442],\n",
       " [61, 3021, 246, 15, 0.45622119815668205, 0.7101449275362319],\n",
       " [62, 3021, 303, 139, 0.5352564102564102, 0.5353535353535354],\n",
       " [63, 3021, 199, 93, 0.39805825242718446, 0.4911242603550296],\n",
       " [64, 3021, 254, 235, 0.49498327759197325, 0.39144736842105265],\n",
       " [65, 3020, 291, 237, 0.36363636363636365, 0.5072463768115942],\n",
       " [66, 3021, 222, 108, 0.43450479233226835, 0.46105919003115264],\n",
       " [67, 3020, 313, 246, 0.291970802919708, 0.543778801843318],\n",
       " [68, 3020, 124, 15, 0.2833333333333333, 0.7101449275362319],\n",
       " [69, 3020, 282, 22, 0.4742268041237113, 0.5109034267912772],\n",
       " [70, 3021, 307, 149, 0.5121951219512195, 0.5741935483870968],\n",
       " [71, 3020, 354, 149, 0.44200626959247646, 0.5741935483870968],\n",
       " [72, 3021, 329, 319, 0.6993464052287581, 0.5833333333333334],\n",
       " [73, 3020, 173, 150, 0.3717105263157895, 0.5824915824915825],\n",
       " [74, 3021, 76, 3, 0.4646017699115044, 0.49498327759197325],\n",
       " [75, 3020, 266, 140, 0.2777777777777778, 0.6271186440677966],\n",
       " [76, 3020, 153, 51, 0.5131578947368421, 0.5],\n",
       " [77, 3020, 342, 162, 0.36524822695035464, 0],\n",
       " [78, 3021, 159, 58, 0.39039039039039036, 0.29213483146067415],\n",
       " [79, 3020, 235, 135, 0.6085526315789473, 0.4380664652567976],\n",
       " [80, 3020, 134, 23, 0.5993975903614458, 0.46394984326018807],\n",
       " [81, 3020, 113, 14, 0, 0.5033333333333333],\n",
       " [82, 3020, 359, 251, 0.35655737704918034, 0.43962848297213625],\n",
       " [83, 3020, 306, 258, 0.39490445859872614, 0.5080906148867314],\n",
       " [84, 3020, 206, 39, 0.2783171521035599, 0.2774566473988439],\n",
       " [85, 3020, 356, 109, 0.3821656050955414, 0.5227272727272727],\n",
       " [86, 3021, 165, 37, 0.4391691394658754, 0.43934426229508194],\n",
       " [87, 3020, 76, 50, 0.4646017699115044, 0.414985590778098],\n",
       " [88, 3021, 279, 180, 0.5032894736842105, 0.38333333333333336],\n",
       " [89, 3020, 269, 81, 0.36789297658862874, 0.125],\n",
       " [90, 3021, 97, 59, 0.3440514469453376, 0.5691823899371069],\n",
       " [91, 3020, 165, 139, 0.4391691394658754, 0.5353535353535354],\n",
       " [92, 3020, 105, 89, 0.38562091503267976, 0.6526315789473685],\n",
       " [93, 3020, 341, 54, 0.40468227424749165, 0.7065217391304348],\n",
       " [94, 3021, 364, 257, 0.3310104529616725, 0.6149732620320856],\n",
       " [95, 3020, 215, 102, 0.4057971014492754, 0.6334519572953736],\n",
       " [96, 3020, 163, 45, 0.46710526315789475, 0.5562913907284768],\n",
       " [97, 3020, 340, 119, 0.3333333333333333, 0.6042780748663101],\n",
       " [98, 3020, 204, 127, 0.5657492354740061, 0.49523809523809526],\n",
       " [99, 3020, 335, 46, 0.6318181818181818, 0.7553191489361702],\n",
       " [100, 3021, 238, 214, 0.6893491124260355, 0.22285714285714286],\n",
       " [101, 3021, 279, 7, 0.5032894736842105, 0.5056179775280899],\n",
       " [102, 3021, 314, 172, 0.43137254901960786, 0.3081395348837209],\n",
       " [103, 3021, 182, 173, 0.39100346020761245, 0.6295081967213115],\n",
       " [104, 3020, 339, 278, 0.5, 0.5859872611464968],\n",
       " [105, 3021, 320, 136, 0.37538461538461537, 0.6405228758169934],\n",
       " [106, 3020, 209, 117, 0.5464684014869888, 0.5275862068965518],\n",
       " [107, 3021, 350, 82, 0.44072948328267475, 0.6040955631399317],\n",
       " [108, 3021, 270, 50, 0.4492753623188406, 0.414985590778098],\n",
       " [109, 3020, 281, 139, 0.3576388888888889, 0.5353535353535354],\n",
       " [110, 3020, 168, 95, 0.6480938416422287, 0.6071428571428571],\n",
       " [111, 3020, 337, 317, 0.6346153846153846, 0.3119266055045872],\n",
       " [112, 3020, 316, 29, 0.5514950166112956, 0.44904458598726116],\n",
       " [113, 3020, 307, 165, 0.5121951219512195, 0.5621301775147929],\n",
       " [114, 3020, 308, 11, 0.4625, 0.5016722408026756],\n",
       " [115, 3021, 351, 81, 0.5765765765765766, 0.125],\n",
       " [116, 3020, 153, 134, 0.5131578947368421, 0.3993993993993994],\n",
       " [117, 3021, 264, 106, 0.515358361774744, 0.42765273311897106],\n",
       " [118, 3020, 343, 265, 0.6183844011142061, 0.5016077170418006],\n",
       " [119, 3020, 188, 61, 0.396875, 0.4966442953020134],\n",
       " [120, 3020, 93, 5, 0.5088757396449705, 0.5959595959595959],\n",
       " [121, 3021, 325, 247, 0.540453074433657, 0.5486111111111112],\n",
       " [122, 3020, 187, 43, 0.41114982578397213, 0.40988372093023256],\n",
       " [123, 3020, 274, 167, 0.45874587458745875, 0.5],\n",
       " [124, 3021, 248, 192, 0.5283018867924528, 0.5033112582781457],\n",
       " [125, 3020, 80, 17, 0.6426332288401254, 0.5240384615384616],\n",
       " [126, 3021, 127, 63, 0.5047619047619047, 0.28846153846153844],\n",
       " [127, 3020, 361, 10, 0.5342465753424658, 0.5372670807453416],\n",
       " [128, 3021, 325, 112, 0.540453074433657, 0.7459016393442623],\n",
       " [129, 3021, 221, 216, 0.4169184290030212, 0.7321428571428571],\n",
       " [130, 3020, 348, 125, 0.6056338028169014, 0.6033333333333334],\n",
       " [131, 3021, 358, 167, 0.6595092024539877, 0.5],\n",
       " [132, 3020, 184, 1, 0.4358974358974359, 0],\n",
       " [133, 3020, 358, 112, 0.6595092024539877, 0.7459016393442623],\n",
       " [134, 3021, 258, 55, 0.4935064935064935, 0.43722943722943725],\n",
       " [135, 3021, 179, 170, 0.6071428571428571, 0.5507246376811594],\n",
       " [136, 3020, 273, 235, 0.564935064935065, 0.39144736842105265],\n",
       " [137, 3021, 292, 206, 0.40414507772020725, 0.7225806451612903],\n",
       " [138, 3021, 64, 13, 0.4984025559105431, 0.44324324324324327],\n",
       " [139, 3020, 116, 91, 0.39090909090909093, 0.48589341692789967],\n",
       " [140, 3020, 302, 286, 0.378839590443686, 0.4064327485380117],\n",
       " [141, 3020, 261, 1, 0.5145631067961165, 0],\n",
       " [142, 3020, 270, 91, 0.4492753623188406, 0.48589341692789967],\n",
       " [143, 3020, 169, 40, 0.6170212765957447, 0.31746031746031744],\n",
       " [144, 3020, 107, 85, 0.6615384615384615, 0.6054421768707483],\n",
       " [145, 3021, 284, 251, 0.34448160535117056, 0.43962848297213625],\n",
       " [146, 3021, 152, 119, 0.4294117647058823, 0.6042780748663101],\n",
       " [147, 3020, 357, 145, 0.48214285714285715, 0.37770897832817335],\n",
       " [148, 3021, 62, 27, 0.4444444444444444, 0.6104651162790697],\n",
       " [149, 3020, 258, 173, 0.4935064935064935, 0.6295081967213115],\n",
       " [150, 3020, 335, 95, 0.6318181818181818, 0.6071428571428571],\n",
       " [151, 3021, 194, 10, 0.3203125, 0.5372670807453416],\n",
       " [152, 3020, 323, 85, 0.5540983606557377, 0.6054421768707483],\n",
       " [153, 3021, 288, 209, 0.8105263157894737, 0.45185185185185184],\n",
       " [154, 3020, 248, 124, 0.5283018867924528, 0.7166666666666667],\n",
       " [155, 3020, 188, 19, 0.396875, 0.7454545454545455],\n",
       " [156, 3020, 303, 135, 0.5352564102564102, 0.4380664652567976],\n",
       " [157, 3021, 180, 11, 0.6150627615062761, 0.5016722408026756],\n",
       " [158, 3020, 241, 185, 0.2682119205298013, 0.42333333333333334],\n",
       " [159, 3021, 212, 95, 0.25, 0.6071428571428571],\n",
       " [160, 3020, 293, 106, 0.7692307692307693, 0.42765273311897106],\n",
       " [161, 3021, 83, 24, 0.3993055555555556, 0.5517241379310345],\n",
       " [162, 3021, 216, 90, 0.26785714285714285, 0.5015673981191222],\n",
       " [163, 3020, 310, 36, 0.29961089494163423, 0.7014925373134329],\n",
       " [164, 3020, 196, 171, 0.3829113924050633, 0.7133550488599348],\n",
       " [165, 3021, 172, 107, 0.6938775510204082, 0.3384615384615385],\n",
       " [166, 3021, 357, 91, 0.48214285714285715, 0.48589341692789967],\n",
       " [167, 3021, 342, 258, 0.36524822695035464, 0.5080906148867314],\n",
       " [168, 3020, 274, 228, 0.45874587458745875, 0.3408360128617363],\n",
       " [169, 3020, 294, 214, 0.44680851063829785, 0.22285714285714286],\n",
       " [170, 3020, 298, 140, 0.37337662337662336, 0.6271186440677966],\n",
       " [171, 3020, 356, 86, 0.3821656050955414, 0.6528662420382165],\n",
       " [172, 3020, 68, 19, 0.5287356321839081, 0.7454545454545455],\n",
       " [173, 3020, 266, 142, 0.2777777777777778, 0.18711656441717792],\n",
       " [174, 3020, 254, 65, 0.49498327759197325, 0.3382352941176471],\n",
       " [175, 3020, 359, 265, 0.35655737704918034, 0.5016077170418006],\n",
       " [176, 3020, 357, 327, 0.48214285714285715, 0.519163763066202],\n",
       " [177, 3021, 323, 201, 0.5540983606557377, 0.4550898203592814],\n",
       " [178, 3021, 348, 194, 0.6056338028169014, 0.6796875],\n",
       " [179, 3021, 177, 83, 0.7072463768115942, 0.6006944444444444],\n",
       " [180, 3020, 336, 13, 0.6139817629179332, 0.44324324324324327],\n",
       " [181, 3020, 283, 81, 0.4076655052264808, 0.125],\n",
       " [182, 3020, 131, 46, 0.6139817629179332, 0.7553191489361702],\n",
       " [183, 3021, 198, 147, 0.4414715719063545, 0.47783251231527096],\n",
       " [184, 3020, 175, 91, 0.5833333333333334, 0.48589341692789967],\n",
       " [185, 3020, 210, 143, 0.5169230769230769, 0.4491017964071856],\n",
       " [186, 3020, 222, 68, 0.43450479233226835, 0.4659090909090909],\n",
       " [187, 3021, 331, 155, 0.569078947368421, 0.752],\n",
       " [188, 3021, 351, 281, 0.5765765765765766, 0.6423611111111112],\n",
       " [189, 3020, 325, 179, 0.540453074433657, 0.3893805309734513],\n",
       " [190, 3021, 323, 45, 0.5540983606557377, 0.5562913907284768],\n",
       " [191, 3020, 326, 259, 0.46689895470383275, 0.49828178694158076],\n",
       " [192, 3021, 180, 8, 0.6150627615062761, 0.6466666666666666],\n",
       " [193, 3020, 158, 37, 0.3205574912891986, 0.43934426229508194],\n",
       " [194, 3020, 127, 44, 0.5047619047619047, 0.6510416666666666],\n",
       " [195, 3020, 267, 236, 0.35555555555555557, 0.5428571428571428],\n",
       " [196, 3021, 277, 245, 0.4915254237288136, 0.3675675675675676],\n",
       " [197, 3020, 23, 12, 0.5360501567398119, 0.25903614457831325],\n",
       " [198, 3020, 261, 143, 0.5145631067961165, 0.4491017964071856],\n",
       " [199, 3020, 325, 70, 0.540453074433657, 0.8067796610169492],\n",
       " [200, 3021, 359, 128, 0.35655737704918034, 0.3498452012383901],\n",
       " [201, 3020, 287, 80, 0.5512048192771084, 0.3573667711598746],\n",
       " [202, 3021, 354, 80, 0.44200626959247646, 0.3573667711598746],\n",
       " [203, 3021, 291, 75, 0.36363636363636365, 0.603225806451613],\n",
       " [204, 3021, 200, 199, 0.27631578947368424, 0.6019417475728155],\n",
       " [205, 3021, 181, 54, 0.6574074074074074, 0.7065217391304348],\n",
       " [206, 3020, 265, 175, 0.5, 0.4166666666666667],\n",
       " [207, 3021, 311, 37, 0.4662379421221865, 0.43934426229508194],\n",
       " [208, 3021, 330, 183, 0.5867768595041323, 0.45896656534954405],\n",
       " [209, 3020, 129, 122, 0.5185185185185185, 0.5261538461538462],\n",
       " [210, 3021, 311, 236, 0.4662379421221865, 0.5428571428571428],\n",
       " [211, 3020, 340, 221, 0.3333333333333333, 0.5813253012048193],\n",
       " [212, 3020, 265, 17, 0.5, 0.5240384615384616],\n",
       " [213, 3020, 355, 287, 0.5220125786163522, 0.45045045045045046],\n",
       " [214, 3020, 196, 122, 0.3829113924050633, 0.5261538461538462],\n",
       " [215, 3020, 207, 66, 0.6813880126182965, 0.3575757575757576],\n",
       " [216, 3020, 143, 73, 0.5495495495495496, 0.43103448275862066],\n",
       " [217, 3021, 204, 38, 0.5657492354740061, 0.6],\n",
       " [218, 3021, 319, 199, 0.4166666666666667, 0.6019417475728155],\n",
       " [219, 3021, 56, 19, 0.44299674267100975, 0.7454545454545455],\n",
       " [220, 3020, 106, 95, 0.5709677419354838, 0.6071428571428571],\n",
       " [221, 3020, 242, 53, 0.24242424242424243, 0.2875],\n",
       " [222, 3021, 220, 99, 0.5252525252525253, 0.4477124183006536],\n",
       " [223, 3020, 186, 80, 0.4227941176470588, 0.3573667711598746],\n",
       " [224, 3021, 357, 190, 0.48214285714285715, 0.5777777777777777],\n",
       " [225, 3021, 195, 95, 0.5306122448979592, 0.6071428571428571],\n",
       " [226, 3021, 306, 250, 0.39490445859872614, 0.4117647058823529],\n",
       " [227, 3021, 182, 129, 0.39100346020761245, 0.4792626728110599],\n",
       " [228, 3021, 168, 60, 0.6480938416422287, 0.46261682242990654],\n",
       " [229, 3020, 232, 110, 0.5520504731861199, 0.4732142857142857],\n",
       " [230, 3020, 255, 40, 0.48854961832061067, 0.31746031746031744],\n",
       " [231, 3021, 215, 23, 0.4057971014492754, 0.46394984326018807],\n",
       " [232, 3020, 360, 117, 0.5133928571428571, 0.5275862068965518],\n",
       " [233, 3021, 219, 11, 0.5017667844522968, 0.5016722408026756],\n",
       " [234, 3020, 249, 5, 0.4440677966101695, 0.5959595959595959],\n",
       " [235, 3020, 205, 128, 0.5673076923076923, 0.3498452012383901],\n",
       " [236, 3020, 139, 7, 0.46283783783783783, 0.5056179775280899],\n",
       " [237, 3020, 255, 159, 0.48854961832061067, 0.6107784431137725],\n",
       " [238, 3020, 153, 69, 0.5131578947368421, 0.5759493670886076],\n",
       " [239, 3021, 294, 239, 0.44680851063829785, 0.6111111111111112],\n",
       " [240, 3021, 269, 191, 0.36789297658862874, 0.5422077922077922],\n",
       " [241, 3021, 316, 167, 0.5514950166112956, 0.5],\n",
       " [242, 3020, 155, 88, 0.248, 0.8461538461538461],\n",
       " [243, 3021, 208, 129, 0.6059602649006622, 0.4792626728110599],\n",
       " [244, 3020, 90, 75, 0.4968553459119497, 0.603225806451613],\n",
       " [245, 3021, 263, 156, 0.3122923588039867, 0.5143769968051118],\n",
       " [246, 3021, 353, 157, 0.5623003194888179, 0.29573170731707316],\n",
       " [247, 3020, 339, 171, 0.5, 0.7133550488599348],\n",
       " [248, 3021, 206, 172, 0.2783171521035599, 0.3081395348837209],\n",
       " [249, 3020, 194, 73, 0.3203125, 0.43103448275862066],\n",
       " [250, 3021, 308, 168, 0.4625, 0.3508771929824561],\n",
       " [251, 3021, 100, 48, 0.3356643356643357, 0.5217391304347826],\n",
       " [252, 3021, 162, 111, 0, 0.20699708454810495],\n",
       " [253, 3020, 167, 145, 0.5016181229773463, 0.37770897832817335],\n",
       " [254, 3021, 213, 46, 0.4574898785425101, 0.7553191489361702],\n",
       " [255, 3021, 358, 54, 0.6595092024539877, 0.7065217391304348],\n",
       " [256, 3020, 362, 358, 0.7409638554216867, 0.34049079754601225],\n",
       " [257, 3020, 170, 86, 0.4492753623188406, 0.6528662420382165],\n",
       " [258, 3020, 358, 342, 0.6595092024539877, 0.6360424028268551],\n",
       " [259, 3021, 102, 48, 0.3678571428571429, 0.5217391304347826],\n",
       " [260, 3021, 273, 252, 0.564935064935065, 0.5118343195266272],\n",
       " [261, 3021, 339, 155, 0.5, 0.752],\n",
       " [262, 3021, 360, 300, 0.5133928571428571, 0.3626062322946176],\n",
       " [263, 3020, 164, 54, 0.38738738738738737, 0.7065217391304348],\n",
       " [264, 3021, 357, 136, 0.48214285714285715, 0.6405228758169934],\n",
       " [265, 3021, 118, 15, 0.5290697674418605, 0.7101449275362319],\n",
       " [266, 3020, 304, 51, 0.2518248175182482, 0.5],\n",
       " [267, 3021, 308, 79, 0.4625, 0.6203389830508474],\n",
       " [268, 3020, 257, 5, 0.3850267379679144, 0.5959595959595959],\n",
       " [269, 3020, 286, 16, 0.5953079178885631, 0.35185185185185186],\n",
       " [270, 3021, 297, 268, 0.6607142857142857, 0.6101083032490975],\n",
       " [271, 3021, 256, 245, 0.5783132530120482, 0.3675675675675676],\n",
       " [272, 3020, 347, 124, 0.515625, 0.7166666666666667],\n",
       " [273, 3020, 72, 62, 0.6510067114093959, 0.5504587155963303],\n",
       " [274, 3020, 152, 95, 0.4294117647058823, 0.6071428571428571],\n",
       " [275, 3020, 141, 105, 0.4937106918238994, 0.6143790849673203],\n",
       " [276, 3021, 344, 240, 0.5563636363636364, 0.5174129353233831],\n",
       " [277, 3021, 249, 52, 0.4440677966101695, 0.7738853503184714],\n",
       " [278, 3021, 303, 113, 0.5352564102564102, 0],\n",
       " [279, 3020, 24, 22, 0.4482758620689655, 0.5109034267912772],\n",
       " [280, 3021, 209, 62, 0.5464684014869888, 0.5504587155963303],\n",
       " [281, 3020, 291, 199, 0.36363636363636365, 0.6019417475728155],\n",
       " [282, 3020, 319, 296, 0.4166666666666667, 0.3123123123123123],\n",
       " [283, 3020, 205, 170, 0.5673076923076923, 0.5507246376811594],\n",
       " [284, 3021, 149, 133, 0.4258064516129032, 0.4375],\n",
       " [285, 3020, 262, 13, 0.45482866043613707, 0.44324324324324327],\n",
       " [286, 3021, 205, 109, 0.5673076923076923, 0.5227272727272727],\n",
       " [287, 3020, 328, 68, 0.6199376947040498, 0.4659090909090909],\n",
       " [288, 3020, 263, 29, 0.3122923588039867, 0.44904458598726116],\n",
       " [289, 3020, 357, 220, 0.48214285714285715, 0.47315436241610737],\n",
       " [290, 3021, 295, 135, 0.47384615384615386, 0.4380664652567976],\n",
       " [291, 3020, 300, 263, 0.6363636363636364, 0.6877076411960132],\n",
       " [292, 3020, 363, 358, 0.42857142857142855, 0.34049079754601225],\n",
       " [293, 3021, 276, 135, 0.4953271028037383, 0.4380664652567976],\n",
       " [294, 3021, 234, 135, 0.5849673202614379, 0.4380664652567976],\n",
       " [295, 3020, 336, 205, 0.6139817629179332, 0.43450479233226835],\n",
       " [296, 3020, 259, 124, 0.5, 0.7166666666666667],\n",
       " [297, 3021, 329, 328, 0.6993464052287581, 0.37888198757763975],\n",
       " [298, 3020, 357, 35, 0.48214285714285715, 0.5912162162162162],\n",
       " [299, 3021, 239, 192, 0.3854748603351955, 0.5033112582781457],\n",
       " [300, 3020, 267, 213, 0.35555555555555557, 0.5425101214574899],\n",
       " [301, 3020, 249, 69, 0.4440677966101695, 0.5759493670886076],\n",
       " [302, 3020, 245, 196, 0.6314363143631436, 0.6182965299684543],\n",
       " [303, 3021, 65, 43, 0.6567164179104478, 0.40988372093023256],\n",
       " [304, 3021, 178, 3, 0.594059405940594, 0.49498327759197325],\n",
       " [305, 3020, 344, 308, 0.5563636363636364, 0.5358255451713395],\n",
       " [306, 3020, 316, 68, 0.5514950166112956, 0.4659090909090909],\n",
       " [307, 3020, 278, 197, 0.41214057507987223, 0.6875],\n",
       " [308, 3021, 87, 10, 0.40273037542662116, 0.5372670807453416],\n",
       " [309, 3020, 231, 61, 0.5943396226415094, 0.4966442953020134],\n",
       " [310, 3020, 236, 98, 0.45714285714285713, 0.5975232198142415],\n",
       " [311, 3020, 314, 217, 0.43137254901960786, 0.6052631578947368],\n",
       " [312, 3020, 238, 167, 0.6893491124260355, 0.5],\n",
       " [313, 3020, 317, 176, 0.6871165644171779, 0.4511627906976744],\n",
       " [314, 3020, 290, 160, 0.6875, 0.5830721003134797],\n",
       " [315, 3021, 320, 256, 0.37538461538461537, 0.42042042042042044],\n",
       " [316, 3020, 269, 87, 0.36789297658862874, 0.5986394557823129],\n",
       " [317, 3021, 211, 50, 0.32967032967032966, 0.414985590778098],\n",
       " [318, 3021, 328, 3, 0.6199376947040498, 0.49498327759197325],\n",
       " [319, 3021, 344, 81, 0.5563636363636364, 0.125],\n",
       " [320, 3021, 237, 225, 0.49127906976744184, 0.4318181818181818],\n",
       " [321, 3021, 209, 153, 0.5464684014869888, 0.4868421052631579],\n",
       " [322, 3020, 122, 108, 0.4722222222222222, 0.46105919003115264],\n",
       " [323, 3020, 274, 7, 0.45874587458745875, 0.5056179775280899],\n",
       " [324, 3020, 234, 223, 0.5849673202614379, 0.27631578947368424],\n",
       " [325, 3020, 214, 95, 0.7771428571428571, 0.6071428571428571],\n",
       " [326, 3020, 324, 255, 0.6696969696969697, 0.5114503816793893],\n",
       " [327, 3021, 63, 52, 0.7087378640776699, 0.7738853503184714],\n",
       " [328, 3020, 336, 12, 0.6139817629179332, 0.25903614457831325],\n",
       " [329, 3021, 359, 254, 0.35655737704918034, 0.5066666666666667],\n",
       " [330, 3020, 364, 209, 0.3310104529616725, 0.45185185185185184],\n",
       " [331, 3020, 258, 76, 0.4935064935064935, 0.5353982300884956],\n",
       " [332, 3020, 325, 318, 0.540453074433657, 0.5062111801242236],\n",
       " [333, 3021, 271, 26, 0.560126582278481, 0.6201298701298701],\n",
       " [334, 3021, 210, 166, 0.5169230769230769, 0.3323262839879154],\n",
       " [335, 3021, 218, 23, 0.4723926380368098, 0.46394984326018807],\n",
       " [336, 3021, 266, 225, 0.2777777777777778, 0.4318181818181818],\n",
       " [337, 3020, 138, 45, 0.4537037037037037, 0.5562913907284768],\n",
       " [338, 3020, 126, 16, 0.36524822695035464, 0.35185185185185186],\n",
       " [339, 3021, 172, 171, 0.6938775510204082, 0.7133550488599348],\n",
       " [340, 3021, 86, 80, 0.3471337579617834, 0.3573667711598746],\n",
       " [341, 3021, 302, 116, 0.378839590443686, 0.6102719033232629],\n",
       " [342, 3020, 151, 37, 0.42207792207792205, 0.43934426229508194],\n",
       " [343, 3020, 135, 80, 0.5606060606060606, 0.3573667711598746],\n",
       " [344, 3020, 238, 55, 0.6893491124260355, 0.43722943722943725],\n",
       " [345, 3021, 342, 334, 0.36524822695035464, 0.409375],\n",
       " [346, 3021, 325, 140, 0.540453074433657, 0.6271186440677966],\n",
       " [347, 3021, 344, 229, 0.5563636363636364, 0.3117283950617284],\n",
       " [348, 3020, 178, 130, 0.594059405940594, 0],\n",
       " [349, 3020, 204, 99, 0.5657492354740061, 0.4477124183006536],\n",
       " [350, 3020, 355, 326, 0.5220125786163522, 0.5347222222222222],\n",
       " [351, 3020, 309, 237, 0.6119402985074627, 0.5072463768115942],\n",
       " [352, 3020, 229, 123, 0.6873065015479877, 0.7763157894736842],\n",
       " [353, 3020, 155, 63, 0.248, 0.28846153846153844],\n",
       " [354, 3021, 300, 56, 0.6363636363636364, 0.5584415584415584],\n",
       " [355, 3020, 268, 19, 0.391304347826087, 0.7454545454545455],\n",
       " [356, 3020, 349, 200, 0.5620915032679739, 0.7236842105263158],\n",
       " [357, 3021, 254, 143, 0.49498327759197325, 0.4491017964071856],\n",
       " [358, 3020, 247, 103, 0.4529616724738676, 0.44011976047904194],\n",
       " [359, 3020, 244, 50, 0.5584415584415584, 0.414985590778098],\n",
       " [360, 3020, 357, 60, 0.48214285714285715, 0.46261682242990654],\n",
       " [361, 3021, 183, 141, 0.541033434650456, 0.5047021943573667],\n",
       " [362, 3021, 182, 178, 0.39100346020761245, 0.40460526315789475],\n",
       " [363, 3020, 180, 172, 0.6150627615062761, 0.3081395348837209],\n",
       " [364, 3021, 244, 33, 0.5584415584415584, 0.4938650306748466],\n",
       " [365, 3020, 307, 270, 0.5121951219512195, 0.5507246376811594],\n",
       " [366, 3021, 281, 272, 0.3576388888888889, 0.46938775510204084],\n",
       " [367, 3020, 138, 57, 0.4537037037037037, 0.5857142857142857],\n",
       " [368, 3020, 193, 150, 0.6869009584664537, 0.5824915824915825],\n",
       " [369, 3021, 352, 1, 0.5841584158415841, 0],\n",
       " [370, 3020, 257, 48, 0.3850267379679144, 0.5217391304347826],\n",
       " [371, 3021, 276, 215, 0.4953271028037383, 0.5942028985507246],\n",
       " [372, 3021, 348, 270, 0.6056338028169014, 0.5507246376811594],\n",
       " [373, 3020, 349, 15, 0.5620915032679739, 0.7101449275362319],\n",
       " [374, 3020, 191, 10, 0.4592833876221498, 0.5372670807453416],\n",
       " [375, 3020, 207, 22, 0.6813880126182965, 0.5109034267912772],\n",
       " [376, 3021, 293, 84, 0.7692307692307693, 0.5365853658536586],\n",
       " [377, 3021, 218, 42, 0.4723926380368098, 0.6367041198501873],\n",
       " [378, 3020, 192, 142, 0.4950166112956811, 0.18711656441717792],\n",
       " [379, 3020, 183, 170, 0.541033434650456, 0.5507246376811594],\n",
       " [380, 3021, 173, 121, 0.3717105263157895, 0.4738372093023256],\n",
       " [381, 3020, 230, 147, 0.6088235294117647, 0.47783251231527096],\n",
       " [382, 3020, 225, 186, 0.5681818181818182, 0.5787545787545788],\n",
       " [383, 3021, 223, 81, 0.72, 0.125],\n",
       " [384, 3020, 284, 142, 0.34448160535117056, 0.18711656441717792],\n",
       " [385, 3021, 339, 166, 0.5, 0.3323262839879154],\n",
       " [386, 3021, 58, 6, 0.7045454545454546, 0.5190311418685121],\n",
       " [387, 3020, 230, 213, 0.6088235294117647, 0.5425101214574899],\n",
       " [388, 3020, 137, 103, 0.5321100917431193, 0.44011976047904194],\n",
       " [389, 3020, 356, 218, 0.3821656050955414, 0.5290519877675841],\n",
       " [390, 3021, 321, 252, 0.4189189189189189, 0.5118343195266272],\n",
       " [391, 3020, 183, 58, 0.541033434650456, 0.29213483146067415],\n",
       " [392, 3021, 274, 80, 0.45874587458745875, 0.3573667711598746],\n",
       " [393, 3020, 355, 279, 0.5220125786163522, 0.4967105263157895],\n",
       " [394, 3020, 262, 250, 0.45482866043613707, 0.4117647058823529],\n",
       " [395, 3020, 220, 187, 0.5252525252525253, 0.5902777777777778],\n",
       " [396, 3021, 162, 131, 0, 0.38484848484848483],\n",
       " [397, 3020, 293, 45, 0.7692307692307693, 0.5562913907284768],\n",
       " [398, 3021, 277, 180, 0.4915254237288136, 0.38333333333333336],\n",
       " [399, 3021, 225, 91, 0.5681818181818182, 0.48589341692789967],\n",
       " [400, 3020, 241, 92, 0.2682119205298013, 0.5866261398176292],\n",
       " [401, 3021, 351, 82, 0.5765765765765766, 0.6040955631399317],\n",
       " [402, 3020, 168, 23, 0.6480938416422287, 0.46394984326018807],\n",
       " [403, 3020, 238, 216, 0.6893491124260355, 0.7321428571428571],\n",
       " [404, 3021, 205, 43, 0.5673076923076923, 0.40988372093023256],\n",
       " [405, 3021, 354, 27, 0.44200626959247646, 0.6104651162790697],\n",
       " [406, 3020, 244, 91, 0.5584415584415584, 0.48589341692789967],\n",
       " [407, 3021, 234, 147, 0.5849673202614379, 0.47783251231527096],\n",
       " [408, 3020, 124, 106, 0.2833333333333333, 0.42765273311897106],\n",
       " [409, 3021, 99, 24, 0.5508196721311476, 0.5517241379310345],\n",
       " [410, 3020, 136, 11, 0.35947712418300654, 0.5016722408026756],\n",
       " [411, 3021, 279, 208, 0.5032894736842105, 0.3927392739273927],\n",
       " [412, 3021, 162, 57, 0, 0.5857142857142857],\n",
       " [413, 3021, 356, 123, 0.3821656050955414, 0.7763157894736842],\n",
       " [414, 3021, 236, 100, 0.45714285714285713, 0.6643356643356644],\n",
       " [415, 3021, 140, 12, 0.3728813559322034, 0.25903614457831325],\n",
       " [416, 3020, 231, 50, 0.5943396226415094, 0.414985590778098],\n",
       " [417, 3020, 240, 94, 0.48258706467661694, 0.6512455516014235],\n",
       " [418, 3021, 167, 163, 0.5016181229773463, 0.5344262295081967],\n",
       " [419, 3020, 101, 5, 0.42528735632183906, 0.5959595959595959],\n",
       " [420, 3021, 295, 292, 0.47384615384615386, 0.5958549222797928],\n",
       " [421, 3021, 241, 165, 0.2682119205298013, 0.5621301775147929],\n",
       " [422, 3020, 92, 73, 0.4146341463414634, 0.43103448275862066],\n",
       " [423, 3020, 324, 7, 0.6696969696969697, 0.5056179775280899],\n",
       " [424, 3021, 245, 125, 0.6314363143631436, 0.6033333333333334],\n",
       " [425, 3020, 85, 58, 0.3924914675767918, 0.29213483146067415],\n",
       " [426, 3020, 280, 144, 0.41454545454545455, 0.7387387387387387],\n",
       " [427, 3020, 361, 199, 0.5342465753424658, 0.6019417475728155],\n",
       " [428, 3020, 313, 10, 0.291970802919708, 0.5372670807453416],\n",
       " [429, 3021, 356, 336, 0.3821656050955414, 0.38484848484848483],\n",
       " [430, 3021, 360, 266, 0.5133928571428571, 0.7222222222222222],\n",
       " [431, 3020, 72, 22, 0.6510067114093959, 0.5109034267912772],\n",
       " [432, 3020, 257, 99, 0.3850267379679144, 0.4477124183006536],\n",
       " [433, 3020, 243, 222, 0.6133333333333333, 0.5654952076677316],\n",
       " [434, 3020, 290, 72, 0.6875, 0.348993288590604],\n",
       " [435, 3021, 256, 111, 0.5783132530120482, 0.20699708454810495],\n",
       " [436, 3021, 129, 23, 0.5185185185185185, 0.46394984326018807],\n",
       " [437, 3020, 289, 166, 0.3501577287066246, 0.3323262839879154],\n",
       " [438, 3021, 236, 128, 0.45714285714285713, 0.3498452012383901],\n",
       " [439, 3021, 339, 162, 0.5, 0],\n",
       " [440, 3020, 269, 148, 0.36789297658862874, 0.6167247386759582],\n",
       " [441, 3020, 248, 241, 0.5283018867924528, 0.7326732673267327],\n",
       " [442, 3020, 64, 15, 0.4984025559105431, 0.7101449275362319],\n",
       " [443, 3020, 172, 161, 0.6938775510204082, 0.4491017964071856],\n",
       " [444, 3020, 238, 77, 0.6893491124260355, 0.5540983606557377],\n",
       " [445, 3021, 212, 211, 0.25, 0.6678832116788321],\n",
       " [446, 3020, 174, 36, 0.5789473684210527, 0.7014925373134329],\n",
       " [447, 3020, 306, 298, 0.39490445859872614, 0.627831715210356],\n",
       " [448, 3020, 232, 155, 0.5520504731861199, 0.752],\n",
       " [449, 3020, 224, 16, 0.5458937198067633, 0.35185185185185186],\n",
       " [450, 3021, 233, 75, 0.38461538461538464, 0.603225806451613],\n",
       " [451, 3020, 339, 42, 0.5, 0.6367041198501873],\n",
       " [452, 3020, 281, 142, 0.3576388888888889, 0.18711656441717792],\n",
       " [453, 3020, 229, 193, 0.6873065015479877, 0.31309904153354634],\n",
       " [454, 3021, 134, 74, 0.5993975903614458, 0.4624624624624625],\n",
       " [455, 3021, 260, 89, 0.45714285714285713, 0.6526315789473685],\n",
       " [456, 3021, 273, 174, 0.564935064935065, 0.419672131147541],\n",
       " [457, 3020, 331, 111, 0.569078947368421, 0.20699708454810495],\n",
       " [458, 3021, 279, 59, 0.5032894736842105, 0.5691823899371069],\n",
       " [459, 3021, 102, 8, 0.3678571428571429, 0.6466666666666666],\n",
       " [460, 3021, 228, 66, 0.6580645161290323, 0.3575757575757576],\n",
       " [461, 3020, 128, 97, 0.6490683229813664, 0.6559485530546624],\n",
       " [462, 3021, 168, 49, 0.6480938416422287, 0.6440677966101694],\n",
       " [463, 3021, 240, 173, 0.48258706467661694, 0.6295081967213115],\n",
       " [464, 3020, 114, 102, 0.5238095238095238, 0.6334519572953736],\n",
       " [465, 3021, 92, 80, 0.4146341463414634, 0.3573667711598746],\n",
       " [466, 3020, 254, 165, 0.49498327759197325, 0.5621301775147929],\n",
       " [467, 3020, 235, 194, 0.6085526315789473, 0.6796875],\n",
       " [468, 3021, 137, 120, 0.5321100917431193, 0.436950146627566],\n",
       " [469, 3020, 232, 102, 0.5520504731861199, 0.6334519572953736],\n",
       " [470, 3020, 362, 206, 0.7409638554216867, 0.7225806451612903],\n",
       " [471, 3021, 246, 210, 0.45622119815668205, 0.48466257668711654],\n",
       " [472, 3021, 298, 44, 0.37337662337662336, 0.6510416666666666],\n",
       " [473, 3021, 278, 86, 0.41214057507987223, 0.6528662420382165],\n",
       " [474, 3021, 325, 5, 0.540453074433657, 0.5959595959595959],\n",
       " [475, 3020, 358, 139, 0.6595092024539877, 0.5353535353535354],\n",
       " [476, 3021, 355, 125, 0.5220125786163522, 0.6033333333333334],\n",
       " [477, 3020, 243, 216, 0.6133333333333333, 0.7321428571428571],\n",
       " [478, 3021, 100, 27, 0.3356643356643357, 0.6104651162790697],\n",
       " [479, 3020, 206, 112, 0.2783171521035599, 0.7459016393442623],\n",
       " [480, 3021, 285, 126, 0.5180722891566265, 0.6360424028268551],\n",
       " [481, 3020, 276, 205, 0.4953271028037383, 0.43450479233226835],\n",
       " [482, 3020, 154, 8, 0.4298780487804878, 0.6466666666666666],\n",
       " [483, 3021, 357, 267, 0.48214285714285715, 0.6444444444444445],\n",
       " [484, 3020, 55, 2, 0.5608695652173913, 0.6185567010309279],\n",
       " [485, 3020, 84, 46, 0.46568627450980393, 0.7553191489361702],\n",
       " [486, 3021, 254, 218, 0.49498327759197325, 0.5290519877675841],\n",
       " [487, 3020, 221, 147, 0.4169184290030212, 0.47783251231527096],\n",
       " [488, 3020, 244, 64, 0.5584415584415584, 0.5],\n",
       " [489, 3021, 357, 43, 0.48214285714285715, 0.40988372093023256],\n",
       " [490, 3021, 306, 109, 0.39490445859872614, 0.5227272727272727],\n",
       " [491, 3021, 234, 219, 0.5849673202614379, 0.49823321554770317],\n",
       " [492, 3021, 333, 48, 0.6355421686746988, 0.5217391304347826],\n",
       " [493, 3021, 157, 120, 0.7033639143730887, 0.436950146627566],\n",
       " [494, 3020, 338, 150, 0.5502958579881657, 0.5824915824915825],\n",
       " [495, 3021, 230, 143, 0.6088235294117647, 0.4491017964071856],\n",
       " [496, 3020, 344, 157, 0.5563636363636364, 0.29573170731707316],\n",
       " [497, 3021, 242, 4, 0.24242424242424243, 0.35919540229885055],\n",
       " [498, 3020, 223, 197, 0.72, 0.6875],\n",
       " [499, 3020, 321, 83, 0.4189189189189189, 0.6006944444444444],\n",
       " [500, 3020, 261, 187, 0.5145631067961165, 0.5902777777777778],\n",
       " [501, 3020, 131, 106, 0.6139817629179332, 0.42765273311897106],\n",
       " [502, 3021, 326, 238, 0.46689895470383275, 0.3106508875739645],\n",
       " [503, 3020, 361, 35, 0.5342465753424658, 0.5912162162162162],\n",
       " [504, 3021, 255, 199, 0.48854961832061067, 0.6019417475728155],\n",
       " [505, 3021, 341, 233, 0.40468227424749165, 0.6134185303514377],\n",
       " [506, 3021, 198, 112, 0.4414715719063545, 0.7459016393442623],\n",
       " [507, 3020, 116, 12, 0.39090909090909093, 0.25903614457831325],\n",
       " [508, 3020, 207, 168, 0.6813880126182965, 0.3508771929824561],\n",
       " [509, 3021, 211, 76, 0.32967032967032966, 0.5353982300884956],\n",
       " [510, 3020, 334, 97, 0.5924764890282131, 0.6559485530546624],\n",
       " [511, 3020, 352, 130, 0.5841584158415841, 0],\n",
       " [512, 3020, 255, 219, 0.48854961832061067, 0.49823321554770317],\n",
       " [513, 3021, 205, 147, 0.5673076923076923, 0.47783251231527096],\n",
       " [514, 3021, 344, 163, 0.5563636363636364, 0.5344262295081967],\n",
       " [515, 3020, 326, 114, 0.46689895470383275, 0.47619047619047616],\n",
       " [516, 3021, 316, 193, 0.5514950166112956, 0.31309904153354634],\n",
       " [517, 3020, 146, 58, 0.6888888888888889, 0.29213483146067415],\n",
       " [518, 3021, 109, 14, 0.4772727272727273, 0.5033333333333333],\n",
       " [519, 3020, 349, 113, 0.5620915032679739, 0],\n",
       " [520, 3021, 257, 16, 0.3850267379679144, 0.35185185185185186],\n",
       " [521, 3021, 175, 1, 0.5833333333333334, 0],\n",
       " [522, 3020, 131, 24, 0.6139817629179332, 0.5517241379310345],\n",
       " [523, 3021, 228, 8, 0.6580645161290323, 0.6466666666666666],\n",
       " [524, 3020, 306, 198, 0.39490445859872614, 0.56],\n",
       " [525, 3020, 226, 75, 0.6363636363636364, 0.603225806451613],\n",
       " [526, 3020, 153, 13, 0.5131578947368421, 0.44324324324324327],\n",
       " [527, 3020, 364, 25, 0.3310104529616725, 0.34536082474226804],\n",
       " [528, 3021, 274, 162, 0.45874587458745875, 0],\n",
       " [529, 3020, 162, 149, 0, 0.5741935483870968],\n",
       " [530, 3021, 262, 191, 0.45482866043613707, 0.5422077922077922],\n",
       " [531, 3021, 239, 73, 0.3854748603351955, 0.43103448275862066],\n",
       " [532, 3021, 224, 156, 0.5458937198067633, 0.5143769968051118],\n",
       " [533, 3020, 179, 162, 0.6071428571428571, 0],\n",
       " [534, 3021, 351, 242, 0.5765765765765766, 0.7575757575757576],\n",
       " [535, 3021, 340, 109, 0.3333333333333333, 0.5227272727272727],\n",
       " [536, 3020, 333, 306, 0.6355421686746988, 0.6063492063492063],\n",
       " [537, 3020, 362, 144, 0.7409638554216867, 0.7387387387387387],\n",
       " [538, 3021, 348, 42, 0.6056338028169014, 0.6367041198501873],\n",
       " [539, 3021, 214, 29, 0.7771428571428571, 0.44904458598726116],\n",
       " [540, 3020, 116, 107, 0.39090909090909093, 0.3384615384615385],\n",
       " [541, 3021, 330, 2, 0.5867768595041323, 0.6185567010309279],\n",
       " [542, 3020, 302, 85, 0.378839590443686, 0.6054421768707483],\n",
       " [543, 3021, 315, 16, 0.3137254901960784, 0.35185185185185186],\n",
       " [544, 3020, 216, 211, 0.26785714285714285, 0.6678832116788321],\n",
       " [545, 3021, 139, 87, 0.46283783783783783, 0.5986394557823129],\n",
       " [546, 3020, 267, 120, 0.35555555555555557, 0.436950146627566],\n",
       " [547, 3021, 237, 82, 0.49127906976744184, 0.6040955631399317],\n",
       " [548, 3020, 260, 240, 0.45714285714285713, 0.5174129353233831],\n",
       " [549, 3021, 165, 135, 0.4391691394658754, 0.4380664652567976],\n",
       " [550, 3021, 177, 78, 0.7072463768115942, 0.50814332247557],\n",
       " [551, 3021, 280, 126, 0.41454545454545455, 0.6360424028268551],\n",
       " [552, 3020, 344, 327, 0.5563636363636364, 0.519163763066202],\n",
       " [553, 3020, 316, 64, 0.5514950166112956, 0.5],\n",
       " [554, 3020, 237, 137, 0.49127906976744184, 0.46788990825688076],\n",
       " [555, 3020, 358, 6, 0.6595092024539877, 0.5190311418685121],\n",
       " [556, 3020, 113, 30, 0, 0.3952802359882006],\n",
       " [557, 3020, 112, 99, 0.2551440329218107, 0.4477124183006536],\n",
       " [558, 3020, 325, 81, 0.540453074433657, 0.125],\n",
       " [559, 3021, 349, 333, 0.5620915032679739, 0.3644578313253012],\n",
       " [560, 3021, 293, 1, 0.7692307692307693, 0],\n",
       " [561, 3021, 105, 99, 0.38562091503267976, 0.4477124183006536],\n",
       " [562, 3020, 192, 68, 0.4950166112956811, 0.4659090909090909],\n",
       " [563, 3020, 134, 108, 0.5993975903614458, 0.46105919003115264],\n",
       " [564, 3021, 245, 69, 0.6314363143631436, 0.5759493670886076],\n",
       " [565, 3021, 262, 62, 0.45482866043613707, 0.5504587155963303],\n",
       " [566, 3020, 305, 156, 0.47928994082840237, 0.5143769968051118],\n",
       " [567, 3020, 328, 161, 0.6199376947040498, 0.4491017964071856],\n",
       " [568, 3020, 271, 234, 0.560126582278481, 0.4169381107491857],\n",
       " [569, 3021, 188, 166, 0.396875, 0.3323262839879154],\n",
       " [570, 3021, 10, 3, 0.46417445482866043, 0.49498327759197325],\n",
       " [571, 3020, 27, 7, 0.38953488372093026, 0.5056179775280899],\n",
       " [572, 3021, 269, 260, 0.36789297658862874, 0.5450236966824644],\n",
       " [573, 3020, 210, 2, 0.5169230769230769, 0.6185567010309279],\n",
       " [574, 3020, 360, 148, 0.5133928571428571, 0.6167247386759582],\n",
       " [575, 3021, 302, 250, 0.378839590443686, 0.4117647058823529],\n",
       " [576, 3020, 339, 188, 0.5, 0.6043613707165109],\n",
       " [577, 3020, 65, 8, 0.6567164179104478, 0.6466666666666666],\n",
       " [578, 3021, 230, 158, 0.6088235294117647, 0.6805555555555556],\n",
       " [579, 3021, 336, 307, 0.6139817629179332, 0.48484848484848486],\n",
       " [580, 3021, 343, 7, 0.6183844011142061, 0.5056179775280899],\n",
       " [581, 3020, 251, 210, 0.5603715170278638, 0.48466257668711654],\n",
       " [582, 3021, 68, 16, 0.5287356321839081, 0.35185185185185186],\n",
       " [583, 3020, 171, 48, 0.28664495114006516, 0.5217391304347826],\n",
       " [584, 3021, 291, 142, 0.36363636363636365, 0.18711656441717792],\n",
       " [585, 3021, 358, 49, 0.6595092024539877, 0.6440677966101694],\n",
       " [586, 3021, 167, 111, 0.5016181229773463, 0.20699708454810495],\n",
       " [587, 3021, 160, 156, 0.41823899371069184, 0.5143769968051118],\n",
       " [588, 3021, 296, 283, 0.6867469879518072, 0.5902777777777778],\n",
       " [589, 3020, 158, 64, 0.3205574912891986, 0.5],\n",
       " [590, 3021, 294, 176, 0.44680851063829785, 0.4511627906976744],\n",
       " [591, 3020, 347, 191, 0.515625, 0.5422077922077922],\n",
       " [592, 3021, 206, 111, 0.2783171521035599, 0.20699708454810495],\n",
       " [593, 3020, 364, 111, 0.3310104529616725, 0.20699708454810495],\n",
       " [594, 3020, 252, 105, 0.4881656804733728, 0.6143790849673203],\n",
       " [595, 3021, 83, 39, 0.3993055555555556, 0.2774566473988439],\n",
       " [596, 3021, 319, 56, 0.4166666666666667, 0.5584415584415584],\n",
       " [597, 3021, 270, 48, 0.4492753623188406, 0.5217391304347826],\n",
       " [598, 3020, 255, 217, 0.48854961832061067, 0.6052631578947368],\n",
       " [599, 3020, 220, 211, 0.5252525252525253, 0.6678832116788321],\n",
       " [600, 3020, 122, 68, 0.4722222222222222, 0.4659090909090909],\n",
       " [601, 3020, 182, 53, 0.39100346020761245, 0.2875],\n",
       " [602, 3020, 215, 209, 0.4057971014492754, 0.45185185185185184],\n",
       " [603, 3020, 298, 130, 0.37337662337662336, 0],\n",
       " [604, 3021, 149, 45, 0.4258064516129032, 0.5562913907284768],\n",
       " [605, 3021, 344, 301, 0.5563636363636364, 0.5290519877675841],\n",
       " [606, 3021, 175, 38, 0.5833333333333334, 0.6],\n",
       " [607, 3020, 190, 180, 0.42356687898089174, 0.38333333333333336],\n",
       " [608, 3020, 166, 101, 0.6666666666666666, 0.5795454545454546],\n",
       " [609, 3020, 298, 16, 0.37337662337662336, 0.35185185185185186],\n",
       " [610, 3020, 321, 71, 0.4189189189189189, 0.6847457627118644],\n",
       " [611, 3020, 245, 53, 0.6314363143631436, 0.2875],\n",
       " [612, 3020, 359, 178, 0.35655737704918034, 0.40460526315789475],\n",
       " [613, 3021, 151, 30, 0.42207792207792205, 0.3952802359882006],\n",
       " [614, 3021, 243, 215, 0.6133333333333333, 0.5942028985507246],\n",
       " [615, 3020, 361, 65, 0.5342465753424658, 0.3382352941176471],\n",
       " [616, 3020, 200, 84, 0.27631578947368424, 0.5365853658536586],\n",
       " [617, 3020, 250, 110, 0.5869565217391305, 0.4732142857142857],\n",
       " [618, 3021, 299, 258, 0.4883720930232558, 0.5080906148867314],\n",
       " [619, 3020, 293, 150, 0.7692307692307693, 0.5824915824915825],\n",
       " [620, 3020, 255, 33, 0.48854961832061067, 0.4938650306748466],\n",
       " [621, 3021, 290, 54, 0.6875, 0.7065217391304348],\n",
       " [622, 3021, 319, 242, 0.4166666666666667, 0.7575757575757576],\n",
       " [623, 3021, 26, 15, 0.3811074918566775, 0.7101449275362319],\n",
       " [624, 3021, 327, 133, 0.4825174825174825, 0.4375],\n",
       " [625, 3021, 237, 56, 0.49127906976744184, 0.5584415584415584],\n",
       " [626, 3020, 247, 156, 0.4529616724738676, 0.5143769968051118],\n",
       " [627, 3020, 205, 94, 0.5673076923076923, 0.6512455516014235],\n",
       " [628, 3021, 342, 254, 0.36524822695035464, 0.5066666666666667],\n",
       " [629, 3020, 282, 166, 0.4742268041237113, 0.3323262839879154],\n",
       " [630, 3021, 162, 36, 0, 0.7014925373134329],\n",
       " [631, 3020, 83, 51, 0.3993055555555556, 0.5],\n",
       " [632, 3020, 249, 183, 0.4440677966101695, 0.45896656534954405],\n",
       " [633, 3021, 251, 100, 0.5603715170278638, 0.6643356643356644],\n",
       " [634, 3020, 140, 33, 0.3728813559322034, 0.4938650306748466],\n",
       " [635, 3021, 179, 7, 0.6071428571428571, 0.5056179775280899],\n",
       " [636, 3020, 261, 27, 0.5145631067961165, 0.6104651162790697],\n",
       " [637, 3020, 234, 80, 0.5849673202614379, 0.3573667711598746],\n",
       " [638, 3021, 352, 350, 0.5841584158415841, 0.5575757575757576],\n",
       " [639, 3021, 247, 41, 0.4529616724738676, 0.6610738255033557],\n",
       " [640, 3021, 69, 63, 0.4253968253968254, 0.28846153846153844],\n",
       " [641, 3020, 124, 75, 0.2833333333333333, 0.603225806451613],\n",
       " [642, 3021, 335, 295, 0.6318181818181818, 0.5245398773006135],\n",
       " [643, 3020, 270, 41, 0.4492753623188406, 0.6610738255033557],\n",
       " [644, 3020, 284, 29, 0.34448160535117056, 0.44904458598726116],\n",
       " [645, 3020, 209, 182, 0.5464684014869888, 0.6103448275862069],\n",
       " [646, 3021, 344, 20, 0.5563636363636364, 0.5652173913043478],\n",
       " [647, 3020, 226, 174, 0.6363636363636364, 0.419672131147541],\n",
       " [648, 3021, 338, 289, 0.5502958579881657, 0.6477987421383647],\n",
       " [649, 3021, 130, 56, 0, 0.5584415584415584],\n",
       " [650, 3020, 344, 244, 0.5563636363636364, 0.4401294498381877],\n",
       " [651, 3020, 225, 72, 0.5681818181818182, 0.348993288590604],\n",
       " [652, 3020, 239, 217, 0.3854748603351955, 0.6052631578947368],\n",
       " [653, 3020, 139, 93, 0.46283783783783783, 0.4911242603550296],\n",
       " [654, 3021, 239, 234, 0.3854748603351955, 0.4169381107491857],\n",
       " [655, 3020, 138, 88, 0.4537037037037037, 0.8461538461538461],\n",
       " [656, 3020, 338, 27, 0.5502958579881657, 0.6104651162790697],\n",
       " [657, 3020, 342, 296, 0.36524822695035464, 0.3123123123123123],\n",
       " [658, 3020, 362, 66, 0.7409638554216867, 0.3575757575757576],\n",
       " [659, 3020, 326, 68, 0.46689895470383275, 0.4659090909090909],\n",
       " [660, 3020, 336, 294, 0.6139817629179332, 0.5531914893617021],\n",
       " [661, 3020, 174, 72, 0.5789473684210527, 0.348993288590604],\n",
       " [662, 3020, 112, 25, 0.2551440329218107, 0.34536082474226804],\n",
       " [663, 3021, 247, 27, 0.4529616724738676, 0.6104651162790697],\n",
       " [664, 3020, 56, 2, 0.44299674267100975, 0.6185567010309279],\n",
       " [665, 3020, 293, 32, 0.7692307692307693, 0.5032051282051282],\n",
       " [666, 3021, 194, 166, 0.3203125, 0.3323262839879154],\n",
       " [667, 3020, 222, 114, 0.43450479233226835, 0.47619047619047616],\n",
       " [668, 3020, 354, 327, 0.44200626959247646, 0.519163763066202],\n",
       " [669, 3020, 357, 50, 0.48214285714285715, 0.414985590778098],\n",
       " [670, 3021, 265, 44, 0.5, 0.6510416666666666],\n",
       " [671, 3020, 62, 46, 0.4444444444444444, 0.7553191489361702],\n",
       " [672, 3020, 334, 142, 0.5924764890282131, 0.18711656441717792],\n",
       " [673, 3020, 117, 116, 0.4724137931034483, 0.6102719033232629],\n",
       " [674, 3021, 200, 63, 0.27631578947368424, 0.28846153846153844],\n",
       " [675, 3021, 30, 11, 0.6035502958579881, 0.5016722408026756],\n",
       " [676, 3021, 70, 54, 0.19387755102040816, 0.7065217391304348],\n",
       " [677, 3020, 232, 196, 0.5520504731861199, 0.6182965299684543],\n",
       " [678, 3020, 284, 6, 0.34448160535117056, 0.5190311418685121],\n",
       " [679, 3021, 278, 229, 0.41214057507987223, 0.3117283950617284],\n",
       " [680, 3021, 293, 83, 0.7692307692307693, 0.6006944444444444],\n",
       " [681, 3020, 349, 114, 0.5620915032679739, 0.47619047619047616],\n",
       " [682, 3021, 325, 141, 0.540453074433657, 0.5047021943573667],\n",
       " [683, 3021, 253, 181, 0.40625, 0.3415384615384615],\n",
       " [684, 3021, 300, 195, 0.6363636363636364, 0.46938775510204084],\n",
       " [685, 3020, 149, 25, 0.4258064516129032, 0.34536082474226804],\n",
       " [686, 3021, 223, 147, 0.72, 0.47783251231527096],\n",
       " [687, 3020, 269, 60, 0.36789297658862874, 0.46261682242990654],\n",
       " [688, 3020, 239, 73, 0.3854748603351955, 0.43103448275862066],\n",
       " [689, 3020, 326, 137, 0.46689895470383275, 0.46788990825688076],\n",
       " [690, 3020, 324, 148, 0.6696969696969697, 0.6167247386759582],\n",
       " [691, 3021, 154, 113, 0.4298780487804878, 0],\n",
       " [692, 3021, 303, 212, 0.5352564102564102, 0.75],\n",
       " [693, 3020, 265, 35, 0.5, 0.5912162162162162],\n",
       " [694, 3021, 75, 23, 0.3967741935483871, 0.46394984326018807],\n",
       " [695, 3020, 130, 124, 0, 0.7166666666666667],\n",
       " [696, 3021, 220, 76, 0.5252525252525253, 0.5353982300884956],\n",
       " [697, 3021, 211, 159, 0.32967032967032966, 0.6107784431137725],\n",
       " [698, 3020, 173, 139, 0.3717105263157895, 0.5353535353535354],\n",
       " [699, 3021, 329, 311, 0.6993464052287581, 0.5352564102564102],\n",
       " [700, 3020, 156, 129, 0.48562300319488816, 0.4792626728110599],\n",
       " [701, 3021, 170, 23, 0.4492753623188406, 0.46394984326018807],\n",
       " [702, 3020, 275, 39, 0.6435643564356436, 0.2774566473988439],\n",
       " [703, 3020, 319, 261, 0.4166666666666667, 0.4854368932038835],\n",
       " [704, 3021, 127, 85, 0.5047619047619047, 0.6054421768707483],\n",
       " [705, 3020, 358, 45, 0.6595092024539877, 0.5562913907284768],\n",
       " [706, 3021, 121, 79, 0.5247813411078717, 0.6203389830508474],\n",
       " [707, 3020, 167, 7, 0.5016181229773463, 0.5056179775280899],\n",
       " [708, 3020, 334, 91, 0.5924764890282131, 0.48589341692789967],\n",
       " [709, 3020, 192, 37, 0.4950166112956811, 0.43934426229508194],\n",
       " [710, 3020, 301, 65, 0.4709480122324159, 0.3382352941176471],\n",
       " [711, 3020, 179, 74, 0.6071428571428571, 0.4624624624624625],\n",
       " [712, 3021, 349, 339, 0.5620915032679739, 0.5],\n",
       " [713, 3021, 231, 38, 0.5943396226415094, 0.6],\n",
       " [714, 3021, 352, 247, 0.5841584158415841, 0.5486111111111112],\n",
       " [715, 3021, 89, 44, 0.3473684210526316, 0.6510416666666666],\n",
       " [716, 3020, 268, 49, 0.391304347826087, 0.6440677966101694],\n",
       " [717, 3021, 44, 42, 0.3507853403141361, 0.6367041198501873],\n",
       " [718, 3020, 279, 98, 0.5032894736842105, 0.5975232198142415],\n",
       " [719, 3021, 326, 126, 0.46689895470383275, 0.6360424028268551],\n",
       " [720, 3021, 347, 125, 0.515625, 0.6033333333333334],\n",
       " [721, 3020, 170, 49, 0.4492753623188406, 0.6440677966101694],\n",
       " [722, 3021, 264, 186, 0.515358361774744, 0.5787545787545788],\n",
       " [723, 3020, 93, 61, 0.5088757396449705, 0.4966442953020134],\n",
       " [724, 3021, 262, 249, 0.45482866043613707, 0.5540540540540541],\n",
       " [725, 3020, 109, 23, 0.4772727272727273, 0.46394984326018807],\n",
       " [726, 3021, 340, 124, 0.3333333333333333, 0.7166666666666667],\n",
       " [727, 3020, 174, 94, 0.5789473684210527, 0.6512455516014235],\n",
       " [728, 3020, 157, 154, 0.7033639143730887, 0.5701219512195121],\n",
       " [729, 3021, 260, 33, 0.45714285714285713, 0.4938650306748466],\n",
       " [730, 3020, 251, 248, 0.5603715170278638, 0.4702194357366771],\n",
       " [731, 3020, 310, 225, 0.29961089494163423, 0.4318181818181818],\n",
       " [732, 3021, 270, 96, 0.4492753623188406, 0.2631578947368421],\n",
       " [733, 3020, 91, 23, 0.5125786163522013, 0.46394984326018807],\n",
       " [734, 3020, 337, 303, 0.6346153846153846, 0.46325878594249204],\n",
       " [735, 3020, 92, 74, 0.4146341463414634, 0.4624624624624625],\n",
       " [736, 3020, 355, 159, 0.5220125786163522, 0.6107784431137725],\n",
       " [737, 3020, 316, 231, 0.5514950166112956, 0.4084507042253521],\n",
       " [738, 3021, 67, 29, 0.30864197530864196, 0.44904458598726116],\n",
       " [739, 3020, 161, 134, 0.5495495495495496, 0.3993993993993994],\n",
       " [740, 3020, 117, 103, 0.4724137931034483, 0.44011976047904194],\n",
       " [741, 3020, 171, 124, 0.28664495114006516, 0.7166666666666667],\n",
       " [742, 3020, 58, 10, 0.7045454545454546, 0.5372670807453416],\n",
       " [743, 3021, 304, 231, 0.2518248175182482, 0.4084507042253521],\n",
       " [744, 3020, 363, 10, 0.42857142857142855, 0.5372670807453416],\n",
       " [745, 3020, 125, 36, 0.39666666666666667, 0.7014925373134329],\n",
       " [746, 3020, 328, 5, 0.6199376947040498, 0.5959595959595959],\n",
       " [747, 3021, 155, 100, 0.248, 0.6643356643356644],\n",
       " [748, 3021, 170, 127, 0.4492753623188406, 0.49523809523809526],\n",
       " [749, 3021, 342, 315, 0.36524822695035464, 0.6862745098039216],\n",
       " [750, 3020, 254, 222, 0.49498327759197325, 0.5654952076677316],\n",
       " [751, 3021, 322, 318, 0.4326923076923077, 0.5062111801242236],\n",
       " [752, 3020, 295, 22, 0.47384615384615386, 0.5109034267912772],\n",
       " [753, 3020, 141, 116, 0.4937106918238994, 0.6102719033232629],\n",
       " [754, 3021, 248, 122, 0.5283018867924528, 0.5261538461538462],\n",
       " [755, 3021, 183, 15, 0.541033434650456, 0.7101449275362319],\n",
       " [756, 3020, 301, 261, 0.4709480122324159, 0.4854368932038835],\n",
       " [757, 3021, 214, 177, 0.7771428571428571, 0.29190751445086704],\n",
       " [758, 3020, 329, 217, 0.6993464052287581, 0.6052631578947368],\n",
       " [759, 3020, 164, 121, 0.38738738738738737, 0.4738372093023256],\n",
       " [760, 3020, 241, 145, 0.2682119205298013, 0.37770897832817335],\n",
       " [761, 3020, 177, 109, 0.7072463768115942, 0.5227272727272727],\n",
       " [762, 3021, 111, 68, 0.7923976608187134, 0.4659090909090909],\n",
       " [763, 3020, 312, 267, 0.6195652173913043, 0.6444444444444445],\n",
       " [764, 3020, 321, 221, 0.4189189189189189, 0.5813253012048193],\n",
       " [765, 3020, 294, 36, 0.44680851063829785, 0.7014925373134329],\n",
       " [766, 3021, 334, 78, 0.5924764890282131, 0.50814332247557],\n",
       " [767, 3021, 322, 218, 0.4326923076923077, 0.5290519877675841],\n",
       " [768, 3021, 130, 120, 0, 0.436950146627566],\n",
       " [769, 3021, 108, 63, 0.5375, 0.28846153846153844],\n",
       " [770, 3020, 312, 112, 0.6195652173913043, 0.7459016393442623],\n",
       " [771, 3020, 204, 43, 0.5657492354740061, 0.40988372093023256],\n",
       " [772, 3020, 240, 229, 0.48258706467661694, 0.3117283950617284],\n",
       " [773, 3021, 270, 95, 0.4492753623188406, 0.6071428571428571],\n",
       " [774, 3020, 254, 105, 0.49498327759197325, 0.6143790849673203],\n",
       " [775, 3021, 69, 42, 0.4253968253968254, 0.6367041198501873],\n",
       " [776, 3021, 248, 11, 0.5283018867924528, 0.5016722408026756],\n",
       " [777, 3021, 253, 171, 0.40625, 0.7133550488599348],\n",
       " [778, 3021, 207, 160, 0.6813880126182965, 0.5830721003134797],\n",
       " [779, 3020, 15, 3, 0.2898550724637681, 0.49498327759197325],\n",
       " [780, 3021, 152, 138, 0.4294117647058823, 0.5462962962962963],\n",
       " [781, 3020, 258, 113, 0.4935064935064935, 0],\n",
       " [782, 3020, 148, 79, 0.38461538461538464, 0.6203389830508474],\n",
       " [783, 3021, 184, 16, 0.4358974358974359, 0.35185185185185186],\n",
       " [784, 3021, 151, 102, 0.42207792207792205, 0.6334519572953736],\n",
       " [785, 3021, 318, 50, 0.4953271028037383, 0.414985590778098],\n",
       " [786, 3021, 307, 62, 0.5121951219512195, 0.5504587155963303],\n",
       " [787, 3020, 185, 81, 0.5752508361204013, 0.125],\n",
       " [788, 3021, 218, 50, 0.4723926380368098, 0.414985590778098],\n",
       " [789, 3021, 201, 70, 0.5435435435435435, 0.8067796610169492],\n",
       " [790, 3021, 216, 146, 0.26785714285714285, 0.3088235294117647],\n",
       " [791, 3021, 340, 98, 0.3333333333333333, 0.5975232198142415],\n",
       " [792, 3020, 356, 252, 0.3821656050955414, 0.5118343195266272],\n",
       " [793, 3020, 111, 84, 0.7923976608187134, 0.5365853658536586],\n",
       " [794, 3021, 251, 238, 0.5603715170278638, 0.3106508875739645],\n",
       " [795, 3020, 145, 5, 0.6211180124223602, 0.5959595959595959],\n",
       " [796, 3021, 191, 172, 0.4592833876221498, 0.3081395348837209],\n",
       " [797, 3020, 184, 32, 0.4358974358974359, 0.5032051282051282],\n",
       " [798, 3020, 243, 132, 0.6133333333333333, 0.531055900621118],\n",
       " [799, 3020, 304, 216, 0.2518248175182482, 0.7321428571428571],\n",
       " [800, 3021, 338, 252, 0.5502958579881657, 0.5118343195266272],\n",
       " [801, 3020, 358, 263, 0.6595092024539877, 0.6877076411960132],\n",
       " [802, 3021, 290, 222, 0.6875, 0.5654952076677316],\n",
       " [803, 3021, 243, 83, 0.6133333333333333, 0.6006944444444444],\n",
       " [804, 3020, 358, 178, 0.6595092024539877, 0.40460526315789475],\n",
       " [805, 3021, 347, 5, 0.515625, 0.5959595959595959],\n",
       " [806, 3020, 334, 248, 0.5924764890282131, 0.4702194357366771],\n",
       " [807, 3021, 364, 146, 0.3310104529616725, 0.3088235294117647],\n",
       " [808, 3021, 302, 218, 0.378839590443686, 0.5290519877675841],\n",
       " [809, 3020, 180, 149, 0.6150627615062761, 0.5741935483870968],\n",
       " [810, 3020, 170, 64, 0.4492753623188406, 0.5],\n",
       " [811, 3020, 357, 256, 0.48214285714285715, 0.42042042042042044],\n",
       " [812, 3020, 249, 13, 0.4440677966101695, 0.44324324324324327],\n",
       " [813, 3020, 276, 230, 0.4953271028037383, 0.39296187683284456],\n",
       " [814, 3021, 223, 32, 0.72, 0.5032051282051282],\n",
       " [815, 3021, 233, 143, 0.38461538461538464, 0.4491017964071856],\n",
       " [816, 3021, 181, 120, 0.6574074074074074, 0.436950146627566],\n",
       " [817, 3021, 248, 136, 0.5283018867924528, 0.6405228758169934],\n",
       " [818, 3020, 324, 124, 0.6696969696969697, 0.7166666666666667],\n",
       " [819, 3020, 356, 135, 0.3821656050955414, 0.4380664652567976],\n",
       " [820, 3021, 319, 58, 0.4166666666666667, 0.29213483146067415],\n",
       " [821, 3021, 361, 144, 0.5342465753424658, 0.7387387387387387],\n",
       " [822, 3020, 300, 142, 0.6363636363636364, 0.18711656441717792],\n",
       " [823, 3021, 214, 2, 0.7771428571428571, 0.6185567010309279],\n",
       " [824, 3020, 309, 124, 0.6119402985074627, 0.7166666666666667],\n",
       " [825, 3020, 294, 198, 0.44680851063829785, 0.56],\n",
       " [826, 3020, 248, 67, 0.5283018867924528, 0.691358024691358],\n",
       " [827, 3020, 327, 40, 0.4825174825174825, 0.31746031746031744],\n",
       " [828, 3020, 44, 16, 0.3507853403141361, 0.35185185185185186],\n",
       " [829, 3020, 331, 204, 0.569078947368421, 0.4329268292682927],\n",
       " [830, 3021, 143, 127, 0.5495495495495496, 0.49523809523809526],\n",
       " [831, 3021, 352, 136, 0.5841584158415841, 0.6405228758169934],\n",
       " [832, 3021, 339, 217, 0.5, 0.6052631578947368],\n",
       " [833, 3021, 310, 208, 0.29961089494163423, 0.3927392739273927],\n",
       " [834, 3021, 295, 294, 0.47384615384615386, 0.5531914893617021],\n",
       " [835, 3020, 359, 223, 0.35655737704918034, 0.27631578947368424],\n",
       " [836, 3020, 288, 224, 0.8105263157894737, 0.45410628019323673],\n",
       " [837, 3021, 326, 169, 0.46689895470383275, 0.3829787234042553],\n",
       " [838, 3021, 279, 130, 0.5032894736842105, 0],\n",
       " [839, 3021, 218, 158, 0.4723926380368098, 0.6805555555555556],\n",
       " [840, 3021, 142, 57, 0.8128834355828221, 0.5857142857142857],\n",
       " [841, 3020, 290, 179, 0.6875, 0.3893805309734513],\n",
       " [842, 3020, 351, 150, 0.5765765765765766, 0.5824915824915825],\n",
       " [843, 3021, 75, 63, 0.3967741935483871, 0.28846153846153844],\n",
       " [844, 3021, 364, 274, 0.3310104529616725, 0.5427631578947368],\n",
       " [845, 3020, 299, 240, 0.4883720930232558, 0.5174129353233831],\n",
       " [846, 3020, 322, 290, 0.4326923076923077, 0.3125],\n",
       " [847, 3020, 134, 112, 0.5993975903614458, 0.7459016393442623],\n",
       " [848, 3021, 133, 44, 0.56, 0.6510416666666666],\n",
       " [849, 3021, 255, 19, 0.48854961832061067, 0.7454545454545455],\n",
       " [850, 3020, 338, 138, 0.5502958579881657, 0.5462962962962963],\n",
       " [851, 3020, 266, 81, 0.2777777777777778, 0.125],\n",
       " [852, 3020, 303, 209, 0.5352564102564102, 0.45185185185185184],\n",
       " [853, 3021, 350, 242, 0.44072948328267475, 0.7575757575757576],\n",
       " [854, 3021, 60, 42, 0.5352112676056338, 0.6367041198501873],\n",
       " [855, 3020, 284, 90, 0.34448160535117056, 0.5015673981191222],\n",
       " [856, 3020, 175, 122, 0.5833333333333334, 0.5261538461538462],\n",
       " [857, 3021, 339, 184, 0.5, 0.5654952076677316],\n",
       " [858, 3020, 213, 145, 0.4574898785425101, 0.37770897832817335],\n",
       " [859, 3021, 254, 99, 0.49498327759197325, 0.4477124183006536],\n",
       " [860, 3021, 144, 56, 0.26126126126126126, 0.5584415584415584],\n",
       " [861, 3020, 102, 52, 0.3678571428571429, 0.7738853503184714],\n",
       " [862, 3021, 301, 260, 0.4709480122324159, 0.5450236966824644],\n",
       " [863, 3021, 351, 286, 0.5765765765765766, 0.4064327485380117],\n",
       " [864, 3021, 356, 104, 0.3821656050955414, 0.5928338762214984],\n",
       " [865, 3020, 228, 77, 0.6580645161290323, 0.5540983606557377],\n",
       " [866, 3020, 261, 87, 0.5145631067961165, 0.5986394557823129],\n",
       " [867, 3020, 274, 6, 0.45874587458745875, 0.5190311418685121],\n",
       " [868, 3021, 291, 211, 0.36363636363636365, 0.6678832116788321],\n",
       " [869, 3020, 348, 181, 0.6056338028169014, 0.3415384615384615],\n",
       " [870, 3021, 160, 86, 0.41823899371069184, 0.6528662420382165],\n",
       " [871, 3021, 19, 16, 0.2545454545454545, 0.35185185185185186],\n",
       " [872, 3020, 184, 108, 0.4358974358974359, 0.46105919003115264],\n",
       " [873, 3021, 168, 106, 0.6480938416422287, 0.42765273311897106],\n",
       " [874, 3021, 61, 17, 0.5050505050505051, 0.5240384615384616],\n",
       " [875, 3020, 362, 242, 0.7409638554216867, 0.7575757575757576],\n",
       " [876, 3021, 294, 240, 0.44680851063829785, 0.5174129353233831],\n",
       " [877, 3020, 163, 69, 0.46710526315789475, 0.5759493670886076],\n",
       " [878, 3020, 286, 92, 0.5953079178885631, 0.5866261398176292],\n",
       " [879, 3020, 263, 90, 0.3122923588039867, 0.5015673981191222],\n",
       " [880, 3021, 340, 192, 0.3333333333333333, 0.5033112582781457],\n",
       " [881, 3020, 240, 161, 0.48258706467661694, 0.4491017964071856],\n",
       " [882, 3020, 32, 19, 0.4983922829581994, 0.7454545454545455],\n",
       " [883, 3020, 364, 264, 0.3310104529616725, 0.48464163822525597],\n",
       " [884, 3021, 224, 93, 0.5458937198067633, 0.4911242603550296],\n",
       " [885, 3021, 344, 5, 0.5563636363636364, 0.5959595959595959],\n",
       " [886, 3021, 354, 314, 0.44200626959247646, 0.5631067961165048],\n",
       " [887, 3020, 279, 20, 0.5032894736842105, 0.5652173913043478],\n",
       " [888, 3021, 325, 107, 0.540453074433657, 0.3384615384615385],\n",
       " [889, 3020, 89, 24, 0.3473684210526316, 0.5517241379310345],\n",
       " [890, 3021, 280, 207, 0.41454545454545455, 0.31761006289308175],\n",
       " [891, 3021, 198, 161, 0.4414715719063545, 0.4491017964071856],\n",
       " [892, 3021, 309, 146, 0.6119402985074627, 0.3088235294117647],\n",
       " [893, 3021, 276, 15, 0.4953271028037383, 0.7101449275362319],\n",
       " [894, 3020, 132, 57, 0.470404984423676, 0.5857142857142857],\n",
       " [895, 3021, 272, 174, 0.5324232081911263, 0.419672131147541],\n",
       " [896, 3021, 159, 135, 0.39039039039039036, 0.4380664652567976],\n",
       " [897, 3020, 364, 14, 0.3310104529616725, 0.5033333333333333],\n",
       " [898, 3020, 303, 139, 0.5352564102564102, 0.5353535353535354],\n",
       " [899, 3021, 327, 166, 0.4825174825174825, 0.3323262839879154],\n",
       " [900, 3021, 303, 44, 0.5352564102564102, 0.6510416666666666],\n",
       " [901, 3021, 310, 80, 0.29961089494163423, 0.3573667711598746],\n",
       " [902, 3021, 231, 62, 0.5943396226415094, 0.5504587155963303],\n",
       " [903, 3021, 315, 152, 0.3137254901960784, 0.5705882352941176],\n",
       " [904, 3021, 111, 30, 0.7923976608187134, 0.3952802359882006],\n",
       " [905, 3020, 233, 114, 0.38461538461538464, 0.47619047619047616],\n",
       " [906, 3020, 331, 289, 0.569078947368421, 0.6477987421383647],\n",
       " [907, 3020, 265, 113, 0.5, 0],\n",
       " [908, 3020, 92, 2, 0.4146341463414634, 0.6185567010309279],\n",
       " [909, 3021, 258, 155, 0.4935064935064935, 0.752],\n",
       " [910, 3020, 181, 78, 0.6574074074074074, 0.50814332247557],\n",
       " [911, 3020, 261, 233, 0.5145631067961165, 0.6134185303514377],\n",
       " [912, 3021, 71, 50, 0.3129251700680272, 0.414985590778098],\n",
       " [913, 3020, 337, 267, 0.6346153846153846, 0.6444444444444445],\n",
       " [914, 3020, 204, 63, 0.5657492354740061, 0.28846153846153844],\n",
       " [915, 3021, 363, 233, 0.42857142857142855, 0.6134185303514377],\n",
       " [916, 3020, 243, 239, 0.6133333333333333, 0.6111111111111112],\n",
       " [917, 3021, 180, 167, 0.6150627615062761, 0.5],\n",
       " [918, 3020, 311, 262, 0.4662379421221865, 0.5451713395638629],\n",
       " [919, 3020, 93, 23, 0.5088757396449705, 0.46394984326018807],\n",
       " [920, 3021, 331, 229, 0.569078947368421, 0.3117283950617284],\n",
       " [921, 3021, 133, 110, 0.56, 0.4732142857142857],\n",
       " [922, 3020, 340, 139, 0.3333333333333333, 0.5353535353535354],\n",
       " [923, 3020, 148, 101, 0.38461538461538464, 0.5795454545454546],\n",
       " [924, 3020, 155, 113, 0.248, 0],\n",
       " [925, 3021, 319, 170, 0.4166666666666667, 0.5507246376811594],\n",
       " [926, 3020, 182, 58, 0.39100346020761245, 0.29213483146067415],\n",
       " [927, 3020, 283, 31, 0.4076655052264808, 0.4429530201342282],\n",
       " [928, 3020, 344, 233, 0.5563636363636364, 0.6134185303514377],\n",
       " [929, 3021, 297, 88, 0.6607142857142857, 0.8461538461538461],\n",
       " [930, 3021, 358, 257, 0.6595092024539877, 0.6149732620320856],\n",
       " [931, 3021, 152, 69, 0.4294117647058823, 0.5759493670886076],\n",
       " [932, 3020, 266, 26, 0.2777777777777778, 0.6201298701298701],\n",
       " [933, 3021, 165, 161, 0.4391691394658754, 0.4491017964071856],\n",
       " [934, 3020, 259, 229, 0.5, 0.3117283950617284],\n",
       " [935, 3021, 149, 43, 0.4258064516129032, 0.40988372093023256],\n",
       " [936, 3020, 280, 116, 0.41454545454545455, 0.6102719033232629],\n",
       " [937, 3021, 330, 57, 0.5867768595041323, 0.5857142857142857],\n",
       " [938, 3021, 180, 58, 0.6150627615062761, 0.29213483146067415],\n",
       " [939, 3020, 62, 8, 0.4444444444444444, 0.6466666666666666],\n",
       " [940, 3020, 273, 16, 0.564935064935065, 0.35185185185185186],\n",
       " [941, 3020, 217, 38, 0.39603960396039606, 0.6],\n",
       " [942, 3020, 302, 19, 0.378839590443686, 0.7454545454545455],\n",
       " [943, 3020, 124, 13, 0.2833333333333333, 0.44324324324324327],\n",
       " [944, 3021, 224, 119, 0.5458937198067633, 0.6042780748663101],\n",
       " [945, 3020, 300, 103, 0.6363636363636364, 0.44011976047904194],\n",
       " [946, 3020, 178, 174, 0.594059405940594, 0.419672131147541],\n",
       " [947, 3021, 128, 48, 0.6490683229813664, 0.5217391304347826],\n",
       " [948, 3021, 259, 240, 0.5, 0.5174129353233831],\n",
       " [949, 3020, 250, 162, 0.5869565217391305, 0],\n",
       " [950, 3021, 264, 108, 0.515358361774744, 0.46105919003115264],\n",
       " [951, 3020, 270, 240, 0.4492753623188406, 0.5174129353233831],\n",
       " [952, 3021, 358, 155, 0.6595092024539877, 0.752],\n",
       " [953, 3020, 97, 50, 0.3440514469453376, 0.414985590778098],\n",
       " [954, 3021, 308, 196, 0.4625, 0.6182965299684543],\n",
       " [955, 3020, 161, 59, 0.5495495495495496, 0.5691823899371069],\n",
       " [956, 3020, 215, 208, 0.4057971014492754, 0.3927392739273927],\n",
       " [957, 3021, 320, 154, 0.37538461538461537, 0.5701219512195121],\n",
       " [958, 3020, 277, 210, 0.4915254237288136, 0.48466257668711654],\n",
       " [959, 3020, 253, 194, 0.40625, 0.6796875],\n",
       " [960, 3020, 155, 89, 0.248, 0.6526315789473685],\n",
       " [961, 3020, 155, 33, 0.248, 0.4938650306748466],\n",
       " [962, 3020, 279, 94, 0.5032894736842105, 0.6512455516014235],\n",
       " [963, 3020, 167, 154, 0.5016181229773463, 0.5701219512195121],\n",
       " [964, 3021, 262, 94, 0.45482866043613707, 0.6512455516014235],\n",
       " [965, 3020, 195, 51, 0.5306122448979592, 0.5],\n",
       " [966, 3020, 340, 88, 0.3333333333333333, 0.8461538461538461],\n",
       " [967, 3020, 85, 55, 0.3924914675767918, 0.43722943722943725],\n",
       " [968, 3020, 198, 101, 0.4414715719063545, 0.5795454545454546],\n",
       " [969, 3021, 323, 259, 0.5540983606557377, 0.49828178694158076],\n",
       " [970, 3020, 206, 116, 0.2783171521035599, 0.6102719033232629],\n",
       " [971, 3021, 342, 281, 0.36524822695035464, 0.6423611111111112],\n",
       " [972, 3021, 338, 204, 0.5502958579881657, 0.4329268292682927],\n",
       " [973, 3020, 301, 247, 0.4709480122324159, 0.5486111111111112],\n",
       " [974, 3021, 260, 246, 0.45714285714285713, 0.543778801843318],\n",
       " [975, 3020, 137, 14, 0.5321100917431193, 0.5033333333333333],\n",
       " [976, 3020, 300, 1, 0.6363636363636364, 0],\n",
       " [977, 3021, 333, 280, 0.6355421686746988, 0.5854545454545454],\n",
       " [978, 3021, 265, 211, 0.5, 0.6678832116788321],\n",
       " [979, 3020, 194, 128, 0.3203125, 0.3498452012383901],\n",
       " [980, 3020, 262, 213, 0.45482866043613707, 0.5425101214574899],\n",
       " [981, 3020, 211, 65, 0.32967032967032966, 0.3382352941176471],\n",
       " [982, 3020, 218, 152, 0.4723926380368098, 0.5705882352941176],\n",
       " [983, 3020, 198, 27, 0.4414715719063545, 0.6104651162790697],\n",
       " [984, 3021, 60, 40, 0.5352112676056338, 0.31746031746031744],\n",
       " [985, 3020, 351, 121, 0.5765765765765766, 0.4738372093023256],\n",
       " [986, 3020, 340, 132, 0.3333333333333333, 0.531055900621118],\n",
       " [987, 3021, 161, 17, 0.5495495495495496, 0.5240384615384616],\n",
       " [988, 3020, 240, 87, 0.48258706467661694, 0.5986394557823129],\n",
       " [989, 3020, 311, 120, 0.4662379421221865, 0.436950146627566],\n",
       " [990, 3021, 124, 123, 0.2833333333333333, 0.7763157894736842],\n",
       " [991, 3021, 355, 121, 0.5220125786163522, 0.4738372093023256],\n",
       " [992, 3021, 231, 154, 0.5943396226415094, 0.5701219512195121],\n",
       " [993, 3020, 190, 165, 0.42356687898089174, 0.5621301775147929],\n",
       " [994, 3020, 261, 84, 0.5145631067961165, 0.5365853658536586],\n",
       " [995, 3021, 46, 10, 0.24468085106382978, 0.5372670807453416],\n",
       " [996, 3020, 206, 50, 0.2783171521035599, 0.414985590778098],\n",
       " [997, 3020, 323, 322, 0.5540983606557377, 0.5686900958466453],\n",
       " [998, 3021, 226, 16, 0.6363636363636364, 0.35185185185185186],\n",
       " [999, 3020, 335, 12, 0.6318181818181818, 0.25903614457831325],\n",
       " ...]"
      ]
     },
     "execution_count": 464,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_test = []\n",
    "for row in test.values:\n",
    "    b = []\n",
    "    if row[2] not in percentage_of_win:\n",
    "        b.append(0)\n",
    "    else:\n",
    "        b.append(percentage_of_win[row[2]][0]/percentage_of_win[row[2]][2])\n",
    "    if row[3] not in percentage_of_win:\n",
    "        b.append(0)\n",
    "    else:\n",
    "        b.append(percentage_of_win[row[3]][1]/percentage_of_win[row[3]][3])\n",
    "    a = list(row) + b\n",
    "    new_test.append(a)\n",
    "new_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train_new = pd.DataFrame(data=new_train, columns=['year', 'day', 'team1', 'team2', 'score1', 'score2', 'target', 'p1', 'p2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_test_new = pd.DataFrame(data=new_test, columns=['ind', 'year', 'team1', 'team2', 'p1', 'p2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_p1p2 = x_train_new[['team1', 'team2', 'p1', 'p2']].values\n",
    "X_train = x_train_new[['team1', 'team2']].values\n",
    "y_train = x_train_new['target'].values\n",
    "X_test_p1p2 = x_test_new[['team1', 'team2', 'p1', 'p2']].values\n",
    "X_test = x_test_new[['team1', 'team2']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "?LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1.0,\n",
       " 'class_weight': None,\n",
       " 'dual': False,\n",
       " 'fit_intercept': True,\n",
       " 'intercept_scaling': 1,\n",
       " 'max_iter': 100,\n",
       " 'multi_class': 'ovr',\n",
       " 'n_jobs': 1,\n",
       " 'penalty': 'l2',\n",
       " 'random_state': None,\n",
       " 'solver': 'liblinear',\n",
       " 'tol': 0.0001,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 566,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegressionCV(Cs=10, class_weight=None, cv=5, dual=False,\n",
       "           fit_intercept=True, intercept_scaling=1.0, max_iter=100,\n",
       "           multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "           refit=True, scoring='log_loss', solver='lbfgs', tol=0.0001,\n",
       "           verbose=0)"
      ]
     },
     "execution_count": 554,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.fit(X_train_p1p2, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "arr = reg.predict_proba(X_test_p1p2)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 0.2, 0.3, 0.5, 0.6, 0.7, 0.8, 0.9, 1, 1.5, 2, 3, 4, 5, 7, 9, 10],\n",
    "    'penalty': ['l2'],\n",
    "    'max_iter': np.linspace(50, 150, 5, dtype=int),\n",
    "    'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opt_reg = GridSearchCV(reg, param_grid, scoring='log_loss', cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/scipy/optimize/linesearch.py:285: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/utils/optimize.py:193: UserWarning: Line Search failed\n",
      "  warnings.warn('Line Search failed')\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/scipy/optimize/linesearch.py:285: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/utils/optimize.py:193: UserWarning: Line Search failed\n",
      "  warnings.warn('Line Search failed')\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/scipy/optimize/linesearch.py:285: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/utils/optimize.py:193: UserWarning: Line Search failed\n",
      "  warnings.warn('Line Search failed')\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/scipy/optimize/linesearch.py:285: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/utils/optimize.py:193: UserWarning: Line Search failed\n",
      "  warnings.warn('Line Search failed')\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/scipy/optimize/linesearch.py:285: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/utils/optimize.py:193: UserWarning: Line Search failed\n",
      "  warnings.warn('Line Search failed')\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/scipy/optimize/linesearch.py:285: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/utils/optimize.py:193: UserWarning: Line Search failed\n",
      "  warnings.warn('Line Search failed')\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/scipy/optimize/linesearch.py:285: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/utils/optimize.py:193: UserWarning: Line Search failed\n",
      "  warnings.warn('Line Search failed')\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/scipy/optimize/linesearch.py:285: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/utils/optimize.py:193: UserWarning: Line Search failed\n",
      "  warnings.warn('Line Search failed')\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/scipy/optimize/linesearch.py:285: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/utils/optimize.py:193: UserWarning: Line Search failed\n",
      "  warnings.warn('Line Search failed')\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/scipy/optimize/linesearch.py:285: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/utils/optimize.py:193: UserWarning: Line Search failed\n",
      "  warnings.warn('Line Search failed')\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/scipy/optimize/linesearch.py:285: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/utils/optimize.py:193: UserWarning: Line Search failed\n",
      "  warnings.warn('Line Search failed')\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/scipy/optimize/linesearch.py:285: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/utils/optimize.py:193: UserWarning: Line Search failed\n",
      "  warnings.warn('Line Search failed')\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/scipy/optimize/linesearch.py:285: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/utils/optimize.py:193: UserWarning: Line Search failed\n",
      "  warnings.warn('Line Search failed')\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/scipy/optimize/linesearch.py:285: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/utils/optimize.py:193: UserWarning: Line Search failed\n",
      "  warnings.warn('Line Search failed')\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/scipy/optimize/linesearch.py:285: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/utils/optimize.py:193: UserWarning: Line Search failed\n",
      "  warnings.warn('Line Search failed')\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/scipy/optimize/linesearch.py:285: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/utils/optimize.py:193: UserWarning: Line Search failed\n",
      "  warnings.warn('Line Search failed')\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/scipy/optimize/linesearch.py:285: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/utils/optimize.py:193: UserWarning: Line Search failed\n",
      "  warnings.warn('Line Search failed')\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/scipy/optimize/linesearch.py:285: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/utils/optimize.py:193: UserWarning: Line Search failed\n",
      "  warnings.warn('Line Search failed')\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/scipy/optimize/linesearch.py:285: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/utils/optimize.py:193: UserWarning: Line Search failed\n",
      "  warnings.warn('Line Search failed')\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/scipy/optimize/linesearch.py:285: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/utils/optimize.py:193: UserWarning: Line Search failed\n",
      "  warnings.warn('Line Search failed')\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'penalty': ['l2'], 'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag'], 'max_iter': array([ 50,  75, 100, 125, 150]), 'C': [0.01, 0.1, 0.2, 0.3, 0.5, 0.6, 0.7, 0.8, 0.9, 1, 1.5, 2, 3, 4, 5, 7, 9, 10]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring='log_loss', verbose=0)"
      ]
     },
     "execution_count": 574,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_reg.fit(X_train_p1p2, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10, 'max_iter': 75, 'penalty': 'l2', 'solver': 'lbfgs'}"
      ]
     },
     "execution_count": 576,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_reg.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Xgboost parameters\n",
    "\n",
    "https://github.com/dmlc/xgboost/blob/master/doc/parameter.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param = {}\n",
    "param['max_depth'] = 8\n",
    "param['booster'] = 'gbtree'\n",
    "param['objective'] = 'binary:logistic'\n",
    "param['eval_metric'] = 'logloss'\n",
    "param['eta'] = 0.01\n",
    "\n",
    "numround = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = xgboost.XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'max_depth': np.linspace(1, 15, 15, dtype=int),\n",
    "    'n_estimators': np.linspace(10, 150, 15, dtype=int),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opt = GridSearchCV(estimator=clf, param_grid=param_grid, scoring='log_loss', cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
       "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "       min_child_weight=1, missing=None, n_estimators=100, nthread=-1,\n",
       "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
       "       scale_pos_weight=1, seed=0, silent=True, subsample=1),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'max_depth': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15]), 'n_estimators': array([ 10,  20,  30,  40,  50,  60,  70,  80,  90, 100, 110, 120, 130,\n",
       "       140, 150])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring='log_loss', verbose=0)"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt.fit(xtrain.values, ytrain.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.65431641172351407"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
       "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=8,\n",
       "       min_child_weight=1, missing=None, n_estimators=150, nthread=-1,\n",
       "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
       "       scale_pos_weight=1, seed=0, silent=True, subsample=1)"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#[1999]\ttrain-logloss:0.585557\teval-logloss:0.634051\n",
    "param = {}\n",
    "param['max_depth'] = 9\n",
    "param['booster'] = 'gbtree'\n",
    "param['objective'] = 'binary:logistic'\n",
    "param['eval_metric'] = 'logloss'\n",
    "param['eta'] = 0.1\n",
    "\n",
    "numround = 340"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:0.690034\teval-logloss:0.690888\n",
      "[10]\ttrain-logloss:0.668431\teval-logloss:0.675843\n",
      "[20]\ttrain-logloss:0.654625\teval-logloss:0.666155\n",
      "[30]\ttrain-logloss:0.646366\teval-logloss:0.661209\n",
      "[40]\ttrain-logloss:0.640452\teval-logloss:0.657902\n",
      "[50]\ttrain-logloss:0.633774\teval-logloss:0.654248\n",
      "[60]\ttrain-logloss:0.629010\teval-logloss:0.651628\n",
      "[70]\ttrain-logloss:0.624447\teval-logloss:0.649329\n",
      "[80]\ttrain-logloss:0.620285\teval-logloss:0.647191\n",
      "[90]\ttrain-logloss:0.614487\teval-logloss:0.644127\n",
      "[100]\ttrain-logloss:0.611106\teval-logloss:0.642714\n",
      "[110]\ttrain-logloss:0.606981\teval-logloss:0.640835\n",
      "[120]\ttrain-logloss:0.603590\teval-logloss:0.639596\n",
      "[130]\ttrain-logloss:0.600450\teval-logloss:0.638167\n",
      "[140]\ttrain-logloss:0.597954\teval-logloss:0.637420\n",
      "[150]\ttrain-logloss:0.594607\teval-logloss:0.636128\n",
      "[160]\ttrain-logloss:0.591651\teval-logloss:0.634989\n",
      "[170]\ttrain-logloss:0.589069\teval-logloss:0.634360\n",
      "[180]\ttrain-logloss:0.586721\teval-logloss:0.633644\n",
      "[190]\ttrain-logloss:0.584725\teval-logloss:0.633067\n",
      "[200]\ttrain-logloss:0.582547\teval-logloss:0.632803\n",
      "[210]\ttrain-logloss:0.580718\teval-logloss:0.632369\n",
      "[220]\ttrain-logloss:0.578621\teval-logloss:0.632174\n",
      "[230]\ttrain-logloss:0.576727\teval-logloss:0.631887\n",
      "[240]\ttrain-logloss:0.575204\teval-logloss:0.631618\n",
      "[250]\ttrain-logloss:0.573527\teval-logloss:0.631443\n",
      "[260]\ttrain-logloss:0.571865\teval-logloss:0.631181\n",
      "[270]\ttrain-logloss:0.570770\teval-logloss:0.631256\n",
      "[280]\ttrain-logloss:0.569322\teval-logloss:0.631070\n",
      "[290]\ttrain-logloss:0.568068\teval-logloss:0.630960\n",
      "[300]\ttrain-logloss:0.566826\teval-logloss:0.630917\n",
      "[310]\ttrain-logloss:0.565742\teval-logloss:0.630889\n",
      "[320]\ttrain-logloss:0.564438\teval-logloss:0.630791\n",
      "[330]\ttrain-logloss:0.563106\teval-logloss:0.630754\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[339]\ttrain-logloss:0.561843\teval-logloss:0.630689\n"
     ]
    }
   ],
   "source": [
    "Xdatatrain = xgboost.DMatrix(data = xtrain, label = ytrain)\n",
    "Xdatatest = xgboost.DMatrix(data = xval, label = yval)\n",
    "\n",
    "plst = list(param.items())\n",
    "watchlist = [(Xdatatrain, 'train'), (Xdatatest, 'eval')]            \n",
    "\n",
    "bst = xgboost.train(plst, Xdatatrain, numround, evals = watchlist, verbose_eval = 10)\n",
    "print(bst.best_iteration)\n",
    "# ypredxgb_tr = bst.predict(Xdatatrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#[1999]\ttrain-logloss:0.585557\teval-logloss:0.634051\n",
    "param = {}\n",
    "param['max_depth'] = 10\n",
    "param['booster'] = 'gbtree'\n",
    "param['objective'] = 'binary:logistic'\n",
    "param['eval_metric'] = 'logloss'\n",
    "param['eta'] = 0.01\n",
    "\n",
    "numround = 320"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['team1', 'team2', 'p1', 'p2']"
      ]
     },
     "execution_count": 527,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_new = features + ['p1', 'p2']\n",
    "features_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xtrain_new = x_train_new.loc[itr, features_new]    \n",
    "ytrain_new = x_train_new.loc[itr, 'target']\n",
    "\n",
    "xval_new = x_train_new.loc[ite, features_new]\n",
    "yval_new = x_train_new.loc[ite, 'target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:0.691577\teval-logloss:0.691828\n",
      "[10]\ttrain-logloss:0.677617\teval-logloss:0.679808\n",
      "[20]\ttrain-logloss:0.665856\teval-logloss:0.669987\n",
      "[30]\ttrain-logloss:0.655762\teval-logloss:0.661771\n",
      "[40]\ttrain-logloss:0.647091\teval-logloss:0.654905\n",
      "[50]\ttrain-logloss:0.639557\teval-logloss:0.649195\n",
      "[60]\ttrain-logloss:0.633071\teval-logloss:0.644432\n",
      "[70]\ttrain-logloss:0.627431\teval-logloss:0.640396\n",
      "[80]\ttrain-logloss:0.622476\teval-logloss:0.636988\n",
      "[90]\ttrain-logloss:0.618045\teval-logloss:0.634139\n",
      "[100]\ttrain-logloss:0.614114\teval-logloss:0.631662\n",
      "[110]\ttrain-logloss:0.610636\teval-logloss:0.629574\n",
      "[120]\ttrain-logloss:0.607542\teval-logloss:0.627845\n",
      "[130]\ttrain-logloss:0.604807\teval-logloss:0.626440\n",
      "[140]\ttrain-logloss:0.602308\teval-logloss:0.625199\n",
      "[150]\ttrain-logloss:0.600042\teval-logloss:0.624180\n",
      "[160]\ttrain-logloss:0.597952\teval-logloss:0.623295\n",
      "[170]\ttrain-logloss:0.596024\teval-logloss:0.622556\n",
      "[180]\ttrain-logloss:0.594253\teval-logloss:0.621937\n",
      "[190]\ttrain-logloss:0.592643\teval-logloss:0.621395\n",
      "[200]\ttrain-logloss:0.591171\teval-logloss:0.620948\n",
      "[210]\ttrain-logloss:0.589812\teval-logloss:0.620540\n",
      "[220]\ttrain-logloss:0.588483\teval-logloss:0.620193\n",
      "[230]\ttrain-logloss:0.587242\teval-logloss:0.619883\n",
      "[240]\ttrain-logloss:0.586047\teval-logloss:0.619654\n",
      "[250]\ttrain-logloss:0.584970\teval-logloss:0.619459\n",
      "[260]\ttrain-logloss:0.583941\teval-logloss:0.619270\n",
      "[270]\ttrain-logloss:0.582980\teval-logloss:0.619160\n",
      "[280]\ttrain-logloss:0.581997\teval-logloss:0.619037\n",
      "[290]\ttrain-logloss:0.581081\teval-logloss:0.618933\n",
      "[300]\ttrain-logloss:0.580241\teval-logloss:0.618842\n",
      "[310]\ttrain-logloss:0.579457\teval-logloss:0.618779\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[319]\ttrain-logloss:0.578788\teval-logloss:0.618748\n"
     ]
    }
   ],
   "source": [
    "Xdatatrain = xgboost.DMatrix(data = xtrain_new, label = ytrain_new)\n",
    "Xdatatest = xgboost.DMatrix(data = xval_new, label = yval_new)\n",
    "\n",
    "plst = list(param.items())\n",
    "watchlist = [(Xdatatrain, 'train'), (Xdatatest, 'eval')]            \n",
    "\n",
    "bst = xgboost.train(plst, Xdatatrain, numround, evals = watchlist, verbose_eval = 10)\n",
    "print(bst.best_iteration)\n",
    "# ypredxgb_tr = bst.predict(Xdatatrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow! Finally our model better than constant predictions! Congratulations! Don't hesitate, submit!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.16356187,  0.74639529,  0.94774258, ...,  0.82250255,\n",
       "        0.38163385,  0.21870503], dtype=float32)"
      ]
     },
     "execution_count": 536,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = bst.predict(xgboost.DMatrix(x_test_new[['team1', 'team2', 'p1', 'p2']]))\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.41481793,  0.78602779,  0.71633184, ...,  0.67208821,\n",
       "        0.49065748,  0.33231843], dtype=float32)"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt.predict_proba(test[['team1', 'team2']].values)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = xgboost.XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
    "       gamma=0, learning_rate=0.07, max_delta_step=0, max_depth=8,\n",
    "       min_child_weight=1, missing=None, n_estimators=130, nthread=-1,\n",
    "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
    "       scale_pos_weight=1, seed=0, silent=True, subsample=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
       "       gamma=0, learning_rate=0.07, max_delta_step=0, max_depth=8,\n",
       "       min_child_weight=1, missing=None, n_estimators=130, nthread=-1,\n",
       "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
       "       scale_pos_weight=1, seed=0, silent=True, subsample=1)"
      ]
     },
     "execution_count": 473,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(train[['team1', 'team2']].values , train['target'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.42683405,  0.68022805,  0.65880686, ...,  0.67071056,\n",
       "        0.54231179,  0.3874718 ], dtype=float32)"
      ]
     },
     "execution_count": 475,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = clf.predict_proba(test[['team1', 'team2']].values)[:,1]\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.97366\n",
      "0.973637\n",
      "0.970839\n",
      "0.971368\n",
      "0.973643\n",
      "0.97366\n",
      "0.970681\n",
      "0.973305\n",
      "0.97366\n",
      "0.972618\n",
      "0.970648\n",
      "0.97366\n",
      "0.973637\n",
      "0.97118\n",
      "0.0294439\n",
      "0.973637\n",
      "0.0295878\n",
      "0.97074\n",
      "0.972847\n",
      "0.973667\n",
      "0.973105\n",
      "0.970007\n",
      "0.97118\n",
      "0.97366\n",
      "0.97118\n",
      "0.973643\n",
      "0.970616\n",
      "0.971368\n",
      "0.973637\n",
      "0.970285\n",
      "0.970353\n",
      "0.973105\n",
      "0.970285\n",
      "0.973637\n",
      "0.97118\n",
      "0.973305\n",
      "0.973637\n",
      "0.971119\n",
      "0.970285\n",
      "0.972819\n",
      "0.971368\n",
      "0.973305\n",
      "0.971439\n",
      "0.97074\n",
      "0.97366\n",
      "0.972163\n",
      "0.97366\n",
      "0.973637\n",
      "0.973667\n",
      "0.973637\n",
      "0.97366\n",
      "0.971368\n",
      "0.97366\n",
      "0.97099\n",
      "0.973637\n",
      "0.971368\n",
      "0.971368\n",
      "0.972274\n",
      "0.972974\n",
      "0.973637\n",
      "0.973637\n",
      "0.970871\n",
      "0.970616\n",
      "0.97118\n",
      "0.973637\n",
      "0.970232\n",
      "0.970846\n",
      "0.970333\n",
      "0.970681\n",
      "0.970871\n",
      "0.97366\n",
      "0.970285\n",
      "0.970206\n",
      "0.970333\n",
      "0.972301\n",
      "0.972591\n",
      "0.971368\n",
      "0.97366\n",
      "0.970839\n",
      "0.971368\n",
      "0.971368\n",
      "0.97366\n",
      "0.973637\n",
      "0.0294439\n",
      "0.97074\n",
      "0.972507\n",
      "0.973305\n",
      "0.970285\n",
      "0.973643\n",
      "0.971368\n",
      "0.973637\n",
      "0.972659\n",
      "0.97366\n",
      "0.97366\n",
      "0.97366\n",
      "0.970839\n",
      "0.97118\n",
      "0.973643\n",
      "0.970871\n",
      "0.971368\n",
      "0.970871\n",
      "0.97022\n",
      "0.970285\n",
      "0.0299488\n",
      "0.972818\n",
      "0.97343\n",
      "0.97366\n",
      "0.970648\n",
      "0.973305\n",
      "0.973637\n",
      "0.970871\n",
      "0.973305\n",
      "0.970871\n",
      "0.973637\n",
      "0.970949\n",
      "0.970871\n",
      "0.97366\n",
      "0.973407\n",
      "0.972507\n",
      "0.972612\n",
      "0.97366\n",
      "0.97366\n",
      "0.97118\n",
      "0.973511\n",
      "0.970839\n",
      "0.97118\n",
      "0.973637\n",
      "0.971368\n",
      "0.97366\n",
      "0.971368\n",
      "0.97074\n",
      "0.970258\n",
      "0.973637\n",
      "0.97366\n",
      "0.97343\n",
      "0.97366\n",
      "0.97366\n",
      "0.970846\n",
      "0.973637\n",
      "0.972974\n",
      "0.970871\n",
      "0.97366\n",
      "0.972507\n",
      "0.97366\n",
      "0.970871\n",
      "0.97118\n",
      "0.973637\n",
      "0.971368\n",
      "0.970871\n",
      "0.97074\n",
      "0.97366\n",
      "0.972651\n",
      "0.97343\n",
      "0.970839\n",
      "0.970353\n",
      "0.97118\n",
      "0.973637\n",
      "0.973637\n",
      "0.973637\n",
      "0.971368\n",
      "0.97366\n",
      "0.97118\n",
      "0.970648\n",
      "0.973667\n",
      "0.970871\n",
      "0.972584\n",
      "0.973637\n",
      "0.973305\n",
      "0.970655\n",
      "0.973228\n",
      "0.97366\n",
      "0.973637\n",
      "0.970648\n",
      "0.971368\n",
      "0.973637\n",
      "0.972573\n",
      "0.973637\n",
      "0.970558\n",
      "0.971368\n",
      "0.973559\n",
      "0.971368\n",
      "0.971368\n",
      "0.97366\n",
      "0.973559\n",
      "0.973637\n",
      "0.971368\n",
      "0.973637\n",
      "0.973559\n",
      "0.97366\n",
      "0.97022\n",
      "0.97366\n",
      "0.973637\n",
      "0.970485\n",
      "0.970655\n",
      "0.971368\n",
      "0.972302\n",
      "0.971368\n",
      "0.97366\n",
      "0.970232\n",
      "0.972612\n",
      "0.970871\n",
      "0.971368\n",
      "0.973643\n",
      "0.973637\n",
      "0.97366\n",
      "0.972612\n",
      "0.0294439\n",
      "0.970258\n",
      "0.970675\n",
      "0.973637\n",
      "0.97366\n",
      "0.97366\n",
      "0.970871\n",
      "0.971368\n",
      "0.973637\n",
      "0.97118\n",
      "0.973637\n",
      "0.97366\n",
      "0.970681\n",
      "0.973667\n",
      "0.970199\n",
      "0.973667\n",
      "0.973305\n",
      "0.971368\n",
      "0.973637\n",
      "0.972507\n",
      "0.973511\n",
      "0.971368\n",
      "0.973305\n",
      "0.973511\n",
      "0.0295611\n",
      "0.97366\n",
      "0.970014\n",
      "0.97118\n",
      "0.973637\n",
      "0.970846\n",
      "0.973208\n",
      "0.97366\n",
      "0.970681\n",
      "0.97074\n",
      "0.973171\n",
      "0.972612\n",
      "0.973305\n",
      "0.973305\n",
      "0.973105\n",
      "0.970839\n",
      "0.970199\n",
      "0.97366\n",
      "0.97366\n",
      "0.973305\n",
      "0.970705\n",
      "0.971368\n",
      "0.970705\n",
      "0.97118\n",
      "0.970139\n",
      "0.971368\n",
      "0.972268\n",
      "0.970705\n",
      "0.97366\n",
      "0.973305\n",
      "0.973667\n",
      "0.97366\n",
      "0.971368\n",
      "0.970846\n",
      "0.970285\n",
      "0.97366\n",
      "0.0295878\n",
      "0.97366\n",
      "0.970871\n",
      "0.972612\n",
      "0.973637\n",
      "0.97366\n",
      "0.97343\n",
      "0.973407\n",
      "0.970611\n",
      "0.970846\n",
      "0.97366\n",
      "0.971368\n",
      "0.97366\n",
      "0.972659\n",
      "0.97366\n",
      "0.970258\n",
      "0.973305\n",
      "0.971368\n",
      "0.973511\n",
      "0.973637\n",
      "0.971368\n",
      "0.973637\n",
      "0.973637\n",
      "0.97343\n",
      "0.970871\n",
      "0.97366\n",
      "0.973305\n",
      "0.971368\n",
      "0.973637\n",
      "0.971368\n",
      "0.973559\n",
      "0.972268\n",
      "0.973407\n",
      "0.972852\n",
      "0.97366\n",
      "0.973305\n",
      "0.97074\n",
      "0.97366\n",
      "0.0294439\n",
      "0.97366\n",
      "0.972847\n",
      "0.971368\n",
      "0.973559\n",
      "0.97366\n",
      "0.973637\n",
      "0.973637\n",
      "0.97366\n",
      "0.973637\n",
      "0.971368\n",
      "0.971368\n",
      "0.970084\n",
      "0.97366\n",
      "0.971368\n",
      "0.971368\n",
      "0.97366\n",
      "0.97343\n",
      "0.97118\n",
      "0.970454\n",
      "0.97118\n",
      "0.972618\n",
      "0.973305\n",
      "0.972612\n",
      "0.973637\n",
      "0.971368\n",
      "0.97118\n",
      "0.970871\n",
      "0.97099\n",
      "0.970232\n",
      "0.973637\n",
      "0.973105\n",
      "0.970871\n",
      "0.971368\n",
      "0.97366\n",
      "0.973208\n",
      "0.973305\n",
      "0.970846\n",
      "0.97118\n",
      "0.971368\n",
      "0.970846\n",
      "0.97118\n",
      "0.972274\n",
      "0.972644\n",
      "0.972584\n",
      "0.971119\n",
      "0.972612\n",
      "0.970681\n",
      "0.970026\n",
      "0.970258\n",
      "0.970454\n",
      "0.973105\n",
      "0.971368\n",
      "0.970871\n",
      "0.973305\n",
      "0.971368\n",
      "0.970232\n",
      "0.970285\n",
      "0.970333\n",
      "0.973667\n",
      "0.970655\n",
      "0.97118\n",
      "0.973305\n",
      "0.97074\n",
      "0.970139\n",
      "0.970839\n",
      "0.970232\n",
      "0.973036\n",
      "0.970648\n",
      "0.973637\n",
      "0.971368\n",
      "0.973305\n",
      "0.973637\n",
      "0.971368\n",
      "0.973637\n",
      "0.971368\n",
      "0.970611\n",
      "0.97366\n",
      "0.97366\n",
      "0.973208\n",
      "0.971119\n",
      "0.972054\n",
      "0.971368\n",
      "0.970871\n",
      "0.97366\n",
      "0.970839\n",
      "0.97118\n",
      "0.97074\n",
      "0.97118\n",
      "0.97099\n",
      "0.971119\n",
      "0.973305\n",
      "0.972573\n",
      "0.971368\n",
      "0.971368\n",
      "0.970675\n",
      "0.973105\n",
      "0.970681\n",
      "0.973667\n",
      "0.97118\n",
      "0.970648\n",
      "0.970485\n",
      "0.970139\n",
      "0.97366\n",
      "0.97366\n",
      "0.973637\n",
      "0.970871\n",
      "0.970681\n",
      "0.97366\n",
      "0.970871\n",
      "0.971368\n",
      "0.973637\n",
      "0.971368\n",
      "0.973637\n",
      "0.970084\n",
      "0.973637\n",
      "0.973208\n",
      "0.970675\n",
      "0.970611\n",
      "0.973036\n",
      "0.973643\n",
      "0.97074\n",
      "0.97366\n",
      "0.970949\n",
      "0.973637\n",
      "0.9706\n",
      "0.971368\n",
      "0.97366\n",
      "0.973559\n",
      "0.973559\n",
      "0.971368\n",
      "0.970705\n",
      "0.971368\n",
      "0.973637\n",
      "0.970871\n",
      "0.97074\n",
      "0.97074\n",
      "0.973208\n",
      "0.970014\n",
      "0.973637\n",
      "0.973637\n",
      "0.970285\n",
      "0.972507\n",
      "0.970871\n",
      "0.973637\n",
      "0.970206\n",
      "0.970333\n",
      "0.970929\n",
      "0.972268\n",
      "0.97366\n",
      "0.973305\n",
      "0.973637\n",
      "0.971368\n",
      "0.971368\n",
      "0.973407\n",
      "0.972514\n",
      "0.972514\n",
      "0.971368\n",
      "0.97366\n",
      "0.973637\n",
      "0.970675\n",
      "0.971368\n",
      "0.973559\n",
      "0.970285\n",
      "0.970454\n",
      "0.97366\n",
      "0.970285\n",
      "0.97366\n",
      "0.973637\n",
      "0.970681\n",
      "0.97343\n",
      "0.97366\n",
      "0.973637\n",
      "0.973637\n",
      "0.971368\n",
      "0.970333\n",
      "0.970871\n",
      "0.973208\n",
      "0.973637\n",
      "0.973637\n",
      "0.973667\n",
      "0.97343\n",
      "0.971368\n",
      "0.970026\n",
      "0.97118\n",
      "0.973637\n",
      "0.97366\n",
      "0.970232\n",
      "0.973559\n",
      "0.97366\n",
      "0.973667\n",
      "0.973637\n",
      "0.973407\n",
      "0.970007\n",
      "0.973511\n",
      "0.971368\n",
      "0.970681\n",
      "0.970333\n",
      "0.970871\n",
      "0.970353\n",
      "0.971368\n",
      "0.972847\n",
      "0.971368\n",
      "0.97074\n",
      "0.0295611\n",
      "0.970611\n",
      "0.97366\n",
      "0.97366\n",
      "0.972574\n",
      "0.97366\n",
      "0.970681\n",
      "0.971119\n",
      "0.973637\n",
      "0.972274\n",
      "0.972163\n",
      "0.973637\n",
      "0.970681\n",
      "0.973305\n",
      "0.970454\n",
      "0.973511\n",
      "0.973305\n",
      "0.973305\n",
      "0.970839\n",
      "0.973637\n",
      "0.972987\n",
      "0.97366\n",
      "0.973637\n",
      "0.97366\n",
      "0.970871\n",
      "0.973637\n",
      "0.973667\n",
      "0.973667\n",
      "0.970839\n",
      "0.973511\n",
      "0.972301\n",
      "0.973637\n",
      "0.970285\n",
      "0.97366\n",
      "0.970929\n",
      "0.97366\n",
      "0.973208\n",
      "0.97118\n",
      "0.970258\n",
      "0.973637\n",
      "0.971368\n",
      "0.970232\n",
      "0.972813\n",
      "0.973305\n",
      "0.970199\n",
      "0.97118\n",
      "0.97343\n",
      "0.97366\n",
      "0.97366\n",
      "0.970871\n",
      "0.0295611\n",
      "0.972584\n",
      "0.972618\n",
      "0.973305\n",
      "0.973637\n",
      "0.970846\n",
      "0.970139\n",
      "0.972274\n",
      "0.970846\n",
      "0.973637\n",
      "0.971368\n",
      "0.971368\n",
      "0.973559\n",
      "0.97118\n",
      "0.972302\n",
      "0.972852\n",
      "0.97366\n",
      "0.97366\n",
      "0.97343\n",
      "0.970232\n",
      "0.970232\n",
      "0.970681\n",
      "0.973559\n",
      "0.973637\n",
      "0.973637\n",
      "0.97118\n",
      "0.97366\n",
      "0.973637\n",
      "0.970871\n",
      "0.973559\n",
      "0.970839\n",
      "0.97366\n",
      "0.0295878\n",
      "0.972574\n",
      "0.970871\n",
      "0.973667\n",
      "0.973637\n",
      "0.973171\n",
      "0.973208\n",
      "0.97118\n",
      "0.973667\n",
      "0.97366\n",
      "0.970839\n",
      "0.97366\n",
      "0.97366\n",
      "0.97366\n",
      "0.973305\n",
      "0.971368\n",
      "0.972618\n",
      "0.970007\n",
      "0.97366\n",
      "0.970839\n",
      "0.972306\n",
      "0.973637\n",
      "0.973637\n",
      "0.973637\n",
      "0.97366\n",
      "0.97366\n",
      "0.970839\n",
      "0.973228\n",
      "0.97118\n",
      "0.973407\n",
      "0.970871\n",
      "0.973305\n",
      "0.973637\n",
      "0.97366\n",
      "0.973305\n",
      "0.972163\n",
      "0.97343\n",
      "0.973637\n",
      "0.972584\n",
      "0.973637\n",
      "0.970949\n",
      "0.970709\n",
      "0.970929\n",
      "0.97118\n",
      "0.970648\n",
      "0.971368\n",
      "0.972268\n",
      "0.973407\n",
      "0.970333\n",
      "0.970871\n",
      "0.97366\n",
      "0.97366\n",
      "0.971368\n",
      "0.971119\n",
      "0.970839\n",
      "0.970258\n",
      "0.97366\n",
      "0.971119\n",
      "0.970871\n",
      "0.973208\n",
      "0.973667\n",
      "0.973559\n",
      "0.971368\n",
      "0.97366\n",
      "0.971368\n",
      "0.973637\n",
      "0.973637\n",
      "0.970648\n",
      "0.97118\n",
      "0.970675\n",
      "0.972306\n",
      "0.973637\n",
      "0.97366\n",
      "0.970558\n",
      "0.97366\n",
      "0.97343\n",
      "0.973637\n",
      "0.970681\n",
      "0.971368\n",
      "0.973305\n",
      "0.97343\n",
      "0.970871\n",
      "0.972268\n",
      "0.97118\n",
      "0.970232\n",
      "0.971368\n",
      "0.97074\n",
      "0.97366\n",
      "0.973276\n",
      "0.971368\n",
      "0.973305\n",
      "0.973559\n",
      "0.0299488\n",
      "0.971368\n",
      "0.0295878\n",
      "0.97074\n",
      "0.971368\n",
      "0.970333\n",
      "0.973637\n",
      "0.973637\n",
      "0.973637\n",
      "0.97366\n",
      "0.973637\n",
      "0.972302\n",
      "0.97366\n",
      "0.970611\n",
      "0.972612\n",
      "0.973637\n",
      "0.971368\n",
      "0.972813\n",
      "0.973559\n",
      "0.97099\n",
      "0.970285\n",
      "0.97366\n",
      "0.970871\n",
      "0.970285\n",
      "0.971368\n",
      "0.970839\n",
      "0.971368\n",
      "0.970839\n",
      "0.970709\n",
      "0.97366\n",
      "0.972302\n",
      "0.971119\n",
      "0.972618\n",
      "0.973643\n",
      "0.97366\n",
      "0.970675\n",
      "0.973637\n",
      "0.972847\n",
      "0.973637\n",
      "0.973637\n",
      "0.971439\n",
      "0.973637\n",
      "0.970871\n",
      "0.97366\n",
      "0.970353\n",
      "0.973637\n",
      "0.970871\n",
      "0.973637\n",
      "0.970839\n",
      "0.97074\n",
      "0.971119\n",
      "0.973637\n",
      "0.97366\n",
      "0.970839\n",
      "0.97099\n",
      "0.97366\n",
      "0.97366\n",
      "0.970611\n",
      "0.973305\n",
      "0.97366\n",
      "0.970871\n",
      "0.97366\n",
      "0.970285\n",
      "0.972268\n",
      "0.971368\n",
      "0.972987\n",
      "0.973637\n",
      "0.972514\n",
      "0.970285\n",
      "0.972514\n",
      "0.973637\n",
      "0.970333\n",
      "0.97343\n",
      "0.972618\n",
      "0.97366\n",
      "0.970681\n",
      "0.973667\n",
      "0.971368\n",
      "0.97366\n",
      "0.973637\n",
      "0.97366\n",
      "0.973305\n",
      "0.973559\n",
      "0.9706\n",
      "0.970333\n",
      "0.97118\n",
      "0.973637\n",
      "0.97118\n",
      "0.972054\n",
      "0.973407\n",
      "0.973511\n",
      "0.97366\n",
      "0.973643\n",
      "0.973305\n",
      "0.97366\n",
      "0.973637\n",
      "0.970232\n",
      "0.970232\n",
      "0.973215\n",
      "0.970871\n",
      "0.973637\n",
      "0.97366\n",
      "0.971119\n",
      "0.97343\n",
      "0.973637\n",
      "0.971368\n",
      "0.97366\n",
      "0.97099\n",
      "0.973637\n",
      "0.970199\n",
      "0.971368\n",
      "0.97343\n",
      "0.970681\n",
      "0.970871\n",
      "0.973637\n",
      "0.970681\n",
      "0.973637\n",
      "0.0295611\n",
      "0.97366\n",
      "0.970846\n",
      "0.973276\n",
      "0.971368\n",
      "0.973637\n",
      "0.970839\n",
      "0.972163\n",
      "0.97366\n",
      "0.972819\n",
      "0.97366\n",
      "0.973637\n",
      "0.97074\n",
      "0.973215\n",
      "0.970285\n",
      "0.973637\n",
      "0.97074\n",
      "0.970285\n",
      "0.972591\n",
      "0.970929\n",
      "0.972644\n",
      "0.97118\n",
      "0.972651\n",
      "0.970007\n",
      "0.97366\n",
      "0.971368\n",
      "0.971368\n",
      "0.971368\n",
      "0.970655\n",
      "0.973637\n",
      "0.973637\n",
      "0.97366\n",
      "0.971368\n",
      "0.971368\n",
      "0.972818\n",
      "0.97366\n",
      "0.972507\n",
      "0.970871\n",
      "0.973208\n",
      "0.973637\n",
      "0.970949\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(arr)):\n",
    "    if arr[i] > 0.97:\n",
    "        print(arr[i])\n",
    "        arr[i] = 1\n",
    "    if arr[i] < 0.03:\n",
    "        print(arr[i])\n",
    "        arr[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.00000000e+00,   3.02100000e+03,   3.63000000e+02,\n",
       "          1.61000000e+02,   4.28571429e-01,   4.49101796e-01],\n",
       "       [  1.00000000e+00,   3.02100000e+03,   2.86000000e+02,\n",
       "          2.00000000e+00,   5.95307918e-01,   6.18556701e-01],\n",
       "       [  2.00000000e+00,   3.02000000e+03,   2.32000000e+02,\n",
       "          5.20000000e+01,   5.52050473e-01,   7.73885350e-01],\n",
       "       ..., \n",
       "       [  1.25204000e+05,   3.02100000e+03,   2.31000000e+02,\n",
       "          1.99000000e+02,   5.94339623e-01,   6.01941748e-01],\n",
       "       [  1.25205000e+05,   3.02100000e+03,   3.50000000e+02,\n",
       "          6.60000000e+01,   4.40729483e-01,   3.57575758e-01],\n",
       "       [  1.25206000e+05,   3.02000000e+03,   3.13000000e+02,\n",
       "          2.88000000e+02,   2.91970803e-01,   1.87500000e-01]])"
      ]
     },
     "execution_count": 540,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_new.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(x_test_new.values) ):\n",
    "    if x_test_new.values[i, 4] < 0.00001:\n",
    "        arr[i] = 1\n",
    "    if x_test_new.values[i, 5] < 0.00001:\n",
    "        arr[i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ss = sample_submission.copy()\n",
    "\n",
    "ss.target = arr\n",
    "ss.to_csv('mighty_xgboost.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strange, but it seems like we got 0.658 instead of 0.649! \n",
    "\n",
    "### What could it be? Perhabs we need to train on all data instead of just 40% of it? Or may be should think over our cross-validation process?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's overview now what we just did here:\n",
    "1) made cross-validation\n",
    "\n",
    "2) tried linear models, they didn't work, but we figured out how to tackle this problem\n",
    "\n",
    "3) tried random forest and almost beat constant benchmark\n",
    "\n",
    "4) tried xgboost and finally beat constant prediction!\n",
    "\n",
    "### But there is the last thing you must know before you'll start this challenge by trying to make the most thorough parameter tuning: the data has it's secrets and those who will find them will be generously rewarded...\n",
    "\n",
    "### now, good luck with it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
